TITLE: Slides from FYS-KJM4411/9411 Variational Monte Carlo methods
AUTHOR: Morten Hjorth-Jensen at Department of Physics, University of Oslo, Oslo, Norway & Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, MI 48824, USA
DATE: Spring 2015





!split
===== Basic Matrix Features =====
!bblock Matrix properties reminder
!bt
\[
 {\bf A} =
      \left( \begin{array}{cccc} a_{11} & a_{12} & a_{13} & a_{14} \\
                                 a_{21} & a_{22} & a_{23} & a_{24} \\
                                   a_{31} & a_{32} & a_{33} & a_{34} \\
                                  a_{41} & a_{42} & a_{43} & a_{44}
             \end{array} \right)\qquad
{\bf I} =
      \left( \begin{array}{cccc} 1 & 0 & 0 & 0 \\
                                 0 & 1 & 0 & 0 \\
                                 0 & 0 & 1 & 0 \\
                                 0 & 0 & 0 & 1
             \end{array} \right)
\]
!et
!eblock


!split
===== Quantum Monte Carlo Motivation =====
!bblock
Given a hamiltonian $H$ and a trial wave function $\Psi_T$, the variational principle states that the expectation value of $\langle H \rangle$, defined through 
!bt
\[
   E[H]= \langle H \rangle =
   \frac{\int d\bm{R}\Psi^{\ast}_T(\bm{R})H(\bm{R})\Psi_T(\bm{R})}
        {\int d\bm{R}\Psi^{\ast}_T(\bm{R})\Psi_T(\bm{R})},
\]
!et
is an upper bound to the ground state energy $E_0$ of the hamiltonian $H$, that is 
!bt
\[
    E_0 \le \langle H \rangle .
\]
!et
In general, the integrals involved in the calculation of various  expectation values  are multi-dimensional ones. Traditional integration methods such as the Gauss-Legendre will not be adequate for say the  computation of the energy of a many-body system.
!eblock

!split
===== Quantum Monte Carlo Motivation =====
!bblock
The trial wave function can be expanded in the eigenstates of the hamiltonian since they form a complete set, viz.,
!bt
\[
   \Psi_T(\bm{R})=\sum_i a_i\Psi_i(\bm{R}),
\]
!et
and assuming the set of eigenfunctions to be normalized one obtains 
!bt
\[
     \frac{\sum_{nm}a^*_ma_n \int d\bm{R}\Psi^{\ast}_m(\bm{R})H(\bm{R})\Psi_n(\bm{R})}
        {\sum_{nm}a^*_ma_n \int d\bm{R}\Psi^{\ast}_m(\bm{R})\Psi_n(\bm{R})} =\frac{\sum_{n}a^2_n E_n}
        {\sum_{n}a^2_n} \ge E_0,
\]
!et
where we used that $H(\bm{R})\Psi_n(\bm{R})=E_n\Psi_n(\bm{R})$.
In general, the integrals involved in the calculation of various  expectation
values  are multi-dimensional ones. 
The variational principle yields the lowest state of a given symmetry.

!eblock


!split
===== Quantum Monte Carlo Motivation =====
!bblock
In most cases, a wave function has only small values in large parts of 
configuration space, and a straightforward procedure which uses
homogenously distributed random points in configuration space 
will most likely lead to poor results. This may suggest that some kind
of importance sampling combined with e.g., the Metropolis algorithm 
may be  a more efficient way of obtaining the ground state energy.
The hope is then that those regions of configurations space where
the wave function assumes appreciable values are sampled more 
efficiently. 
!eblock


!split
===== Quantum Monte Carlo Motivation =====
!bblock
The tedious part in a VMC calculation is the search for the variational
minimum. A good knowledge of the system is required in order to carry out
reasonable VMC calculations. This is not always the case, 
and often VMC calculations 
serve rather as the starting
point for so-called diffusion Monte Carlo calculations (DMC). DMC is a way of
solving exactly the many-body Schroedinger equation by means of 
a stochastic procedure. A good guess on the binding energy
and its wave function is however necessary. 
A carefully performed VMC calculation can aid in this context. 
!eblock


!split
===== Quantum Monte Carlo Motivation =====
!bblock
* Construct first a trial wave function $\psi_T(\bm{R},\bm{\alpha})$,  for a many-body system consisting of $N$ particles located at positions 
$\bm{R}=(\bm{R}_1,\dots ,\bm{R}_N)$. The trial wave function depends on $\alpha$ variational parameters $\bm{\alpha}=(\alpha_1,\dots ,\alpha_M)$.
* Then we evaluate the expectation value of the hamiltonian $H$ 
!bt
\[
   E[H]=\langle H \rangle =
   \frac{\int d\bm{R}\Psi^{\ast}_{T}(\bm{R},\bm{\alpha})H(\bm{R})\Psi_{T}(\bm{R},\bm{\alpha})}
        {\int d\bm{R}\Psi^{\ast}_{T}(\bm{R},\bm{\alpha})\Psi_{T}(\bm{R},\bm{\alpha})}.
\]
!et
* Thereafter we vary $\alpha$ according to some minimization algorithm and return to the first step.
!eblock


!split
===== Quantum Monte Carlo Motivation =====
!bblock Basic steps
Choose a trial wave function
$\psi_T(\bm{R})$.
!bt
\[
   P(\bm{R})= \frac{\left|\psi_T(\bm{R})\right|^2}{\int \left|\psi_T(\bm{R})\right|^2d\bm{R}}.
\]
!et
This is our new probability distribution function  (PDF).
The approximation to the expectation value of the Hamiltonian is now 
!bt
\[
   E[H(\bm{\alpha})] = 
   \frac{\int d\bm{R}\Psi^{\ast}_T(\bm{R},\bm{\alpha})H(\bm{R})\Psi_T(\bm{R},\bm{\alpha})}
        {\int d\bm{R}\Psi^{\ast}_T(\bm{R},\bm{\alpha})\Psi_T(\bm{R},\bm{\alpha})}.
\]
!et
!eblock


!split
===== Quantum Monte Carlo Motivation =====
!bblock
Define a new quantity
!bt
\[
   E_L(\bm{R},\bm{\alpha})=\frac{1}{\psi_T(\bm{R},\bm{\alpha})}H\psi_T(\bm{R},\bm{\alpha}),
   label{eq:locale1}
\]
!et
called the local energy, which, together with our trial PDF yields
!bt
\[
  E[H(\bm{\alpha})]= = \int P(\bm{R})E_L(\bm{R}) d\bm{R}\approx \frac{1}{N}\sum_{i=1}^NP(\bm{R_i},\bm{\alpha})E_L(\bm{R_i},\bm{\alpha})
  label{eq:vmc1}
\]
!et
with $N$ being the number of Monte Carlo samples.
!eblock






!split
===== Quantum Monte Carlo =====
!bblock
The Algorithm for performing a variational Monte Carlo calculations runs thus as this
       
  *  Initialisation: Fix the number of Monte Carlo steps. Choose an initial $\bm{R}$ and variational parameters $\alpha$ and calculate $\left|\psi_T^{\alpha}(\bm{R})\right|^2$. 
  *  Initialise the energy and the variance and start the Monte Carlo calculation.
     *  Calculate  a trial position  $\bm{R}_p=\bm{R}+r*step$ where $r$ is a random variable $r \in [0,1]$.
     *  Metropolis algorithm to accept or reject this move  $w = P(\bm{R}_p)/P(\bm{R})$.
     *  If the step is accepted, then we set $\bm{R}=\bm{R}_p$. 
     *  Update averages
  *  Finish and compute final averages.
      
Observe that the jumping in space is governed by the variable *step*. This is Called brute-force sampling.
Need importance sampling to get more relevant sampling, see lectures below.

!split
===== Quantum Monte Carlo: hydrogen atom =====
!bblock
The radial Schroedinger equation for the hydrogen atom can be
written as
!bt
\[
-\frac{\hbar^2}{2m}\frac{\partial^2 u(r)}{\partial r^2}-
\left(\frac{ke^2}{r}-\frac{\hbar^2l(l+1)}{2mr^2}\right)u(r)=Eu(r),
\]
!et
or with dimensionless variables
!bt
\[
-\frac{1}{2}\frac{\partial^2 u(\rho)}{\partial \rho^2}-
\frac{u(\rho)}{\rho}+\frac{l(l+1)}{2\rho^2}u(\rho)-\lambda u(\rho)=0,
label{eq:hydrodimless1}
\]
!et
with the hamiltonian
!bt
\[
H=-\frac{1}{2}\frac{\partial^2 }{\partial \rho^2}-
\frac{1}{\rho}+\frac{l(l+1)}{2\rho^2}.
\]
!et
Use variational parameter $\alpha$ in the trial
wave function 
!bt
\[
   u_T^{\alpha}(\rho)=\alpha\rho e^{-\alpha\rho}. 
   label{eq:trialhydrogen}
\]
!et
!eblock

!split
===== Quantum Monte Carlo: hydrogen atom =====
!bblock
Inserting this wave function into the expression for the
local energy $E_L$ gives
!bt
\[
   E_L(\rho)=-\frac{1}{\rho}-
              \frac{\alpha}{2}\left(\alpha-\frac{2}{\rho}\right).
\]
!et
A simple variational Monte Carlo calculation results in
|----------------------------------------------------------------------------------------|
|     $\alpha$      |     $\langle H \rangle $      | $\sigma^2$  |  $\sigma/\sqrt{N}$   |
|----------------------------------------------------------------------------------------|
| 7.00000E-01 |        -4.57759E-01 |  4.51201E-02 |  6.71715E-04  |
| 8.00000E-01 |        -4.81461E-01 |  3.05736E-02 |  5.52934E-04 |
| 9.00000E-01 | -4.95899E-01 |  8.20497E-03 |  2.86443E-04  |
| 1.00000E-00 | -5.00000E-01 |  0.00000E+00 |  0.00000E+00  |
| 1.10000E+00 | -4.93738E-01 |  1.16989E-02 |  3.42036E-04  |
| 1.20000E+00 | -4.75563E-01 |  8.85899E-02 |  9.41222E-04  |
| 1.30000E+00 | -4.54341E-01 |  1.45171E-01 |  1.20487E-03  |
|----------------------------------------------------------------------------------------|

!eblock


!split
===== Quantum Monte Carlo: hydrogen atom =====
!bblock

We note that at $\alpha=1$ we obtain the exact
result, and the variance is zero, as it should. The reason is that 
we then have the exact wave function, and the action of the hamiltionan
on the wave function
!bt
\[
   H\psi = \mathrm{constant}\times \psi,
\]
!et
yields just a constant. The integral which defines various 
expectation values involving moments of the hamiltonian becomes then
!bt
\[
   \langle H^n \rangle =
   \frac{\int d\bm{R}\Psi^{\ast}_T(\bm{R})H^n(\bm{R})\Psi_T(\bm{R})}
        {\int d\bm{R}\Psi^{\ast}_T(\bm{R})\Psi_T(\bm{R})}=
\mathrm{constant}\times\frac{\int d\bm{R}\Psi^{\ast}_T(\bm{R})\Psi_T(\bm{R})}
        {\int d\bm{R}\Psi^{\ast}_T(\bm{R})\Psi_T(\bm{R})}=\mathrm{constant}.
\]
!et
_This gives an important information: the exact wave function leads to zero variance!_
Variation is then performed by minimizing both the energy and the variance.
!eblock



!split
===== Quantum Monte Carlo: the helium atom =====
!bblock
The helium atom consists of two electrons and a nucleus with
charge $Z=2$. 
The contribution  
to the potential energy due to the attraction from the nucleus is
!bt
\[
   -\frac{2ke^2}{r_1}-\frac{2ke^2}{r_2},
\] 
!et
and if we add the repulsion arising from the two 
interacting electrons, we obtain the potential energy
!bt
\[
 V(r_1, r_2)=-\frac{2ke^2}{r_1}-\frac{2ke^2}{r_2}+
               \frac{ke^2}{r_{12}},
\]
!et
with the electrons separated at a distance 
$r_{12}=|\bm{r}_1-\bm{r}_2|$.
!eblock


!split
===== Quantum Monte Carlo: the helium atom =====
!bblock

The hamiltonian becomes then
!bt
\[
   \hat{H}=-\frac{\hbar^2\nabla_1^2}{2m}-\frac{\hbar^2\nabla_2^2}{2m}
          -\frac{2ke^2}{r_1}-\frac{2ke^2}{r_2}+
               \frac{ke^2}{r_{12}},
\]
!et
and  Schroedingers equation reads
!bt
\[
   \hat{H}\psi=E\psi.
\]
!et
All observables are evaluated with respect to the probability distribution
!bt
\[
   P(\bm{R})= \frac{\left|\psi_T(\bm{R})\right|^2}{\int \left|\psi_T(\bm{R})\right|^2d\bm{R}}.
\]
!et
generated by the trial wave function.   
The trial wave function must approximate an exact 
eigenstate in order that accurate results are to be obtained. 
!eblock

!split
===== Quantum Monte Carlo: the helium atom =====
!bblock
Choice of trial wave function for Helium:
Assume $r_1 \rightarrow 0$.
!bt
\[
   E_L(\bm{R})=\frac{1}{\psi_T(\bm{R})}H\psi_T(\bm{R})=
     \frac{1}{\psi_T(\bm{R})}\left(-\frac{1}{2}\nabla^2_1
     -\frac{Z}{r_1}\right)\psi_T(\bm{R}) + \mathrm{finite \hspace{0.1cm}terms}.
\]
!et
!bt
\[ 
    E_L(R)=
    \frac{1}{{\cal R}_T(r_1)}\left(-\frac{1}{2}\frac{d^2}{dr_1^2}-
     \frac{1}{r_1}\frac{d}{dr_1}
     -\frac{Z}{r_1}\right){\cal R}_T(r_1) + \mathrm{finite\hspace{0.1cm} terms}
\]
!et
For small values of $r_1$, the terms which dominate are
!bt
\[ 
    \lim_{r_1 \rightarrow 0}E_L(R)=
    \frac{1}{{\cal R}_T(r_1)}\left(-
     \frac{1}{r_1}\frac{d}{dr_1}
     -\frac{Z}{r_1}\right){\cal R}_T(r_1),
\]
!et
since the second derivative does not diverge due to the finiteness of  $\Psi$ at the origin.
!eblockx




!split
===== Quantum Monte Carlo: the helium atom =====
!bblock
This results in
!bt
\[
     \frac{1}{{\cal R}_T(r_1)}\frac{d {\cal R}_T(r_1)}{dr_1}=-Z,
\]
!et
and
!bt
\[
   {\cal R}_T(r_1)\propto e^{-Zr_1}.
\]
!et
A similar condition applies to electron 2 as well. 
For orbital momenta $l > 0$ we have 
!bt
\[
     \frac{1}{{\cal R}_T(r)}\frac{d {\cal R}_T(r)}{dr}=-\frac{Z}{l+1}.
\]
!et
Similarly, studying the case $r_{12}\rightarrow 0$ we can write 
a possible trial wave function as
!bt
\[
   \psi_T(\bm{R})=e^{-\alpha(r_1+r_2)}e^{\beta r_{12}}.
    label{eq:wavehelium2}
\]
!et
The last equation can be generalized to
!bt
\[
   \psi_T(\bm{R})=\phi(\bm{r}_1)\phi(\bm{r}_2)\dots\phi(\bm{r}_N)
                   \prod_{i< j}f(r_{ij}),
\]
!et
for a system with $N$ electrons or particles. 
!eblock


!split
===== The first attempt at solving the Helium atom =====
!bblock The main program
!bc cppcod
#include "vmcsolver.h"
#include <iostream>

using namespace std;

int main()
{
    VMCSolver *solver = new VMCSolver();
    solver->runMonteCarloIntegration();
    return 0;
}
!ec
!eblock


!split
===== The first attempt at solving the Helium atom =====
!bblock The VMCSolver class
!bc cppcod
#ifndef VMCSOLVER_H
#define VMCSOLVER_H
#include <armadillo>

using namespace arma;
class VMCSolver
{
public:
    VMCSolver();
    void runMonteCarloIntegration();
private:
    double waveFunction(const mat &r);
    double localEnergy(const mat &r);
    int nDimensions, charge, nparticles;
    double stepLength, h, h2, alpha;
    long idum;
    int nCycles;
    mat rOld, rNew;
};
#endif // VMCSOLVER_H
!ec
!eblock


!split
===== The first attempt at solving the Helium atom =====
!bblock The VMCSolver class
!bc cppcod

!ec
!eblock


!split
===== The first attempt at solving the Helium atom =====
!bblock The VMCSolver class
!bc cppcod

!ec
!eblock


!split
===== The first attempt at solving the Helium atom =====
!bblock The VMCSolver class
!bc cppcod
#include "vmcsolver.h"
#include "lib.h"
#include <armadillo>
#include <iostream>
using namespace arma;
using namespace 
VMCSolver::VMCSolver() :
    nDimensions(3),
    charge(2),
    stepLength(1.0),
    nparticles(2),
    h(0.001),
    h2(1000000),
    idum(-1),
    alpha(0.5*charge),
    nCycles(1000000)

void VMCSolver::runMonteCarloIntegration()
{
    rOld = zeros<mat>(nparticles, nDimensions);
    rNew = zeros<mat>(nparticles, nDimensions);
    double waveFunctionOld = 0;
    double waveFunctionNew = 0;
    double energySum = 0;
    double energySquaredSum = 0;
    double deltaE;
    // initial trial positions
    for(int i = 0; i < nparticles; i++) {
        for(int j = 0; j < nDimensions; j++) {
            rOld(i,j) = stepLength * (ran2(&idum) - 0.5);
        }
    }
    rNew = rOld;
    // loop over Monte Carlo cycles
    for(int cycle = 0; cycle < nCycles; cycle++) {
        // Store the current value of the wave function
        waveFunctionOld = waveFunction(rOld);
        // New position to test
        for(int i = 0; i < nparticles; i++) {
            for(int j = 0; j < nDimensions; j++) {
                rNew(i,j) = rOld(i,j) + stepLength*(ran2(&idum) - 0.5);
            }
            // Recalculate the value of the wave function
            waveFunctionNew = waveFunction(rNew);
            // Check for step acceptance (if yes, update position, if no, reset position)
            if(ran2(&idum) <= (waveFunctionNew*waveFunctionNew) / (waveFunctionOld*waveFunctionOld)) {
                for(int j = 0; j < nDimensions; j++) {
                    rOld(i,j) = rNew(i,j);
                    waveFunctionOld = waveFunctionNew;
                }
            } else {
                for(int j = 0; j < nDimensions; j++) {
                    rNew(i,j) = rOld(i,j);
                }
            }
            // update energies
            deltaE = localEnergy(rNew);
            energySum += deltaE;
            energySquaredSum += deltaE*deltaE;
        }
    }
    double energy = energySum/(nCycles * nparticles);
    double energySquared = energySquaredSum/(nCycles * nparticles);
    cout << "Energy: " << energy << " Energy (squared sum): " << energySquared << endl;
}
double VMCSolver::localEnergy(const mat &r)
{
    mat rPlus = zeros<mat>(nparticles, nDimensions);
    mat rMinus = zeros<mat>(nparticles, nDimensions);
    rPlus = rMinus = r;
    double waveFunctionMinus = 0;
    double waveFunctionPlus = 0;
    double waveFunctionCurrent = waveFunction(r);
    // Kinetic energy
    double kineticEnergy = 0;
    for(int i = 0; i < nparticles; i++) {
        for(int j = 0; j < nDimensions; j++) {
            rPlus(i,j) += h;
            rMinus(i,j) -= h;
            waveFunctionMinus = waveFunction(rMinus);
            waveFunctionPlus = waveFunction(rPlus);
            kineticEnergy -= (waveFunctionMinus + waveFunctionPlus - 2 * waveFunctionCurrent);
            rPlus(i,j) = r(i,j);
            rMinus(i,j) = r(i,j);
        }
    }
    kineticEnergy = 0.5 * h2 * kineticEnergy / waveFunctionCurrent;
    // Potential energy
    double potentialEnergy = 0;
    double rSingleParticle  = 0;
    for(int i = 0; i < nparticles; i++) {
        rSingleParticle  = 0;
        for(int j = 0; j < nDimensions; j++) {
            rSingleParticle  += r(i,j)*r(i,j);
        }
        potentialEnergy -= charge / sqrt(rSingleParticle );
    }
    // Contribution from electron-electron potential
    double r12 = 0;
    for(int i = 0; i < nparticles; i++) {
        for(int j = i + 1; j < nparticles; j++) {
            r12 = 0;
            for(int k = 0; k < nDimensions; k++) {
                r12 += (r(i,k) - r(j,k)) * (r(i,k) - r(j,k));
            }
            potentialEnergy += 1 / sqrt(r12);
        }
    }
    return kineticEnergy + potentialEnergy;
}
double VMCSolver::waveFunction(const mat &r)
{
    double argument = 0;
    for(int i = 0; i < nparticles; i++) {
        double rSingleParticle  = 0;
        for(int j = 0; j < nDimensions; j++) {
            rSingleParticle  += r(i,j) * r(i,j);
        }
        argument += sqrt(rSingleParticle );
    }
    return exp(-argument * alpha);
}
!ec
!eblock


During the development of our code we need to make several checks. It is also very instructive to compute a closed form expression for the local energy. Since our wave function is rather simple  it is straightforward
to find an analytic expressions.  Consider first the case of the simple helium function 
\[
   \Psi_T(\mathbf{r}_1,\mathbf{r}_2) = e^{-\alpha(r_1+r_2)}
\]
The local energy is for this case 
\[ 
E_{L1} = \left(\alpha-Z\right)\left(\frac{1}{r_1}+\frac{1}{r_2}\right)+\frac{1}{r_{12}}-\alpha^2
\]
which gives an expectation value for the local energy given by
\[
\langle E_{L1} \rangle = \alpha^2-2\alpha\left(Z-\frac{5}{16}\right)
\]
In our project, the simple form is
\[
   \Psi_T(\mathbf{r}_1,\mathbf{r}_2) = e^{-\alpha\omega(r_1^2+r_2^2)/2}
\]
Find the contribution to the local energy!


  ===== Structuring the code}


With closed form formulae we  can speed up the computation of the correlation. In our case
we write it as 
\[
\Psi_C= \exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\]
which means that the gradient needed for the so-called quantum force and local energy 
can be calculated analytically.
This will speed up your code since the computation of the correlation part and the Slater determinant are the most 
time consuming parts in your code.  

We will refer to this correlation function as $\Psi_C$ or the \emph{linear Pad\'e-Jastrow}.


  ===== Structuring the code}


We can test this by computing the local energy for our helium wave function

\[
   \psi_{T}(\bm{r}_1,\bm{r}_2) = 
   \exp{\left(-\alpha(r_1+r_2)\right)}
   \exp{\left(\frac{r_{12}}{2(1+\beta r_{12})}\right)}, 
\]

with $\alpha$ and $\beta$ as variational parameters.

The local energy is for this case 
\[ 
E_{L2} = E_{L1}+\frac{1}{2(1+\beta r_{12})^2}\left\{\frac{\alpha(r_1+r_2)}{r_{12}}(1-\frac{\mathbf{r}_1\mathbf{r}_2}{r_1r_2})-\frac{1}{2(1+\beta r_{12})^2}-\frac{2}{r_{12}}+\frac{2\beta}{1+\beta r_{12}}\right\}
\]
It is very useful to test your code against these expressions. It means also that you don't need to
compute a derivative numerically as discussed in the above code example. 

!split
===== Your first tasks =====

*  Implement the closed form expression for the local energy
*  Convince yourself that the closed form expressions are correct. 
*  Implement the above expressions for the helium atom with two electrons.
*  Start working on exercises 1a and 1b. 



*  Implement the closed form expression for the local energy and the so-called quantum force
*  Convince yourself that the closed form expressions are correct.
*  Implement the closed form expressions for systems with more than two electrons.
*  Make another copy of your code.
*  Implement the closed form expression for the local energy
*  Compile the new and old codes with the -pg option for profiling.
*  Run both codes and profile them afterwards using $\mathrm{gprof} \{\mathrm{name executable}\} > \mathrm{outprofile}$
*  Study the time usage in the file _outprofile_

}

}



 {
   ===== Efficient calculations of wave function ratios}
 
 

In the Metropolis/Hasting algorithm, the \emph{acceptance ratio} determines the probability for a particle  to be accepted at a new position. The ratio of the trial wave functions evaluated at the new and current positions is given by

\begin{equation}label{acceptanceRatio}
\boxed{R \equiv \frac{\Psi_{T}^{new}}{\Psi_{T}^{cur}} = \underbrace{\frac{\Psi_{D}^{new}}{\Psi_{D}^{cur}}}_{R_{SD}}\, \underbrace{\frac{\Psi_{C}^{new}}{\Psi_{C}^{cur}}}_{R_{C}}.}
\end{equation}
Here $\Psi_{D}$ is our Slater determinant while $\Psi_{C}$ is our correlation function. 
We need to optimize $\nabla \Psi_T / \Psi_T$ ratio and the second derivative as well, that is
the $\nabla^2 \Psi_T/\Psi_T$ ratio. The first is needed when we compute the so-called quantum force in importance sampling.
The second is needed when we compute the kinetic energy term of the local energy.
\[
\frac{\Grad \Psi}{\Psi}  = \frac{\Grad (\Psi_{D} \, \Psi_{C})}{\Psi_{D} \, \Psi_{C}}  =  \frac{ \Psi_C \Grad \Psi_{D} + \Psi_{D} \Grad \Psi_{C}}{\Psi_{D} \Psi_{C}} = \frac{\Grad \Psi_{D}}{\Psi_{D}} + \frac{\Grad  \Psi_C}{ \Psi_C}
\]


   ===== Efficient calculations of wave function ratios}
 
 

The expectation value of the kinetic energy expressed in atomic units for electron $i$ is 
\begin{equation}
 \langle \Op{K}_i \rangle = -\frac{1}{2}\frac{\langle\Psi|\nabla_{i}^2|\Psi \rangle}{\langle\Psi|\Psi \rangle},
\end{equation}

\begin{equation}label{kineticE}
K_i = -\frac{1}{2}\frac{\nabla_{i}^{2} \Psi}{\Psi}.
\end{equation}
\begin{eqnarray}
\frac{\nabla^2 \Psi}{\Psi} & = & \frac{\nabla^2 ({\Psi_{D} \,  \Psi_C})}{\Psi_{D} \,  \Psi_C} = \frac{\Grad \cdot [\Grad {(\Psi_{D} \,  \Psi_C)}]}{\Psi_{D} \,  \Psi_C} = \frac{\Grad \cdot [ \Psi_C \Grad \Psi_{D} + \Psi_{D} \Grad  \Psi_C]}{\Psi_{D} \,  \Psi_C}\nonumber\\
&  = & \frac{\Grad  \Psi_C \cdot \Grad \Psi_{D} +  \Psi_C \nabla^2 \Psi_{D} + \Grad \Psi_{D} \cdot \Grad  \Psi_C + \Psi_{D} \nabla^2  \Psi_C}{\Psi_{D} \,  \Psi_C}\nonumber\\
\end{eqnarray}
\begin{eqnarray}
\frac{\nabla^2 \Psi}{\Psi}
& = & \frac{\nabla^2 \Psi_{D}}{\Psi_{D}} + \frac{\nabla^2  \Psi_C}{ \Psi_C} + 2 \frac{\Grad \Psi_{D}}{\Psi_{D}}\cdot\frac{\Grad  \Psi_C}{ \Psi_C}
\end{eqnarray}
 }
 
 }



 {
   ===== Definitions}
 
 
We define the correlated function as
\[
\Psi_C=\prod_{i< j}g(r_{ij})=\prod_{i< j}^Ng(r_{ij})= \prod_{i=1}^N\prod_{j=i+1}^Ng(r_{ij}),
\]
with 
$r_{ij}=|\bm{r}_i-\bm{r}_j|=\sqrt{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2}$ for three dimensions and
$r_{ij}=|\bm{r}_i-\bm{r}_j|=\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}$ for two dimensions.

In our particular case we have
\[
\Psi_C=\prod_{i< j}g(r_{ij})=\exp{\left\{\sum_{i<j}f(r_{ij})\right\}}=
\exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\]
 }
 
 }






 {
   ===== Efficient calculations of wave function ratios}
 
 

The total number of different relative distances $r_{ij}$ is $N(N-1)/2$. In a matrix storage format, the set forms a strictly upper triangular matrix
\begin{equation}label{utrij}
 \bfv{r} \equiv \begin{pmatrix}
  0 & r_{1,2} & r_{1,3} & \cdots & r_{1,N} \\
  \vdots & 0       & r_{2,3} & \cdots & r_{2,N} \\
  \vdots & \vdots  & 0  & \ddots & \vdots  \\
  \vdots & \vdots  & \vdots  & \ddots  & r_{N-1,N} \\
  0 & 0  & 0  & \cdots  & 0
 \end{pmatrix}.
\end{equation}
This applies to  $\bfv{g} = \bfv{g}(r_{ij})$ as well. 

In our algorithm we will move one particle  at the time, say the $kth$-particle . Keep this in mind in the discussion to come.
 }
 
 }



 {
   ===== Efficient calculations of wave function ratios}
 
 
\begin{equation}label{RjfRatio}
 \boxed{R_{C} = \frac{\Psi_{C}^\mathrm{new}}{\Psi_{C}^\mathrm{cur}} =
\prod_{i=1}^{k-1}\frac{g_{ik}^\mathrm{new}}{g_{ik}^\mathrm{cur}}\;
\prod_{i=k+1}^{N}\frac{g_{ki}^\mathrm{new}}{g_{ki}^\mathrm{cur}}}.
\end{equation}label{padepadeRatio}
For the Pad\'e-Jastrow form
\begin{equation}
 \boxed{R_{C} = \frac{\Psi_{C}^\mathrm{new}}{\Psi_{C}^\mathrm{cur}} = \frac{e^{U_{new}}}{e^{U_{cur}}} = e^{\Delta U},}
\end{equation}
where
\begin{equation}
\Delta U =
\sum_{i=1}^{k-1}\big(f_{ik}^\mathrm{new}-f_{ik}^\mathrm{cur}\big)
+
\sum_{i=k+1}^{N}\big(f_{ki}^\mathrm{new}-f_{ki}^\mathrm{cur}\big)
\end{equation}

One needs to develop a special algorithm 
that runs only through the elements of the upper triangular
matrix $\bfv{g}$ and have $k$ as an index. 

 }
 
 }



 {
   ===== Efficient calculations of wave function ratios}
 
 
The expression to be derived in the following is of interest when computing the quantum force and the kinetic energy. It has the form
$$
\frac{\bfv{{\nabla_i}}\Psi_C}{\Psi_C} = \frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_i},
$$
for all dimensions and with $i$ running over all particles.
For the first derivative only $N-1$ terms survive the ratio because the $g$-terms that are not differentiated cancel with their corresponding ones in the denominator. Then,
\begin{equation}label{1jgradG}
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{1}{g_{ik}}\frac{\partial g_{ik}}{\partial x_k}
+
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\partial g_{ki}}{\partial x_k}.
\end{equation}
An equivalent equation is obtained for the exponential form after replacing $g_{ij}$ by $\exp(f_{ij})$, yielding:
\begin{equation}label{1jgradEG}
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k}
+
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_k},
\end{equation}
with both expressions scaling as $\mathcal{O}(N)$.
 }
 
 }



 {
   ===== Efficient calculations of wave function ratios}
 
 
Using the identity 
\begin{equation}label{firstDerIdentity}
\frac{\partial}{\partial x_i}g_{ij} = -\frac{\partial}{\partial x_j}g_{ij} 
\end{equation}
on the right hand side terms of Eq.~(ref{1jgradG}) and Eq.~(ref{1jgradEG}), we get expressions where all the derivatives acting on the particle  are represented by the
\emph{second} index of $g$:
\begin{equation}label{gradJasGen}
\boxed{
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{1}{g_{ik}}\frac{\partial g_{ik}}{\partial x_k}
-
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\partial g_{ki}}{\partial x_i},
}
\end{equation}
and for the exponential case:
\begin{equation}label{gradJasGenExp}
\boxed{
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k}
-
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_i}.
}
\end{equation}
 }
 
 }

 {
   ===== Efficient calculations of wave function ratios}
 
 

For correlation forms depending only on the scalar distances $r_{ij}$ we can use the chain rule. Noting that 
\begin{equation}label{chainRule}
\frac{\partial g_{ij}}{\partial x_j} = \frac{\partial g_{ij}}{\partial r_{ij}} \frac{\partial r_{ij}}{\partial x_j} = \frac{x_j - x_i}{r_{ij}} \frac{\partial g_{ij}}{\partial r_{ij}},
\end{equation}
after substitution in Eq.~(ref{gradJasGen}) and Eq.~(ref{gradJasGenExp}) we arrive at
\begin{equation}label{generalCorrelation}
\boxed{
\frac{1}{\Psi_C}\frac{\partial \Psi_C}{\partial x_k} = 
\sum_{i=1}^{k-1}\frac{1}{g_{ik}} \frac{\bfv{r_{ik}}}{r_{ik}} \frac{\partial g_{ik}}{\partial r_{ik}}
-
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\bfv{r_{ki}}}{r_{ki}}\frac{\partial g_{ki}}{\partial r_{ki}}.
}
\end{equation}
 }
 
 }

 {
   ===== Efficient calculations of wave function ratios}
 
 

Note that for the Pad\'e-Jastrow form we can set $g_{ij} \equiv g(r_{ij}) = e^{f(r_{ij})} = e^{f_{ij}}$ and 
\begin{equation}
\frac{\partial g_{ij}}{\partial r_{ij}} = g_{ij} \frac{\partial f_{ij}}{\partial r_{ij}}.
\end{equation}
Therefore, 
\begin{equation}label{padeJastrowGradJasRatio}
\boxed{
\frac{1}{\Psi_{C}}\frac{\partial \Psi_{C}}{\partial x_k} =
\sum_{i=1}^{k-1}\frac{\bfv{r_{ik}}}{r_{ik}}\frac{\partial f_{ik}}{\partial r_{ik}}
-
\sum_{i=k+1}^{N}\frac{\bfv{r_{ki}}}{r_{ki}}\frac{\partial f_{ki}}{\partial r_{ki}},
}
\end{equation}
where 
\begin{equation}label{distanceVector}
 \bfv{r}_{ij} = |\bfv{r}_j - \bfv{r}_i| = (x_j - x_i)\vec{e}_1 + (y_j - y_i)\vec{e}_2 + (z_j - z_i)\vec{e}_3
\end{equation}
is the vectorial distance. When the correlation function is the \emph{linear Pad\'e-Jastrow} we set \begin{equation}
f_{ij} = \frac{a r_{ij}}{(1 + \beta r_{ij})},
\end{equation}
which yields the closed form expression
\begin{equation}label{analyticalPJGrad}
 \boxed{\frac{\partial f_{ij}}{\partial r_{ij}} = \frac{a}{(1 + \beta r_{ij})^2}}.
\end{equation}
 }
 
 }




 {
   ===== Efficient calculations of wave function ratios}
 
 

{Computing the $\nabla^2 \Psi_C/\Psi_C$ ratio}

\[\bfv{\nabla}_k \Psi_C = 
\sum_{i=1}^{k-1}\frac{1}{g_{ik}} \bfv{\nabla}_k g_{ik}
+
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\bfv{\nabla}_k g_{ki}.\]
After multiplying by $\Psi_C$ and taking the gradient on both sides we get,
\begin{align}label{gradLap}
\nabla_{k}^2 \Psi_C & = \bfv{\nabla}_k \Psi_C \cdot 
\left(\sum_{i=1}^{k-1}\frac{1}{g_{ik}} \bfv{\nabla}_k g_{ik}
+
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\bfv{\nabla}_k g_{ki}\right)\nonumber\\
&+
\Psi_C \nabla_k \cdot \left(\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\bfv{\nabla}_k g_{ki}
+
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\bfv{\nabla}_k g_{ki}\right)\nonumber\\
& = \Psi_C \left(\frac{\bfv{\nabla}_k \Psi_C}{\Psi_C}\right)^2 +
\Psi_C \nabla_k \cdot \left(\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\bfv{\nabla}_k g_{ki}
+
\sum_{i=k+1}^{N}\frac{1}{g_{ki}}\bfv{\nabla}_k g_{ki}\right).
\end{align}
 }
 
 }

 {
   ===== Efficient calculations of wave function ratios}
 
 

Now,
\begin{align}
 \bfv{\nabla}_k \cdot \left(\frac{1}{g_{ik}}\bfv{\nabla}_k g_{ik}\right) &= \bfv{\nabla}_k \left(\frac{1}{g_{ik}}\right)\cdot \bfv{\nabla}_k g_{ik} + \frac{1}{g_{ik}}\bfv{\nabla}_k \cdot \bfv{\nabla}_k g_{ik}\nonumber\\
 & = -\frac{1}{g_{ik}^2} \bfv{\nabla}_k g_{ik} \cdot \bfv{\nabla}_k g_{ik} + \frac{1}{g_{ik}} \bfv{\nabla}_k \cdot \left(\frac{\bfv{r}_{ik}}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right)\nonumber\\
 & = -\frac{1}{g_{ik}^2} (\bfv{\nabla}_k g_{ik})^2 \nonumber\\&+ \frac{1}{g_{ik}}\left[\bfv{\nabla}_k \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right)\cdot \bfv{r}_{ik} + \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right) \bfv{\nabla}_k \cdot \bfv{r}_{ik}  \right] \nonumber\\
 &= -\frac{1}{g_{ik}^2} \left(\frac{\bfv{r}_{ik}}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right)^2\nonumber\\ &+ \frac{1}{g_{ik}}\left[\bfv{\nabla}_k \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right)\cdot \bfv{r}_{ik} + \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right) d  \right]\nonumber\\
 &= -\frac{1}{g_{ik}^2} \left(\frac{\partial g_{ik}}{\partial r_{ik}}\right)^2\nonumber\\ &+ \frac{1}{g_{ik}}\left[\bfv{\nabla}_k \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right)\cdot \bfv{r}_{ik} + \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right) d  \right], label{subs0}
 \end{align}
with $d$ being the number of spatial dimensions.
 }
 
 }

 {
   ===== Efficient calculations of wave function ratios}
 
 

Moreover, 
\begin{align*}
\bfv{\nabla}_k \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right) &= \frac{\bfv{r}_{ik}}{r_{ik}} \frac{\partial }{\partial r_{ik}} \left(\frac{1}{r_{ik}}\frac{\partial g_{ik}}{\partial r_{ik}}\right)\nonumber\\
&=\frac{\bfv{r}_{ik}}{r_{ik}}\left(-\frac{1}{r_{ik}^2}\frac{\partial g_{ik}}{\partial r_{ik}} + \frac{1}{r_{ik}}\frac{\partial^2 g_{ik}}{\partial r_{ik}^2}\right).label{subs1}
\end{align*}

We finally get
\begin{align*}
  \bfv{\nabla}_k \cdot \left(\frac{1}{g_{ik}}\bfv{\nabla}_k g_{ik}\right) &= -\frac{1}{g_{ik}^2}\left(\frac{\partial g_{ik}}{\partial r_{ik}}\right)^2 + \frac{1}{g_{ik}}\left[\left(\frac{d-1}{r_{ik}}\right)\frac{\partial g_{ik}}{\partial r_{ik}} + \frac{\partial^2 g_{ik}}{\partial r_{ik}^2} \right].
\end{align*}
 }
 
 }

 {
   ===== Efficient calculations of wave function ratios}
 
 

Inserting the last expression in Eq.~(ref{gradLap}) and after division by $\Psi_C$ we get,

\begin{align}
 \frac{\nabla_{k}^2 \Psi_C}{\Psi_C} & =  \left(\frac{\bfv{\nabla}_k \Psi_C}{\Psi_C}\right)^2 \nonumber\\
 & + \sum_{i=1}^{k-1} -\frac{1}{g_{ik}^2}\left(\frac{\partial g_{ik}}{\partial r_{ik}}\right)^2 + \frac{1}{g_{ik}}\left[\left(\frac{d-1}{r_{ik}}\right)\frac{\partial g_{ik}}{\partial r_{ik}} + \frac{\partial^2 g_{ik}}{\partial r_{ik}^2} \right]\nonumber\\
 & + \sum_{i=k+1}^{N} -\frac{1}{g_{ki}^2}\left(\frac{\partial g_{ki}}{\partial r_{ki}}\right)^2 + \frac{1}{g_{ki}}\left[\left(\frac{d-1}{r_{ki}}\right)\frac{\partial g_{ki}}{\partial r_{ki}} + \frac{\partial^2 g_{ki}}{\partial r_{ki}^2} \right].
\end{align}
 }
 
 }

 {
   ===== Efficient calculations of wave function ratios}
 
 

For the exponential case we have
\begin{align*}
 \frac{\nabla_{k}^2 \Psi_{C}}{\Psi_{C}} & =  \left(\frac{\bfv{\nabla}_k \Psi_{C}}{\Psi_{C}}\right)^2 \nonumber\\
 & + \sum_{i=1}^{k-1} -\frac{1}{g_{ik}^2}\left(g_{ik}\frac{\partial f_{ik}}{\partial r_{ik}}\right)^2 + \frac{1}{g_{ik}}\left[\left(\frac{d-1}{r_{ik}}\right)g_{ik}\frac{\partial f_{ik}}{\partial r_{ik}} + \frac{\partial }{\partial r_{ik}}\left(g_{ik}\frac{\partial f_{ik}}{\partial r_{ik}}\right) \right]\nonumber\\
 & + \sum_{i=k+1}^{N} -\frac{1}{g_{ki}^2}\left(g_{ik}\frac{\partial f_{ki}}{\partial r_{ki}}\right)^2 + \frac{1}{g_{ki}}\left[\left(\frac{d-1}{r_{ki}}\right)g_{ki}\frac{\partial f_{ki}}{\partial r_{ki}} + \frac{\partial }{\partial r_{ki}}\left(g_{ki}\frac{\partial f_{ki}}{\partial r_{ki}}\right) \right].
 \end{align*}
 }
 
 }
 {
   ===== Efficient calculations of wave function ratios}
 
 

Using
\begin{align*}
 \frac{\partial }{\partial r_{ik}}\left(g_{ik}\frac{\partial f_{ik}}{\partial r_{ik}}\right) & = \frac{\partial g_{ik}}{\partial r_{ik}}\frac{\partial f_{ik}}{\partial r_{ik}} + g_{ik}\frac{\partial^2 f_{ik}}{\partial r_{ik}^2}\\
 & = g_{ik}\frac{\partial f_{ik}}{\partial r_{ik}}\frac{\partial f_{ik}}{\partial r_{ik}} + g_{ik}\frac{\partial^2 f_{ik}}{\partial r_{ik}^2}\\
 & = g_{ik}\left(\frac{\partial f_{ik}}{\partial r_{ik}}\right)^2 + g_{ik}\frac{\partial^2 f_{ik}}{\partial r_{ik}^2}
\end{align*}
and substituting this result into the equation above gives rise to the final expression,
\begin{align}label{lapJasRatio}
\frac{\nabla_{k}^2 \Psi_{PJ}}{\Psi_{PJ}}  &=  \left(\frac{\bfv{\nabla}_k \Psi_{PJ}}{\Psi_{PJ}}\right)^2\nonumber\\
  &+ \sum_{i=1}^{k-1} \left[\left(\frac{d-1}{r_{ik}}\right)\frac{\partial f_{ik}}{\partial r_{ik}} + \frac{\partial^2  f_{ik}}{\partial r_{ik}^2} \right]
  + \sum_{i=k+1}^{N} \left[\left(\frac{d-1}{r_{ki}}\right)\frac{\partial f_{ki}}{\partial r_{ki}} + \frac{\partial^2 f_{ki}}{\partial r_{ki}^2} \right].
 \end{align}
 }
 
 }



{
  ===== Summing up: Bringing it all together, Local energy}



The second derivative of the Jastrow factor divided by the Jastrow factor (the way it enters the kinetic energy) is
\[
\left[\frac{\nabla^2 \Psi_C}{\Psi_C}\right]_x =\  
2\sum_{k=1}^{N}
\sum_{i=1}^{k-1}\frac{\partial^2 g_{ik}}{\partial x_k^2}\ +\ 
\sum_{k=1}^N
\left(
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k} -
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_i}
\right)^2
\]
But we have a simple form for the function, namely
\[
\Psi_{C}=\prod_{i< j}\exp{f(r_{ij})}= \exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\]
and it is easy to see that for particle  $k$
we have
\[
  \frac{\nabla^2_k \Psi_C}{\Psi_C }=
\sum_{ij\ne k}\frac{(\bm{r}_k-\bm{r}_i)(\bm{r}_k-\bm{r}_j)}{r_{ki}r_{kj}}f'(r_{ki})f'(r_{kj})+
\sum_{j\ne k}\left( f''(r_{kj})+\frac{2}{r_{kj}}f'(r_{kj})\right)
\]
}

}




{
  ===== Bringing it all together, Local energy}


Using 
\[
f(r_{ij})= \frac{ar_{ij}}{1+\beta r_{ij}},
\]
and $g'(r_{kj})=dg(r_{kj})/dr_{kj}$ and 
$g''(r_{kj})=d^2g(r_{kj})/dr_{kj}^2$  we find that for particle  $k$
we have
\[
  \frac{\nabla^2_k \Psi_C}{\Psi_C }=
\sum_{ij\ne k}\frac{(\bm{r}_k-\bm{r}_i)(\bm{r}_k-\bm{r}_j)}{r_{ki}r_{kj}}\frac{a}{(1+\beta r_{ki})^2}
\frac{a}{(1+\beta r_{kj})^2}+
\sum_{j\ne k}\left(\frac{2a}{r_{kj}(1+\beta r_{kj})^2}-\frac{2a\beta}{(1+\beta r_{kj})^3}\right)
\]
}

}


{
  ===== Important feature}


For the correlation part 
\[
\Psi_C=\prod_{i< j}g(r_{ij})= \exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\]
we need to take into account whether electrons have equal or opposite spins since we have to obey the
electron-electron cusp condition as well.  
When the electrons have  equal spins 
\[
a= 1/4,
\]
while for opposite spins (like the ground state in Helium)
\[
a= 1/2
\] 
}

}




{
  ===== Slater determinants}



We are now ready to start implementing the coding of the Slater determinant.
The potentially most time-consuming part is the
evaluation of the gradient and the Laplacian of an $N$-particle  Slater
determinant. We have to differentiate the determinant with respect to
all spatial coordinates of all particles. A brute force
differentiation would involve $N\cdot d$ evaluations of the entire
determinant which would even worsen the already undesirable time
scaling, making it $Nd\cdot\bigO(N^3)\sim \bigO(d\cdot N^4)$.
This poses serious hindrances to the overall efficiency of our code.

The efficiency can be improved however if we move only one electron at the time.
The Slater determinant matrix $\matr D$ is defined by the matrix elements
\be
d_{ij}\equiv\phi_j(x_i)
\ee
where $\phi_j(\mathbf{r}_i)$ is a single particle  wave function.
The columns correspond to the position of a given particle 
while the rows stand for the various quantum numbers.
}

}


{
  ===== Slater determinants}


What we need to realize is that when differentiating a Slater
determinant with respect to some given coordinate, only one row of the
corresponding Slater matrix is changed. Therefore, by recalculating
the whole determinant we risk producing redundant information. The
solution turns out to be an algorithm that requires to keep track of
the \emph{inverse} of the Slater matrix.

Let the
current position in phase space be represented by the $(N\cdot
d)$-element vector $\mathbf{r}^{\mathrm{old}}$ and the new suggested
position by the vector $\mathbf{r}^{\mathrm{new}}$.


The inverse of $\matr D$ can be expressed in terms of its
cofactors $C_{ij}$ and its determinant $\det{\matr D}$:
\be
d_{ij}^{-1} = \frac{C_{ji}}{\det{\matr D}}
label{eq:inverse_cofactor}
\ee
Notice that the interchanged indices indicate that the matrix of
cofactors is to be transposed.
}

}


{
  ===== Slater determinants}


If $\matr D$ is invertible, then we must obviously have $\matr
D^{-1}\matr D= \bm{1}$, or explicitly in terms of the individual
elements of $\matr D$ and $\matr D^{-1}$:
\be
\sum_{k=1}^N d_{ik}^{\phantom X}d_{kj}^{-1} = \delta_{ij}^{\phantom X}
label{eq:unity_explicitely}
\ee
Consider the ratio, which we shall call $R$, between $\det{\matr
  D(\mathbf{r}^{\mathrm{new}})}$ and $\det{\matr D(\mathbf{r}^{\mathrm{old}})}$. 
By definition, each of these determinants can
individually be expressed in terms of the $i$th row of its cofactor
matrix
\be
R\equiv\frac{\det{\matr D(\mathbf{r}^{\mathrm{new}})}}
{\det{\matr D(\mathbf{r}^{\mathrm{old}})}} =
\frac{\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{new}})\,
C_{ij}(\mathbf{r}^{\mathrm{new}})}
{\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{old}})\,
C_{ij}(\mathbf{r}^{\mathrm{old}})}
label{eq:detratio_cofactors}
\ee
}

}


{
  ===== Slater determinants}


Suppose now that we move only one particle  at a time, meaning that
$\mathbf{r}^{\mathrm{new}}$ differs from $\mathbf{r}^{\mathrm{old}}$ by the
position of only one, say the $i$th, particle . This means that $\matr
D(\mathbf{r}^{\mathrm{new}})$ and $\matr D(\mathbf{r}^{\mathrm{old}})$ differ
only by the entries of the $i$th row.  Recall also that the $i$th row
of a cofactor matrix $\matr C$ is independent of the entries of the
$i$th row of its corresponding matrix $\matr D$. In this particular
case we therefore get that the $i$th row of $\matr C(\mathbf{r}^{\mathrm{new}})$ 
and $\matr C(\mathbf{r}^{\mathrm{old}})$ must be
equal. Explicitly, we have:
\be
C_{ij}(\mathbf{r}^{\mathrm{new}}) = C_{ij}(\mathbf{r}^{\mathrm{old}})\quad
\forall\ j\in\{1,\dots,N\}
\ee
}

}


{
  ===== Slater determinants}


Inserting this into the numerator of eq.~(ref{eq:detratio_cofactors})
and using eq.~(ref{eq:inverse_cofactor}) to substitute the cofactors
with the elements of the inverse matrix, we get:
\be
%\frac{\det{\matr D(\mathbf{r}^{\mathrm{new}})}}
%{\det{\matr D(\mathbf{r}^{\mathrm{old}})}}
R =
\frac{\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{new}})\,
C_{ij}(\mathbf{r}^{\mathrm{old}})}
{\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{old}})\,
C_{ij}(\mathbf{r}^{\mathrm{old}})} =
\frac{\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{new}})\,
d_{ji}^{-1}(\mathbf{r}^{\mathrm{old}})}
{\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{old}})\,
d_{ji}^{-1}(\mathbf{r}^{\mathrm{old}})}
\ee
}

}


{
  ===== Slater determinants}


Now by eq.~(ref{eq:unity_explicitely}) the denominator of the rightmost
expression must be unity, so that we finally arrive at:
\be
R =
%\frac{\det{\matr D(\mathbf{r}^{\mathrm{new}})}}
%{\det{\matr D(\mathbf{r}^{\mathrm{old}})}} =
\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{new}})\,
d_{ji}^{-1}(\mathbf{r}^{\mathrm{old}}) = 
\sum_{j=1}^N \phi_j(\mathbf{r}_i^{\mathrm{new}})\,
d_{ji}^{-1}(\mathbf{r}^{\mathrm{old}})
label{eq:detratio_inverse}
\ee
What this means is that in order to get the ratio when only the $i$th
particle  has been moved, we only need to calculate the dot
product of the vector $\left(\phi_1(\mathbf{r}_i^\mathrm{new}),\,\dots,\,
\phi_N(\mathbf{r}_i^\mathrm{new})\right)$ of single particle  wave functions
evaluated at this new position with the $i$th column of the inverse
matrix $\matr D^{-1}$ evaluated at the original position. Such
an operation has a time scaling of $\bigO(N)$. The only extra thing we
need to do is to maintain the inverse matrix $\matr D^{-1}(\vec
x^{\mathrm{old}})$.
}

}


{
  ===== Slater determinants}


If the new position $\mathbf{r}^{\mathrm{new}}$ is accepted, then the
inverse matrix can by suitably updated by an algorithm having a time
scaling of $\bigO(N^2)$.  This algorithm goes as
follows. First we update all but the $i$th column of $\matr
D^{-1}$. For each column $j\neq i$, we first calculate the quantity:
\be
S_j =
(\matr D(\mathbf{r}^{\mathrm{new}})\times
\matr D^{-1}(\mathbf{r}^{\mathrm{old}}))_{ij} =
\sum_{l=1}^N d_{il}(\mathbf{r}^{\mathrm{new}})\,
d^{-1}_{lj}(\mathbf{r}^{\mathrm{old}})
label{eq:inverse_update_1}
\ee
The new elements of the $j$th column of $\matr D^{-1}$ are then given
by:
\be
d_{kj}^{-1}(\mathbf{r}^{\mathrm{new}}) =
d_{kj}^{-1}(\mathbf{r}^{\mathrm{old}}) -
\frac{S_j}{R}\,d_{ki}^{-1}(\mathbf{r}^{\mathrm{old}})\quad
\begin{array}{ll}
\forall\ \ k\in\{1,\dots,N\}\\j\neq i
\end{array}
label{eq:inverse_update_2}
\ee
}

}


{
  ===== Slater determinants}


Finally the elements of the $i$th column of $\matr D^{-1}$ are updated
simply as follows:
\be
d_{ki}^{-1}(\mathbf{r}^{\mathrm{new}}) =
\frac{1}{R}\,d_{ki}^{-1}(\mathbf{r}^{\mathrm{old}})\quad
\forall\ \ k\in\{1,\dots,N\}
label{eq:inverse_update_3}
\ee
We see from these formulas that the time scaling of an update of
$\matr D^{-1}$ after changing one row of $\matr D$ is $\bigO(N^2)$.
}

}



{
  ===== Slater determinants}


The scheme is also applicable for the calculation of the ratios
involving derivatives. It turns
out that differentiating the Slater determinant with respect
to the coordinates of a single particle  $\mathbf{r}_i$ changes only the
$i$th row of the corresponding Slater matrix. 
}

}





{
  ===== Slater determinants}


The gradient and
Laplacian can therefore be calculated as follows:
\be
\frac{\vec\nabla_i\det{\matr D(\mathbf{r})}}
{\det{\matr D(\mathbf{r})}} =
\sum_{j=1}^N \vec\nabla_i d_{ij}(\mathbf{r})\,
d_{ji}^{-1}(\mathbf{r}) =
\sum_{j=1}^N \vec\nabla_i \phi_j(\mathbf{r}_i)\,
d_{ji}^{-1}(\mathbf{r})
\ee
and
\be
\frac{\nabla^2_i\det{\matr D(\mathbf{r})}}
{\det{\matr D(\mathbf{r})}} =
\sum_{j=1}^N \nabla^2_i d_{ij}(\mathbf{r})\,
d_{ji}^{-1}(\mathbf{r}) =
\sum_{j=1}^N \nabla^2_i \phi_j(\mathbf{r}_i)\,
d_{ji}^{-1}(\mathbf{r})
\ee
}

}


{
  ===== Slater determinants}


Thus, to calculate all the derivatives of the Slater determinant, we
only need the derivatives of the single particle  wave functions
($\vec\nabla_i \phi_j(\mathbf{r}_i)$ and $\nabla^2_i \phi_j(\mathbf{r}_i)$)
and the elements of the corresponding inverse Slater matrix ($\matr
D^{-1}(\mathbf{r}_i)$). A calculation of a single derivative is by the
above result an $\bigO(N)$ operation. Since there are $d\cdot N$
derivatives, the time scaling of the total evaluation becomes
$\bigO(d\cdot N^2)$. With an $\bigO(N^2)$ updating algorithm for the
inverse matrix, the total scaling is no worse, which is far better
than the brute force approach yielding $\bigO(d\cdot N^4)$.\newline
\bm{Important note:} In most cases you end with closed form expressions for the single-particle  wave functions. It is then useful to calculate the various derivatives and make separate functions
for them.

}

}

[containsverbatim]
{
  ===== Slater determinant: Explicit expressions for various Atoms, beryllium}


The Slater determinant takes the form  
\[
   \Phi(\bm{r}_1,\bm{r}_2,,\bm{r}_3,\bm{r}_4, \alpha,\beta,\gamma,\delta)=\frac{1}{\sqrt{4!}}
\left| \begin{array}{cccc} \psi_{100\uparrow}(\bm{r}_1)& \psi_{100\uparrow}(\bm{r}_2)& \psi_{100\uparrow}(\bm{r}_3)&\psi_{100\uparrow}(\bm{r}_4) \\
\psi_{100\downarrow}(\bm{r}_1)& \psi_{100\downarrow}(\bm{r}_2)& \psi_{100\downarrow}(\bm{r}_3)&\psi_{100\downarrow}(\bm{r}_4) \\
\psi_{200\uparrow}(\bm{r}_1)& \psi_{200\uparrow}(\bm{r}_2)& \psi_{200\uparrow}(\bm{r}_3)&\psi_{200\uparrow}(\bm{r}_4) \\
\psi_{200\downarrow}(\bm{r}_1)& \psi_{200\downarrow}(\bm{r}_2)& \psi_{200\downarrow}(\bm{r}_3)&\psi_{200\downarrow}(\bm{r}_4) \end{array} \right|.
\]

The Slater determinant as written is zero since the spatial wave functions for the spin up and spin down 
states are equal.  
But we can rewrite it as the product of two Slater determinants, one for spin up and one for spin down.
 }
 
 }



[containsverbatim]
{
  ===== Slater determinant: Explicit expressions for various Atoms, beryllium}


We can rewrite it as 
\[
   \Phi(\bm{r}_1,\bm{r}_2,,\bm{r}_3,\bm{r}_4, \alpha,\beta,\gamma,\delta)=Det\uparrow(1,2)Det\downarrow(3,4)-
Det\uparrow(1,3)Det\downarrow(2,4)
\]
\[
-Det\uparrow(1,4)Det\downarrow(3,2)+Det\uparrow(2,3)Det\downarrow(1,4)-Det\uparrow(2,4)Det\downarrow(1,3)
\]
\[
+Det\uparrow(3,4)Det\downarrow(1,2),
\]
where we have defined
\[
Det\uparrow(1,2)=\frac{1}{\sqrt{2}}\left| \begin{array}{cc} \psi_{100\uparrow}(\bm{r}_1)& \psi_{100\uparrow}(\bm{r}_2)\\
\psi_{200\uparrow}(\bm{r}_1)& \psi_{200\uparrow}(\bm{r}_2) \end{array} \right|,
\]
and 
\[
Det\downarrow(3,4)=\frac{1}{\sqrt{2}}\left| \begin{array}{cc} \psi_{100\downarrow}(\bm{r}_3)& \psi_{100\downarrow}(\bm{r}_4)\\
\psi_{200\downarrow}(\bm{r}_3)& \psi_{200\downarrow}(\bm{r}_4) \end{array} \right|.
\]

The total determinant is still zero!
 }
 
 }



[containsverbatim]
{
  ===== Slater determinant: Explicit expressions for various Atoms, beryllium}



We want to avoid to sum over spin variables, in particular when the interaction does not depend on spin.

It can be shown, see for example Moskowitz and Kalos, Int.~J.~Quantum Chem.~\bm{20} (1981) 1107, that for the variational energy
we can approximate the Slater determinant as  
\[
   \Phi(\bm{r}_1,\bm{r}_2,,\bm{r}_3,\bm{r}_4, \alpha,\beta,\gamma,\delta) \propto Det\uparrow(1,2)Det\downarrow(3,4),
\]
or more generally as 
\[
   \Phi(\bm{r}_1,\bm{r}_2,\dots \bm{r}_N) \propto Det\uparrow Det\downarrow,
\]
where we have the Slater determinant as the product of a spin up part involving the number of electrons with spin up only (2 for beryllium and 5 for neon) and a spin down part involving the electrons with spin down.

This ansatz is not antisymmetric under the exchange of electrons with  opposite spins but it can be shown that it gives the same
expectation value for the energy as the full Slater determinant.

As long as the Hamiltonian is spin independent, the above is correct. It is rather straightforward to see this if you go back to the equations for the energy discussed earlier today.
 }
 
 }




{
  ===== Slater determinants}


We will thus
factorize the full determinant $\det{\matr D}$ into two smaller ones, where 
each can be identified with $\uparrow$ and $\downarrow$
respectively:
\be
\det{\matr D} = \det{\matr D}_\uparrow\cdot\det{\matr D}_\downarrow
\ee
The combined dimensionality of the two smaller determinants equals the
dimensionality of the full determinant. Such a factorization is
advantageous in that it makes it possible to perform the calculation
of the ratio $R$ and the updating of the inverse matrix separately for
$\det{\matr D}_\uparrow$ and $\det{\matr D}_\downarrow$:
\be
\frac{\det{\matr D}^\mathrm{new}}{\det{\matr D}^\mathrm{old}} =
\frac{\det{\matr D}^\mathrm{new}_\uparrow}
{\det{\matr D}^\mathrm{old}_\uparrow}\cdot
\frac{\det{\matr D}^\mathrm{new}_\downarrow
}{\det{\matr D}^\mathrm{old}_\downarrow}
\ee
}

}


{
  ===== Slater determinants}


This reduces the calculation time by a constant factor. The maximal
time reduction happens in a system of equal numbers of $\uparrow$ and
$\downarrow$ particles, so that the two factorized determinants are
half the size of the original one.


Consider the case of moving only one particle  at a time which
originally had the following time scaling for one transition:
\be
\bigO_R(N)+\bigO_\mathrm{inverse}(N^2)
\ee
For the factorized determinants one of the two determinants is
obviously unaffected by the change so that it cancels from the ratio
$R$. 
}

}


{
  ===== Slater determinants}


Therefore, only one determinant of size $N/2$ is involved in each
calculation of $R$ and update of the inverse matrix. The scaling of
each transition then becomes:
\be
\bigO_R(N/2)+\bigO_\mathrm{inverse}(N^2/4)
\ee
and the time scaling when the transitions for all $N$ particles are
put together:
\be
\bigO_R(N^2/2)+\bigO_\mathrm{inverse}(N^3/4)
\ee
which gives the same reduction as in the case of moving all particles
at once.
}

}



{
  ===== Updating the Slater matrix}


Computing the ratios discussed above requires that we maintain 
the inverse of the Slater matrix evaluated at the current position. 
Each time a trial position is accepted, the row number $i$ of the Slater 
matrix changes and updating its inverse has to be carried out. 
Getting the inverse of an $N \times N$ matrix by Gaussian elimination has a 
complexity of order of $\mathcal{O}(N^3)$ operations, a luxury that we 
cannot afford for each time a particle  move is accepted.
We will use the expression
\begin{eqnarray}label{updatingInverse}
\boxed{d^{-1}_{kj}(\bfv{x^{new}})  = \left\{ 
\begin{array}{l l}
  d^{-1}_{kj}(\bfv{x^{old}}) - \frac{d^{-1}_{ki}(\bfv{x^{old}})}{R} \sum_{l=1}^{N} d_{il}(\bfv{x^{new}})  d^{-1}_{lj}(\bfv{x^{old}}) & \mbox{if $j \neq i$}\nonumber \\ \\
 \frac{d^{-1}_{ki}(\bfv{x^{old}})}{R} \sum_{l=1}^{N} d_{il}(\bfv{x^{old}}) d^{-1}_{lj}(\bfv{x^{old}}) & \mbox{if $j=i$}
\end{array} \right.}\\
\end{eqnarray}
}

}



{
  ===== Updating the Slater matrix}


This equation scales as $O(N^2)$.
The evaluation of the determinant of an $N \times N$ matrix by standard Gaussian elimination requires ${\cal O}(N^3)$
calculations. 
As there are $Nd$ independent coordinates we need to evaluate $Nd$ Slater determinants 
for the gradient (quantum force) and $Nd$ for the Laplacian (kinetic energy). 
With the updating algorithm we need only to invert the Slater 
determinant matrix once. This can be done by standard LU decomposition methods.\\

}

}






{
  ===== Slater Determinant and  VMC}



Determining a determinant of an $N \times N$ matrix by
standard Gaussian elimination is of the order of ${\cal O}(N^3)$
calculations. As there are $N\cdot d$ independent coordinates we need
to evaluate $Nd$ Slater determinants for the gradient (quantum force) and
$N\cdot d$ for the Laplacian (kinetic energy)

With the updating algorithm we need only to invert the Slater determinant matrix once.
This is done by calling standard LU decomposition methods.
}

}






{
  ===== How to compute the Slater Determinant}


If you choose to implement the above recipe for the computation of the Slater determinant,
you need to LU decompose the Slater matrix. This is described in chapter 6 of the lecture notes from 2012.

You need to call the function ludcmp in lib.cpp.
You need to transfer the Slater matrix and its dimension. You get back an LU decomposed matrix.
}

}


{
  ===== LU Decomposition}


The LU decomposition method means that we can rewrite
this matrix as the product of two matrices $\bm{B}$ and $\bm{C}$
where 
\[
label{eq3}
   \left(\begin{array}{cccc}
                          a_{11} & a_{12} & a_{13} & a_{14} \\
                          a_{21} & a_{22} & a_{23} & a_{24} \\
                          a_{31} & a_{32} & a_{33} & a_{34} \\
                          a_{41} & a_{42} & a_{43} & a_{44} 
                      \end{array} \right)
                      = \left( \begin{array}{cccc}
                              1  & 0      & 0      & 0 \\
                          b_{21} & 1      & 0      & 0 \\
                          b_{31} & b_{32} & 1      & 0 \\
                          b_{41} & b_{42} & b_{43} & 1 
                      \end{array} \right) 
                        \left( \begin{array}{cccc}
                          c_{11} & c_{12} & c_{13} & c_{14} \\
                               0 & c_{22} & c_{23} & c_{24} \\
                               0 & 0      & c_{33} & c_{34} \\
                               0 & 0      &  0     & c_{44} 
             \end{array} \right).
\]
The matrix $\bm{A}\in \mathbb{R}^{n\times n}$ has an LU factorization if the determinant 
is different from zero. If the LU factorization exists and $\bm{A}$ is non-singular, then the LU factorization
is unique and the determinant is given by 
\[
det\{\bm{A}\}
  = c_{11}c_{22}\dots c_{nn}.
\]
}

}

[containsverbatim]
{
  ===== How should we structure our code?}
What do you think is reasonable to split into subtasks defined by classes?

*  Single-particle  wave functions?
*  External potentials?
*  Operations on $r_{ij}$ and the correlation function?
*  Mathematical operations like the first and second derivative of the
trial wave function? How can you split the derivatives into various subtasks?
*  Matrix and vector operations? 

Your task is to figure out how to structure your code in order
to compute the Slater determinant for beryllium. Do not include the correlation factor in the first attempt nor the electron-electron repulsion. You should also hard-code the $2\times 2$ determinant as that serves as a simple test. 
}



 {
   ===== Efficient calculations of wave function ratios}
 
 

The expectation value of the kinetic energy expressed in atomic units for electron $i$ is 
\begin{equation}
 \langle \Op{K}_i \rangle = -\frac{1}{2}\frac{\langle\Psi|\nabla_{i}^2|\Psi \rangle}{\langle\Psi|\Psi \rangle},
\end{equation}

\begin{equation}label{kineticE}
K_i = -\frac{1}{2}\frac{\nabla_{i}^{2} \Psi}{\Psi}.
\end{equation}
\begin{eqnarray}
\frac{\nabla^2 \Psi}{\Psi} & = & \frac{\nabla^2 ({\Psi_{D} \,  \Psi_C})}{\Psi_{D} \,  \Psi_C} = \frac{\Grad \cdot [\Grad {(\Psi_{D} \,  \Psi_C)}]}{\Psi_{D} \,  \Psi_C} = \frac{\Grad \cdot [ \Psi_C \Grad \Psi_{D} + \Psi_{D} \Grad  \Psi_C]}{\Psi_{D} \,  \Psi_C}\nonumber\\
&  = & \frac{\Grad  \Psi_C \cdot \Grad \Psi_{D} +  \Psi_C \nabla^2 \Psi_{D} + \Grad \Psi_{D} \cdot \Grad  \Psi_C + \Psi_{D} \nabla^2  \Psi_C}{\Psi_{D} \,  \Psi_C}\nonumber\\
\end{eqnarray}
\begin{eqnarray}
\frac{\nabla^2 \Psi}{\Psi}
& = & \frac{\nabla^2 \Psi_{D}}{\Psi_{D}} + \frac{\nabla^2  \Psi_C}{ \Psi_C} + 2 \frac{\Grad \Psi_{D}}{\Psi_{D}}\cdot\frac{\Grad  \Psi_C}{ \Psi_C}
\end{eqnarray}
 }
 
 }



{
  ===== Summing up: Bringing it all together, Local energy}



The second derivative of the Jastrow factor divided by the Jastrow factor (the way it enters the kinetic energy) is
\[
\left[\frac{\nabla^2 \Psi_C}{\Psi_C}\right]_x =\  
2\sum_{k=1}^{N}
\sum_{i=1}^{k-1}\frac{\partial^2 g_{ik}}{\partial x_k^2}\ +\ 
\sum_{k=1}^N
\left(
\sum_{i=1}^{k-1}\frac{\partial g_{ik}}{\partial x_k} -
\sum_{i=k+1}^{N}\frac{\partial g_{ki}}{\partial x_i}
\right)^2
\]
But we have a simple form for the function, namely
\[
\Psi_{C}=\prod_{i< j}\exp{f(r_{ij})}= \exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\]
and it is easy to see that for particle  $k$
we have
\[
  \frac{\nabla^2_k \Psi_C}{\Psi_C }=
\sum_{ij\ne k}\frac{(\bm{r}_k-\bm{r}_i)(\bm{r}_k-\bm{r}_j)}{r_{ki}r_{kj}}f'(r_{ki})f'(r_{kj})+
\sum_{j\ne k}\left( f''(r_{kj})+\frac{2}{r_{kj}}f'(r_{kj})\right)
\]
}

}




{
  ===== Bringing it all together, Local energy}


Using 
\[
f(r_{ij})= \frac{ar_{ij}}{1+\beta r_{ij}},
\]
and $g'(r_{kj})=dg(r_{kj})/dr_{kj}$ and 
$g''(r_{kj})=d^2g(r_{kj})/dr_{kj}^2$  we find that for particle  $k$
we have
\[
  \frac{\nabla^2_k \Psi_C}{\Psi_C }=
\sum_{ij\ne k}\frac{(\bm{r}_k-\bm{r}_i)(\bm{r}_k-\bm{r}_j)}{r_{ki}r_{kj}}\frac{a}{(1+\beta r_{ki})^2}
\frac{a}{(1+\beta r_{kj})^2}+
\sum_{j\ne k}\left(\frac{2a}{r_{kj}(1+\beta r_{kj})^2}-\frac{2a\beta}{(1+\beta r_{kj})^3}\right)
\]
}

}


{
  ===== Local energy}


The gradient and
Laplacian can be calculated as follows:
\[
\frac{\vec\nabla_i\det{\matr D(\mathbf{r})}}
{\det{\matr D(\mathbf{r})}} =
\sum_{j=1}^N \vec\nabla_i d_{ij}(\mathbf{r})\,
d_{ji}^{-1}(\mathbf{r}) =
\sum_{j=1}^N \vec\nabla_i \phi_j(\mathbf{r}_i)\,
d_{ji}^{-1}(\mathbf{r})
\]
and
\[
\frac{\nabla^2_i\det{\matr D(\mathbf{r})}}
{\det{\matr D(\mathbf{r})}} =
\sum_{j=1}^N \nabla^2_i d_{ij}(\mathbf{r})\,
d_{ji}^{-1}(\mathbf{r}) =
\sum_{j=1}^N \nabla^2_i \phi_j(\mathbf{r}_i)\,
d_{ji}^{-1}(\mathbf{r})
\]
}

}




{
  ===== Determinant part in quantum force}


The gradient for the determinant is 
\[
\frac{\vec\nabla_i\det{\matr D(\mathbf{r})}}
{\det{\matr D(\mathbf{r})}} =
\sum_{j=1}^N \vec\nabla_i d_{ij}(\mathbf{r})\,
d_{ji}^{-1}(\mathbf{r}) =
\sum_{j=1}^N \vec\nabla_i \phi_j(\mathbf{r}_i)\,
d_{ji}^{-1}(\mathbf{r}).
\]
}

}



{
  ===== Jastrow gradient in quantum force}


We have
\[
\Psi_C=\prod_{i< j}g(r_{ij})= \exp{\left\{\sum_{i<j}\frac{ar_{ij}}{1+\beta r_{ij}}\right\}},
\]
the gradient needed for the quantum force and local energy is easy to compute.  
We get for particle  $k$
\[
\frac{ \nabla_k \Psi_C}{ \Psi_C }= \sum_{j\ne k}\frac{\bm{r}_{kj}}{r_{kj}}\frac{a}{(1+\beta r_{kj})^2},
\]
which is rather easy to code.  Remember to sum over all particles  when you compute the local energy.
}

}

{
  ===== Metropolis Hastings part}



We need to compute the ratio between wave functions, in particular  for the Slater determinants.
\[
R =
%\frac{\det{\matr D(\mathbf{r}^{\mathrm{new}})}}
%{\det{\matr D(\mathbf{r}^{\mathrm{old}})}} =
\sum_{j=1}^N d_{ij}(\mathbf{r}^{\mathrm{new}})\,
d_{ji}^{-1}(\mathbf{r}^{\mathrm{old}}) = 
\sum_{j=1}^N \phi_j(\mathbf{r}_i^{\mathrm{new}})\,
d_{ji}^{-1}(\mathbf{r}^{\mathrm{old}})
\]
What this means is that in order to get the ratio when only the $i$th
particle  has been moved, we only need to calculate the dot
product of the vector $\left(\phi_1(\mathbf{r}_i^\mathrm{new}),\,\dots,\,
\phi_N(\mathbf{r}_i^\mathrm{new})\right)$ of single particle  wave functions
evaluated at this new position with the $i$th column of the inverse
matrix $\matr D^{-1}$ evaluated at the original position. Such
an operation has a time scaling of $\bigO(N)$. The only extra thing we
need to do is to maintain the inverse matrix $\matr D^{-1}(\vec
x^{\mathrm{old}})$.
}

}




 {
   ===== Jastrow factor in Metropolis Hastings}
 
 
We have
\begin{equation}
 \boxed{R_{C} = \frac{\Psi_{C}^\mathrm{new}}{\Psi_{C}^\mathrm{cur}} = \frac{e^{U_{new}}}{e^{U_{cur}}} = e^{\Delta U},}
\end{equation}
where
\begin{equation}
\Delta U =
\sum_{i=1}^{k-1}\big(f_{ik}^\mathrm{new}-f_{ik}^\mathrm{cur}\big)
+
\sum_{i=k+1}^{N}\big(f_{ki}^\mathrm{new}-f_{ki}^\mathrm{cur}\big)
\end{equation}
One needs to develop a special algorithm 
that runs only through the elements of the upper triangular
matrix $\bfv{g}$ and have $k$ as an index. 

 }
 
 }


{
  ===== Topics for Week 10, March 4-8}
  \begin{block}{Slater determinants for systems with more than two particles}

*  Repetition from last time, discusssion of Slater determinants
*  Treatment of statistical data, blocking as a simple way to extract the standard deviation
*  Find minima in multivariable spaces, begin discussion of the Conjugate Gradient method

Project work this week: Finalize the Slater determinant part and include blocking. Start thinking of applying the conjugate gradient method. For a proof of blocking, partly to be discussed later this week, see the article of 
H.~Flyvbjerg and H.~G.~Petersen, {\em Error estimates on averages of correlated data},  The Journal of Chemical Physics _91_, 461-466 (1989).
For next week: Read this article and look at the first simple example. Look  also through chapters 10.2-10.7 of Numerical recipes on the conjugate gradient method and related methods.
  \end{block}
} 

[containsverbatim]
{
  ===== Useful equations}


The $1s$ hydrogen like wave function
\[
R_{10}(r) =  2\left(\frac{Z}{a_0}\right)^{3/2}\exp{(-Zr/a_0)}= u_{10}/r 
\]
The total energy for helium (not the Hartree or Fock terms) from  the direct and the exchange term should give $5Z/8$.

The single-particle energy with no interactions should give $-Z^2/2n^2$. 

The $2s$ hydrogen-like wave function is
\[
R_{20}(r) =  2\left(\frac{Z}{2a_0}\right)^{3/2}\left(1-\frac{Zr}{2a_0}\right)\exp{(-Zr/2a_0)}= u_{20}/r 
\]
and the $2p$ hydrogen -like wave function is
\[
R_{21}(r) =  \frac{1}{\sqrt{3}}\left(\frac{Z}{2a_0}\right)^{3/2}\frac{Zr}{a_0}\exp{(-Zr/2a_0)}= u_{21}/r 
\]
We use $a_0=1$.
 }
 
 }




{
  ===== Problems with neon for VMC}


In the standard textbook case one uses spherical coordinates  in order to get the hydrogen-like wave functions
     \[
        x=rsin\theta cos\phi,  
      \]
      \[
        y=rsin\theta sin\phi,
     \]
and
     \[
        z=rcos\theta.
     \]
The reason we introduce spherical coordinates is the spherical symmetry of the Coulomb potential
\[
    \frac{e^2}{4\pi\epsilon_0r}=\frac{e^2}{4\pi\epsilon_0\sqrt{x^2+y^2+z^2}},
\]
where we have used $r=\sqrt{x^2+y^2+z^2}$. 
It is not possible to find a separable solution of the type
\[
    \psi(x,y,z)=\psi(x)\psi(y)\psi(z).
\]
However, with spherical coordinates we can find a solution
of the form
\[
   \psi(r,\theta,\phi)=R(r)P(\theta)F(\phi).
\]
}

}





{
  ===== Problems with neon for VMC}


The angle-dependent differential equations result in the spherical harmonic functions as
solutions, with quantum numbers $l$ and $m_l$.
These functions are given by
\[
    Y_{lm_l}(\theta,\phi)=P(\theta)F(\phi)=\sqrt{\frac{(2l+1)(l-m_l)!}{4\pi (l+m_l)!}}
                      P_l^{m_l}(cos(\theta))\exp{(im_l\phi)},
\]
with $P_l^{m_l}$ being the associated Legendre polynomials
They can be rewritten as 
\[
   Y_{lm_l}(\theta,\phi)=sin^{|m_l|}(\theta) \times (\mathrm{polynom}(cos\theta))\exp{(im_l\phi)},
\]
}

}



{
  ===== Problems with neon for VMC}


We have the following selected examples
\[
   Y_{00}=\sqrt{\frac{1}{4\pi}},
\]
for $l=m_l=0$, 
\[
   Y_{10}=\sqrt{\frac{3}{4\pi}}cos(\theta),
\]
for $l=1$ og $m_l=0$, 
\[
   Y_{1\pm 1}=\sqrt{\frac{3}{8\pi}}sin(\theta)exp(\pm i\phi),
\]
for  $l=1$ og $m_l=\pm 1$. 
}

}




{
  ===== Problems with neon for VMC}


A problem with the spherical harmonics is that they are complex. The introduction of
\emph{solid harmonics} allows the use
of real orbital wave-functions for a wide range of applications. The
complex solid harmonics ${\cal Y}_{lm_l}(\mathbf{r})$ are related to
the spherical harmonics  $Y_{lm_l}(\mathbf{r})$ through
\begin{equation*}
  {\cal Y}_{lm_l}(\mathbf{r}) = r^l Y_{lm_l}(\mathbf{r}).
\end{equation*}
By factoring out the leading $r$-dependency of the radial-function
\begin{equation*}
  {\cal R}_{nl}(\mathbf{r}) = r^{-l} R_{nl}(\mathbf{r}),
\end{equation*}
we obtain 
\begin{equation*}
  \Psi_{nlm_l}(r,\theta, \phi) %=R_{nl}(r) \cdot Y_{lm_l}(\theta,\phi)
  = {\cal R}_{nl}(\mathbf{r})\cdot{\cal Y}_{lm_l}(\mathbf{r}).
%label{totalSolidHydrogenWavefunction}
\end{equation*}
}

}











{
  ===== Problems with neon for VMC}


For the theoretical development of the \emph{real solid harmonics} we first 
express the complex solid harmonics, $C_{lm_l}$, by (complex) Cartesian
coordinates, and arrive at the real solid harmonics, $S_{lm_l}$, through
the unitary transformation
\begin{equation*}
  \left( \begin{split} &\phantom{i} S_{lm_l} \\ 
    &S_{l,-m_l} \end{split} \right) 
  = \frac{1}{\sqrt{2}} \left(        \begin{split}
    (-1)^m_l \phantom{a} & \phantom{aa} 1 \\ 
    -(-1)^m_l i & \phantom{aa} i       \end{split} \right)  
  \left( \begin{split} &\phantom{i} C_{lm_l} \\ 
    &C_{l,-m_l} \end{split} \right).
\end{equation*}
}

}




{
  ===== Problems with neon for VMC}


This transformation will not alter any physical quantities that are
degenerate in the subspace consisting of opposite magnetic quantum
numbers (the angular momentum $l$ is equal for both these cases). This
means for example that the above transformation does not alter the
energies, unless an external magnetic field is applied to the
system. Henceforth, we will use the solid harmonics, and note that
changing the spherical potential beyond the Coulomb potential will not
alter the solid harmonics.
}

}




{
  ===== Problems with neon for VMC}


We have defined 
\begin{equation*}
  {\cal Y}_{lm_l}(\mathbf{r}) = r^l Y_{lm_l}(\mathbf{r}).
\end{equation*}
The real-valued spherical harmonics are defined as
\[
S_{l0} =  \sqrt{\frac{4\pi}{2l+1}} {\cal Y}_{l0}(\mathbf{r}),
\]
\[
S_{lm_l} =  (-1)^{m_l}\sqrt{\frac{8\pi}{2l+1}} \mathrm{Re}{\cal Y}_{l0}(\mathbf{r}),
\]

\[
S_{lm_l} =  (-1)^{m_l}\sqrt{\frac{8\pi}{2l+1}} \mathrm{Im}{\cal Y}_{l0}(\mathbf{r}),
\]
for $m_l> 0$.

}

}





{
  ===== Problems with neon for VMC}


 The lowest-order real solid harmonics are
listed in here
\begin{center} {\large \bf Real Solid Harmonics} \\ 
$\phantom{a}$ \\
\begin{tabular}{ccccc}
\hline\\ 
$m_l\backslash l$ & \phantom{AA}0\phantom{AA}
& \phantom{AA}1\phantom{AA} & \phantom{AA}2\phantom{AA} &
\phantom{AA}3\phantom{AA} \\ 
\hline\\ 
+3& & &
&$\frac{1}{2}\sqrt{\frac{5}{2}}(x^2-3y^2)x$ \\ [7pt] 
+2& & &$\frac{1}{2}\sqrt{3}(x^2-y^2)$&$\frac{1}{2}\sqrt{15}(x^2-y^2)z$
\\ [7pt] 
+1& &x&$\sqrt{3}xz$
&$\frac{1}{2}\sqrt{\frac{3}{2}}(5z^2-r^2)x$ \\ [7pt] 
0&1&y&$\frac{1}{2}(3z^2-r^2)$       &$\frac{1}{2}(5z^2-3r^2)x$ \\
 [7pt] 
-1& &z&$\sqrt{3}yz$
&$\frac{1}{2}\sqrt{\frac{3}{2}}(5z^2-r^2)y$ \\ [7pt] 
-2& & &$\sqrt{3}xy$                  &$\sqrt{15}xyz$ \\ [7pt] 
-3& & &
&$\frac{1}{2}\sqrt{\frac{5}{2}}(3x^2-y^2)y$ \\ [7pt] 
\hline
\end{tabular} 
\end{center}

}

}


