%%
%% Automatically generated file from DocOnce source
%% (https://github.com/hplgit/doconce/)
%%
%%


%-------------------- begin preamble ----------------------

\documentclass[%
twoside,                 % oneside: electronic viewing, twoside: printing
final,                   % or draft (marks overfull hboxes, figures with paths)
10pt]{article}

\listfiles               % print all files needed to compile this document

\usepackage{relsize,makeidx,color,setspace,amsmath,amsfonts}
\usepackage[table]{xcolor}
\usepackage{bm,microtype}

\usepackage[T1]{fontenc}
%\usepackage[latin1]{inputenc}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}

\usepackage{lmodern}         % Latin Modern fonts derived from Computer Modern

% Hyperlinks in PDF:
\definecolor{linkcolor}{rgb}{0,0,0.4}
\usepackage{hyperref}
\hypersetup{
    breaklinks=true,
    colorlinks=true,
    linkcolor=linkcolor,
    urlcolor=linkcolor,
    citecolor=black,
    filecolor=black,
    %filecolor=blue,
    pdfmenubar=true,
    pdftoolbar=true,
    bookmarksdepth=3   % Uncomment (and tweak) for PDF bookmarks with more levels than the TOC
    }
%\hyperbaseurl{}   % hyperlinks are relative to this root

\setcounter{tocdepth}{2}  % number chapter, section, subsection

\usepackage[framemethod=TikZ]{mdframed}

% --- begin definitions of admonition environments ---

% --- end of definitions of admonition environments ---

% prevent orhpans and widows
\clubpenalty = 10000
\widowpenalty = 10000

% --- end of standard preamble for documents ---


% insert custom LaTeX commands...

\raggedbottom
\makeindex

%-------------------- end preamble ----------------------

\begin{document}



% ------------------- main content ----------------------



% ----------------- title -------------------------

\thispagestyle{empty}

\begin{center}
{\LARGE\bf
\begin{spacing}{1.25}
Hartree-Fock methods
\end{spacing}
}
\end{center}

% ----------------- author(s) -------------------------

\begin{center}
{\bf Morten Hjorth-Jensen, National Superconducting Cyclotron Laboratory and Department of Physics and Astronomy, Michigan State University, East Lansing, MI 48824, USA {\&} Department of Physics, University of Oslo, Oslo, Norway${}^{}$} \\ [0mm]
\end{center}

    \begin{center}
% List of all institutions:
\end{center}
    
% ----------------- end author(s) -------------------------

\begin{center} % date
Spring 2015
\end{center}

\vspace{1cm}


% !split
\subsection{Why Hartree-Fock? Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
Hartree-Fock (HF) theory is an algorithm for finding an approximative expression for the ground state of a given Hamiltonian. The basic ingredients are
\begin{itemize}
  \item Define a single-particle basis $\{\psi_{\alpha}\}$ so that
\end{itemize}

\noindent
\[ 
\hat{h}^{\mathrm{HF}}\psi_{\alpha} = \varepsilon_{\alpha}\psi_{\alpha}
\]
with the Hartree-Fock Hamiltonian defined as
\[
\hat{h}^{\mathrm{HF}}=\hat{t}+\hat{u}_{\mathrm{ext}}+\hat{u}^{\mathrm{HF}}
\]
\begin{itemize}
  \item The term  $\hat{u}^{\mathrm{HF}}$ is a single-particle potential to be determined by the HF algorithm.

  \item The HF algorithm means to choose $\hat{u}^{\mathrm{HF}}$ in order to have 
\end{itemize}

\noindent
\[ \langle \hat{H} \rangle = E^{\mathrm{HF}}= \langle \Phi_0 | \hat{H}|\Phi_0 \rangle
\]
that is to find a local minimum with a Slater determinant $\Phi_0$ being the ansatz for the ground state. 
\begin{itemize}
  \item The variational principle ensures that $E^{\mathrm{HF}} \ge E_0$, with $E_0$ the exact ground state energy.
\end{itemize}

\noindent
% --- end paragraph admon ---




% !split
\subsection{Why Hartree-Fock? Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
We will show that the Hartree-Fock Hamiltonian $\hat{h}^{\mathrm{HF}}$ equals our definition of the operator $\hat{f}$ discussed in connection with the new definition of the normal-ordered Hamiltonian (see later lectures), that is we have, for a specific matrix element
\[
\langle p |\hat{h}^{\mathrm{HF}}| q \rangle =\langle p |\hat{f}| q \rangle=\langle p|\hat{t}+\hat{u}_{\mathrm{ext}}|q \rangle +\sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS},
\]
meaning that
\[
\langle p|\hat{u}^{\mathrm{HF}}|q\rangle = \sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS}.
\]
The so-called Hartree-Fock potential $\hat{u}^{\mathrm{HF}}$ brings an explicit medium dependence due to the summation over all single-particle states below the Fermi level $F$. It brings also in an explicit dependence on the two-body interaction (in nuclear physics we can also have complicated three- or higher-body forces). The two-body interaction, with its contribution from the other bystanding fermions, creates an effective mean field in which a given fermion moves, in addition to the external potential $\hat{u}_{\mathrm{ext}}$ which confines the motion of the fermion. For systems like nuclei, there is no external confining potential. Nuclei are examples of self-bound systems, where the binding arises due to the intrinsic nature of the strong force. For nuclear systems thus, there would be no external one-body potential in the Hartree-Fock Hamiltonian.
% --- end paragraph admon ---



% !split
\subsection{Variational Calculus and Lagrangian Multipliers}

% --- begin paragraph admon ---
\paragraph{}
The calculus of variations involves 
problems where the quantity to be minimized or maximized is an integral. 

In the general case we have an integral of the type
\[ 
E[\Phi]= \int_a^b f(\Phi(x),\frac{\partial \Phi}{\partial x},x)dx,
\]
where $E$ is the quantity which is sought minimized or maximized.
The problem is that although $f$ is a function of the variables $\Phi$, $\partial \Phi/\partial x$ and $x$, the exact dependence of
$\Phi$ on $x$ is not known.  This means again that even though the integral has fixed limits $a$ and $b$, the path of integration is
not known. In our case the unknown quantities are the single-particle wave functions and we wish to choose an integration path which makes
the functional $E[\Phi]$ stationary. This means that we want to find minima, or maxima or saddle points. In physics we search normally for minima.
Our task is therefore to find the minimum of $E[\Phi]$ so that its variation $\delta E$ is zero  subject to specific
constraints. In our case the constraints appear as the integral which expresses the orthogonality of the  single-particle wave functions.
The constraints can be treated via the technique of Lagrangian multipliers
% --- end paragraph admon ---




% !split
\subsection{Variational Calculus and Lagrangian Multipliers}

% --- begin paragraph admon ---
\paragraph{}
Let us specialize to the expectation value of the energy for one particle in three-dimensions.
This expectation value reads
\[
  E=\int dxdydz \psi^*(x,y,z) \hat{H} \psi(x,y,z),
\]
with the constraint
\[
 \int dxdydz \psi^*(x,y,z) \psi(x,y,z)=1,
\]
and a Hamiltonian
\[
\hat{H}=-\frac{1}{2}\nabla^2+V(x,y,z).
\]
We will, for the sake of notational convenience,  skip the variables $x,y,z$ below, and write for example $V(x,y,z)=V$.
% --- end paragraph admon ---



% !split
\subsection{Variational Calculus and Lagrangian Multipliers}

% --- begin paragraph admon ---
\paragraph{}
The integral involving the kinetic energy can be written as, with the function $\psi$ vanishing
strongly for large values of $x,y,z$ (given here by the limits $a$ and $b$), 
 \[
  \int_a^b dxdydz \psi^* \left(-\frac{1}{2}\nabla^2\right) \psi dxdydz = \psi^*\nabla\psi|_a^b+\int_a^b dxdydz\frac{1}{2}\nabla\psi^*\nabla\psi.
\]
We will drop the limits $a$ and $b$ in the remaining discussion. 
Inserting this expression into the expectation value for the energy and taking the variational minimum  we obtain
\[
\delta E = \delta \left\{\int dxdydz\left( \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi\right)\right\} = 0.
\]
% --- end paragraph admon ---



% !split
\subsection{Variational Calculus and Lagrangian Multipliers}

% --- begin paragraph admon ---
\paragraph{}
The constraint appears in integral form as 
\[
 \int dxdydz \psi^* \psi=\mathrm{constant},
\]
and multiplying with a Lagrangian multiplier $\lambda$ and taking the variational minimum we obtain the final variational equation
\[
\delta \left\{\int dxdydz\left( \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi-\lambda\psi^*\psi\right)\right\} = 0.
\]
We introduce the function  $f$
\[
  f =  \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi-\lambda\psi^*\psi=
\frac{1}{2}(\psi^*_x\psi_x+\psi^*_y\psi_y+\psi^*_z\psi_z)+V\psi^*\psi-\lambda\psi^*\psi,
\]
where we have skipped the dependence on $x,y,z$ and introduced the shorthand $\psi_x$, $\psi_y$ and $\psi_z$  for the various derivatives.
% --- end paragraph admon ---



% !split
\subsection{Variational Calculus and Lagrangian Multipliers}

% --- begin paragraph admon ---
\paragraph{}
For $\psi^*$ the Euler-Lagrange  equations yield
\[
\frac{\partial f}{\partial \psi^*}- \frac{\partial }{\partial x}\frac{\partial f}{\partial \psi^*_x}-\frac{\partial }{\partial y}\frac{\partial f}{\partial \psi^*_y}-\frac{\partial }{\partial z}\frac{\partial f}{\partial \psi^*_z}=0,
\] 
which results in 
\[
    -\frac{1}{2}(\psi_{xx}+\psi_{yy}+\psi_{zz})+V\psi=\lambda \psi.
\]
We can then identify the  Lagrangian multiplier as the energy of the system. The last equation is 
nothing but the standard 
Schroedinger equation and the variational  approach discussed here provides 
a powerful method for obtaining approximate solutions of the wave function.
% --- end paragraph admon ---






% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
Before we proceed we need some definitions.
We will assume that the interacting part of the Hamiltonian
can be approximated by a two-body interaction.
This means that our Hamiltonian is written as the sum of some onebody part and a twobody part
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^N \hat{h}_0(x_i) + \sum_{i < j}^N \hat{v}(r_{ij}),
\label{Hnuclei}
\end{equation}
with 
\begin{equation}
  H_0=\sum_{i=1}^N \hat{h}_0(x_i).
\label{hinuclei}
\end{equation}
The onebody part $u_{\mathrm{ext}}(x_i)$ is normally approximated by a harmonic oscillator potential or the Coulomb interaction an electron feels from the nucleus. However, other potentials are fully possible, such as 
one derived from the self-consistent solution of the Hartree-Fock equations to be discussed here.
% --- end paragraph admon ---




% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
Our Hamiltonian is invariant under the permutation (interchange) of two particles.
Since we deal with fermions however, the total wave function is antisymmetric.
Let $\hat{P}$ be an operator which interchanges two particles.
Due to the symmetries we have ascribed to our Hamiltonian, this operator commutes with the total Hamiltonian,
\[
[\hat{H},\hat{P}] = 0,
 \]
meaning that $\Psi_{\lambda}(x_1, x_2, \dots , x_A)$ is an eigenfunction of 
$\hat{P}$ as well, that is
\[
\hat{P}_{ij}\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A)=
\beta\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A),
\]
where $\beta$ is the eigenvalue of $\hat{P}$. We have introduced the suffix $ij$ in order to indicate that we permute particles $i$ and $j$.
The Pauli principle tells us that the total wave function for a system of fermions
has to be antisymmetric, resulting in the eigenvalue $\beta = -1$.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
In our case we assume that  we can approximate the exact eigenfunction with a Slater determinant
\begin{equation}
   \Phi(x_1, x_2,\dots ,x_A,\alpha,\beta,\dots, \sigma)=\frac{1}{\sqrt{N!}}
\left| \begin{array}{ccccc} \psi_{\alpha}(x_1)& \psi_{\alpha}(x_2)& \dots & \dots & \psi_{\alpha}(x_A)\\
                            \psi_{\beta}(x_1)&\psi_{\beta}(x_2)& \dots & \dots & \psi_{\beta}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{\sigma}(x_1)&\psi_{\sigma}(x_2)& \dots & \dots & \psi_{\sigma}(x_A)\end{array} \right|, \label{eq:HartreeFockDet}
\end{equation}
where  $x_i$  stand for the coordinates and spin values of a particle $i$ and $\alpha,\beta,\dots, \gamma$ 
are quantum numbers needed to describe remaining quantum numbers.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
The single-particle function $\psi_{\alpha}(x_i)$  are eigenfunctions of the onebody
Hamiltonian $h_i$, that is
\[
\hat{h}_0(x_i)=\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i),
\]
with eigenvalues 
\[
\hat{h}_0(x_i) \psi_{\alpha}(x_i)=\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i).
\]
The energies $\varepsilon_{\alpha}$ are the so-called non-interacting single-particle energies, or unperturbed energies. 
The total energy is in this case the sum over all  single-particle energies, if no two-body or more complicated
many-body interactions are present.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
Let us denote the ground state energy by $E_0$. According to the
variational principle we have
\[
  E_0 \le E[\Phi] = \int \Phi^*\hat{H}\Phi d\mathbf{\tau}
\]
where $\Phi$ is a trial function which we assume to be normalized
\[
  \int \Phi^*\Phi d\mathbf{\tau} = 1,
\]
where we have used the shorthand $d\mathbf{\tau}=dx_1dr_2\dots dr_A$.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
In the Hartree-Fock method the trial function is the Slater
determinant of Eq.~(\ref{eq:HartreeFockDet}) which can be rewritten as 
\[
  \Phi(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{N!}}\sum_{P} (-)^P\hat{P}\psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A)=\sqrt{N!}\hat{A}\Phi_H,
\]
where we have introduced the antisymmetrization operator $\hat{A}$ defined by the 
summation over all possible permutations of two particles.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
It is defined as
\begin{equation}
  \hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
\label{antiSymmetryOperator}
\end{equation}
with $p$ standing for the number of permutations. We have introduced for later use the so-called
Hartree-function, defined by the simple product of all possible single-particle functions
\[
  \Phi_H(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) =
  \psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A).
\]
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
Both $\hat{H}_0$ and $\hat{H}_I$ are invariant under all possible permutations of any two particles
and hence commute with $\hat{A}$
\begin{equation}
  [H_0,\hat{A}] = [H_I,\hat{A}] = 0. \label{commutionAntiSym}
\end{equation}
Furthermore, $\hat{A}$ satisfies
\begin{equation}
  \hat{A}^2 = \hat{A},  \label{AntiSymSquared}
\end{equation}
since every permutation of the Slater
determinant reproduces it.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
The expectation value of $\hat{H}_0$ 
\[
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau}
\]
is readily reduced to
\[
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau},
\]
where we have used Eqs.~(\ref{commutionAntiSym}) and
(\ref{AntiSymSquared}). The next step is to replace the antisymmetrization
operator by its definition and to
replace $\hat{H}_0$ with the sum of one-body operators
\[
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{i=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{h}_0\hat{P}\Phi_H d\mathbf{\tau}.
\]
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
The integral vanishes if two or more particles are permuted in only one
of the Hartree-functions $\Phi_H$ because the individual single-particle wave functions are
orthogonal. We obtain then
\[
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}= \sum_{i=1}^N \int \Phi_H^*\hat{h}_0\Phi_H  d\mathbf{\tau}.
\]
Orthogonality of the single-particle functions allows us to further simplify the integral, and we
arrive at the following expression for the expectation values of the
sum of one-body Hamiltonians 
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{\mu=1}^N \int \psi_{\mu}^*(x)\hat{h}_0\psi_{\mu}(x)dx
  d\mathbf{r}.
  \label{H1Expectation}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
We introduce the following shorthand for the above integral
\[
\langle \mu | \hat{h}_0 | \mu \rangle = \int \psi_{\mu}^*(x)\hat{h}_0\psi_{\mu}(x)dx,
\]
and rewrite Eq.~(\ref{H1Expectation}) as
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\tau
  = \sum_{\mu=1}^N \langle \mu | \hat{h}_0 | \mu \rangle.
  \label{H1Expectation1}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
The expectation value of the two-body part of the Hamiltonian is obtained in a
similar manner. We have
\[
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_I\hat{A}\Phi_H d\mathbf{\tau},
\]
which reduces to
\[
 \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i\le j=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{v}(r_{ij})\hat{P}\Phi_H d\mathbf{\tau},
\]
by following the same arguments as for the one-body
Hamiltonian.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
Because of the dependence on the inter-particle distance $r_{ij}$,  permutations of
any two particles no longer vanish, and we get
\[
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i < j=1}^N \int  
  \Phi_H^*\hat{v}(r_{ij})(1-P_{ij})\Phi_H d\mathbf{\tau}.
\]
where $P_{ij}$ is the permutation operator that interchanges
particle $i$ and particle $j$. Again we use the assumption that the single-particle wave functions
are orthogonal.
% --- end paragraph admon ---




% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
We obtain
\begin{equation}
\begin{split}
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N
    &\left[ \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j \right.\\
  &\left.
  - \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j
  \right]. \label{H2Expectation}
\end{split}
\end{equation}
The first term is the so-called direct term. It is frequently also called the  Hartree term, 
while the second is due to the Pauli principle and is called
the exchange term or just the Fock term.
The factor  $1/2$ is introduced because we now run over
all pairs twice.
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
The last equation allows us to  introduce some further definitions.  
The single-particle wave functions $\psi_{\mu}(x)$, defined by the quantum numbers $\mu$ and $x$
are defined as the overlap 
\[
   \psi_{\alpha}(x)  = \langle x | \alpha \rangle .
\]
% --- end paragraph admon ---



% !split
\subsection{Definitions and notations}

% --- begin paragraph admon ---
\paragraph{}
We introduce the following shorthands for the above two integrals
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle =  \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j,
\]
and
\[
\langle \mu\nu|\hat{v}|\nu\mu\rangle = \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j.  
\]
% --- end paragraph admon ---












% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
Let us denote the ground state energy by $E_0$. According to the
variational principle we have
\[
  E_0 \le E[\Phi] = \int \Phi^*\hat{H}\Phi d\mathbf{\tau}
\]
where $\Phi$ is a trial function which we assume to be normalized
\[
  \int \Phi^*\Phi d\mathbf{\tau} = 1,
\]
where we have used the shorthand $d\mathbf{\tau}=dx_1dx_2\dots dx_A$.
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
In the Hartree-Fock method the trial function is a Slater
determinant which can be rewritten as 
\[
  \Psi(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{N!}}\sum_{P} (-)^PP\psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A)=\sqrt{N!}\hat{A}\Phi_H,
\]
where we have introduced the anti-symmetrization operator $\hat{A}$ defined by the 
summation over all possible permutations \emph{p} of two fermions.
It is defined as
\[
  \hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
\]
with the the Hartree-function given by the simple product of all possible single-particle function
\[
  \Phi_H(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) =
  \psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A).
\]
% --- end paragraph admon ---






% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
Our functional is written as
\[
  E[\Phi] = \sum_{\mu=1}^N \int \psi_{\mu}^*(x_i)\hat{h}_0(x_i)\psi_{\mu}(x_i) dx_i 
  + \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N
   \left[ \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)dx_idx_j- \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
 \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)dx_idx_j\right]
\]
The more compact version reads
\[
  E[\Phi] 
  = \sum_{\mu}^N \langle \mu | \hat{h}_0 | \mu\rangle+ \frac{1}{2}\sum_{\mu\nu}^N\left[\langle \mu\nu |\hat{v}|\mu\nu\rangle-\langle \nu\mu |\hat{v}|\mu\nu\rangle\right].
\]
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
Since the interaction is invariant under the interchange of two particles it means for example that we have
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle =  \langle \nu\mu|\hat{v}|\nu\mu\rangle,  
\]
or in the more general case
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle =  \langle \nu\mu|\hat{v}|\tau\sigma\rangle.  
\]
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
The direct and exchange matrix elements can be  brought together if we define the antisymmetrized matrix element
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS}= \langle \mu\nu|\hat{v}|\mu\nu\rangle-\langle \mu\nu|\hat{v}|\nu\mu\rangle,
\]
or for a general matrix element  
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{AS}= \langle \mu\nu|\hat{v}|\sigma\tau\rangle-\langle \mu\nu|\hat{v}|\tau\sigma\rangle.
\]
It has the symmetry property
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{AS}= -\langle \mu\nu|\hat{v}|\tau\sigma\rangle_{AS}=-\langle \nu\mu|\hat{v}|\sigma\tau\rangle_{AS}.
\]
The antisymmetric matrix element is also hermitian, implying 
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{AS}= \langle \sigma\tau|\hat{v}|\mu\nu\rangle_{AS}.
\]
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
With these notations we rewrite the Hartree-Fock functional as
\begin{equation}
  \int \Phi^*\hat{H_I}\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS}. \label{H2Expectation2}
\end{equation}

Adding the contribution from the one-body operator $\hat{H}_0$ to
(\ref{H2Expectation2}) we obtain the energy functional 
\begin{equation}
  E[\Phi] 
  = \sum_{\mu=1}^N \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS}. \label{FunctionalEPhi}
\end{equation}
In our coordinate space derivations below we will spell out the Hartree-Fock equations in terms of their integrals.
% --- end paragraph admon ---




% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
If we generalize the Euler-Lagrange equations to more variables 
and introduce $N^2$ Lagrange multipliers which we denote by 
$\epsilon_{\mu\nu}$, we can write the variational equation for the functional of $E$
\[
  \delta E - \sum_{\mu\nu}^N \epsilon_{\mu\nu} \delta
  \int \psi_{\mu}^* \psi_{\nu} = 0.
\]
For the orthogonal wave functions $\psi_{i}$ this reduces to
\[
  \delta E - \sum_{\mu=1}^N \epsilon_{\mu} \delta
  \int \psi_{\mu}^* \psi_{\mu} = 0.
\]
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
Variation with respect to the single-particle wave functions $\psi_{\mu}$ yields then
\[
  \sum_{\mu=1}^N \int \delta\psi_{\mu}^*\hat{h_0}(x_i)\psi_{\mu}
  dx_i  
  + \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \left[ \int
  \delta\psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\psi_{\mu}\psi_{\nu} dx_idx_j- \int
  \delta\psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\psi_{\nu}\psi_{\mu}
  dx_idx_j \right]+ 
\]
\[
\sum_{\mu=1}^N \int \psi_{\mu}^*\hat{h_0}(x_i)\delta\psi_{\mu}
  dx_i 
  + \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \left[ \int
  \psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\delta\psi_{\mu}\psi_{\nu} dx_idx_j- \int
  \psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\psi_{\nu}\delta\psi_{\mu}
  dx_idx_j \right]-  \sum_{{\mu}=1}^N E_{\mu} \int \delta\psi_{\mu}^*
  \psi_{\mu}dx_i
  -  \sum_{{\mu}=1}^N E_{\mu} \int \psi_{\mu}^*
  \delta\psi_{\mu}dx_i = 0.
\]
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
Although the variations $\delta\psi$ and $\delta\psi^*$ are not
independent, they may in fact be treated as such, so that the 
terms dependent on either $\delta\psi$ and $\delta\psi^*$ individually 
may be set equal to zero. To see this, simply 
replace the arbitrary variation $\delta\psi$ by $i\delta\psi$, so that
$\delta\psi^*$ is replaced by $-i\delta\psi^*$, and combine the two
equations. We thus arrive at the Hartree-Fock equations
\begin{equation}
\left[ -\frac{1}{2}\nabla_i^2+ \sum_{\nu=1}^N\int \psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\nu}(x_j)dx_j \right]\psi_{\mu}(x_i) - \left[ \sum_{{\nu}=1}^N \int\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_j) dx_j\right] \psi_{\nu}(x_i) = \epsilon_{\mu} \psi_{\mu}(x_i).  \label{eq:hartreefockcoordinatespace}
\end{equation}
Notice that the integration $\int dx_j$ implies an
integration over the spatial coordinates $\mathbf{r_j}$ and a summation
over the spin-coordinate of fermion $j$. We note that the factor of $1/2$ in front of the sum involving the two-body interaction, has been removed. This is due to the fact that we need to vary both $\delta\psi_{\mu}^*$ and
$\delta\psi_{\nu}^*$. Using the symmetry properties of the two-body interaction and interchanging $\mu$ and $\nu$
as summation indices, we obtain two identical terms.
% --- end paragraph admon ---



% !split
\subsection{Derivation of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
The two first terms in the last equation are the one-body kinetic energy and the
electron-nucleus potential. The third or \emph{direct} term is the averaged electronic repulsion of the other
electrons. As written, the
term includes the \emph{self-interaction} of 
electrons when $\mu=\nu$. The self-interaction is cancelled in the fourth
term, or the \emph{exchange} term. The exchange term results from our
inclusion of the Pauli principle and the assumed determinantal form of
the wave-function. Equation (\ref{eq:hartreefockcoordinatespace}), in addition to the kinetic energy and the attraction from the atomic nucleus that confines the motion of a single electron,   represents now the motion of a single-particle modified by the two-body interaction. The additional contribution to the Schroedinger equation due to the two-body interaction, represents a mean field set up by all the other bystanding electrons, the latter given by the sum over all single-particle states occupied by $N$ electrons. 

The Hartree-Fock equation is an example of an integro-differential equation. These equations involve repeated calculations of integrals, in addition to the solution of a set of coupled differential equations. 
The Hartree-Fock equations can also be rewritten in terms of an eigenvalue problem. The solution of an eigenvalue problem represents often a more practical algorithm and the  solution of  coupled  integro-differential equations.
This alternative derivation of the Hartree-Fock equations is given below.
% --- end paragraph admon ---




% !split
\subsection{Analysis of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
  A theoretically convenient form of the
Hartree-Fock equation is to regard the direct and exchange operator
defined through 
\begin{equation*}
  V_{\mu}^{d}(x_i) = \int \psi_{\mu}^*(x_j) 
 \hat{v}(r_{ij})\psi_{\mu}(x_j) dx_j
\end{equation*}
and
\begin{equation*}
  V_{\mu}^{ex}(x_i) g(x_i) 
  = \left(\int \psi_{\mu}^*(x_j) 
 \hat{v}(r_{ij})g(x_j) dx_j
  \right)\psi_{\mu}(x_i),
\end{equation*}
respectively.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations in coordinate space}

% --- begin paragraph admon ---
\paragraph{}
The function $g(x_i)$ is an arbitrary function,
and by the substitution $g(x_i) = \psi_{\nu}(x_i)$
we get
\begin{equation*}
  V_{\mu}^{ex}(x_i) \psi_{\nu}(x_i) 
  = \left(\int \psi_{\mu}^*(x_j) 
 \hat{v}(r_{ij})\psi_{\nu}(x_j)
  dx_j\right)\psi_{\mu}(x_i).
\end{equation*}
We may then rewrite the Hartree-Fock equations as
\[
  \hat{h}^{HF}(x_i) \psi_{\nu}(x_i) = \epsilon_{\nu}\psi_{\nu}(x_i),
\]
with
\[
  \hat{h}^{HF}(x_i)= \hat{h}_0(x_i) + \sum_{\mu=1}^NV_{\mu}^{d}(x_i) -
  \sum_{\mu=1}^NV_{\mu}^{ex}(x_i),
\]
and where $\hat{h}_0(i)$ is the one-body part. The latter is normally chosen as a part which yields solutions in closed form. The harmonic oscilltor is a classical problem thereof.
We normally rewrite the last equation as
\[
  \hat{h}^{HF}(x_i)= \hat{h}_0(x_i) + \hat{u}^{HF}(x_i). 
\]
% --- end paragraph admon ---




% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
Another possibility is to expand the single-particle functions in a known basis  and vary the coefficients, 
that is, the new single-particle wave function is written as a linear expansion
in terms of a fixed chosen orthogonal basis (for example the well-known harmonic oscillator functions or the hydrogen-like functions etc).
We define our new Hartree-Fock single-particle basis by performing a unitary transformation 
on our previous basis (labelled with greek indices) as
\begin{equation}
\psi_p^{HF}  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. \label{eq:newbasis}
\end{equation}
In this case we vary the coefficients $C_{p\lambda}$. If the basis has infinitely many solutions, we need
to truncate the above sum.  We assume that the basis $\phi_{\lambda}$ is orthogonal. A unitary transformation keeps the orthogonality, as discussed in exercise 1 below.
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
It is normal to choose a single-particle basis defined as the eigenfunctions
of parts of the full Hamiltonian. The typical situation consists of the solutions of the one-body part of the Hamiltonian, that is we have
\[
\hat{h}_0\phi_{\lambda}=\epsilon_{\lambda}\phi_{\lambda}.
\]
The single-particle wave functions $\phi_{\lambda}({\bf r})$, defined by the quantum numbers $\lambda$ and ${\bf r}$
are defined as the overlap 
\[
   \phi_{\lambda}({\bf r})  = \langle {\bf r} | \lambda \rangle .
\]
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
In our discussions hereafter we will use our definitions of single-particle states above and below the Fermi ($F$) level given by the labels
$ijkl\dots \le F$ for so-called single-hole states and $abcd\dots > F$ for so-called particle states.
For general single-particle states we employ the labels $pqrs\dots$.
% --- end paragraph admon ---




% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
In Eq.~(\ref{FunctionalEPhi}), restated here
\[
  E[\Phi] 
  = \sum_{\mu=1}^N \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS},
\]
we found the expression for the energy functional in terms of the basis function $\phi_{\lambda}({\bf r})$. We then  varied the above energy functional with respect to the basis functions $|\mu \rangle$. 
Now we are interested in defining a new basis defined in terms of
a chosen basis as defined in Eq.~(\ref{eq:newbasis}). We can then rewrite the energy functional as
\begin{equation}
  E[\Phi^{HF}] 
  = \sum_{i=1}^N \langle i | h | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS}, \label{FunctionalEPhi2}
\end{equation}
where $\Phi^{HF}$ is the new Slater determinant defined by the new basis of Eq.~(\ref{eq:newbasis}).
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
Using Eq.~(\ref{eq:newbasis}) we can rewrite Eq.~(\ref{FunctionalEPhi2}) as 
\begin{equation}
  E[\Psi] 
  = \sum_{i=1}^N \sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
  \frac{1}{2}\sum_{ij=1}^N\sum_{{\alpha\beta\gamma\delta}} C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. \label{FunctionalEPhi3}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
We wish now to minimize the above functional. We introduce again a set of Lagrange multipliers, noting that
since $\langle i | j \rangle = \delta_{i,j}$ and $\langle \alpha | \beta \rangle = \delta_{\alpha,\beta}$, 
the coefficients $C_{i\gamma}$ obey the relation
\[
 \langle i | j \rangle=\delta_{i,j}=\sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | \beta \rangle=
\sum_{\alpha} C^*_{i\alpha}C_{i\alpha},
\]
which allows us to define a functional to be minimized that reads
\begin{equation}
  F[\Phi^{HF}]=E[\Phi^{HF}] - \sum_{i=1}^N\epsilon_i\sum_{\alpha} C^*_{i\alpha}C_{i\alpha}.
\end{equation}
% --- end paragraph admon ---





% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
Minimizing with respect to $C^*_{i\alpha}$, remembering that the equations for $C^*_{i\alpha}$ and $C_{i\alpha}$
can be written as two  independent equations, we obtain
\[
\frac{d}{dC^*_{i\alpha}}\left[  E[\Phi^{HF}] - \sum_{j}\epsilon_j\sum_{\alpha} C^*_{j\alpha}C_{j\alpha}\right]=0,
\]
which yields for every single-particle state $i$ and index $\alpha$ (recalling that the coefficients $C_{i\alpha}$ are matrix elements of a unitary (or orthogonal for a real symmetric matrix) matrix)
the following Hartree-Fock equations
\[
\sum_{\beta} C_{i\beta}\langle \alpha | h | \beta \rangle+
\sum_{j=1}^N\sum_{\beta\gamma\delta} C^*_{j\beta}C_{j\delta}C_{i\gamma}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}=\epsilon_i^{HF}C_{i\alpha}.
\]
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
We can rewrite this equation as (changing dummy variables)
\[
\sum_{\beta} \left\{\langle \alpha | h | \beta \rangle+
\sum_{j}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}\right\}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}.
\]
Note that the sums over greek indices run over the number of basis set functions (in principle an infinite number).
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock by varying the coefficients of a wave function expansion}

% --- begin paragraph admon ---
\paragraph{}
Defining 
\[
h_{\alpha\beta}^{HF}=\langle \alpha | h | \beta \rangle+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS},
\]
we can rewrite the new equations as 
\begin{equation}
\sum_{\gamma}h_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}. \label{eq:newhf}
\end{equation}
The latter is nothing but a standard eigenvalue problem. Compared with Eq.~(\ref{eq:hartreefockcoordinatespace}),
we see that we do not need to compute any integrals in an iterative procedure for solving the equations.
It suffices to tabulate the matrix elements $\langle \alpha | h | \beta \rangle$ and $\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}$ once and for all. Successive iterations require thus only a look-up in tables over one-body and two-body matrix elements. These details will be discussed below when we solve the Hartree-Fock equations numerical.
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock algorithm}

% --- begin paragraph admon ---
\paragraph{}
Our Hartree-Fock matrix  is thus
\[
\hat{h}_{\alpha\beta}^{HF}=\langle \alpha | \hat{h}_0 | \beta \rangle+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The Hartree-Fock equations are solved in an iterative waym starting with a guess for the coefficients $C_{j\gamma}=\delta_{j,\gamma}$ and solving the equations by diagonalization till the new single-particle energies
$\epsilon_i^{\mathrm{HF}}$ do not change anymore by a prefixed quantity.
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock algorithm}

% --- begin paragraph admon ---
\paragraph{}
Normally we assume that the single-particle basis $|\beta\rangle$ forms an eigenbasis for the operator
$\hat{h}_0$, meaning that the Hartree-Fock matrix becomes  
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The Hartree-Fock eigenvalue problem
\[
\sum_{\beta}\hat{h}_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{\mathrm{HF}}C_{i\alpha},
\]
can be written out in a more compact form as
\[
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}. 
\]
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock algorithm}

% --- begin paragraph admon ---
\paragraph{}
The Hartree-Fock equations are, in their simplest form, solved in an iterative way, starting with a guess for the
coefficients $C_{i\alpha}$. We label the coefficients as $C_{i\alpha}^{(n)}$, where the subscript $n$ stands for iteration $n$.
To set up the algorithm we can proceed as follows:

\begin{itemize}
 \item We start with a guess $C_{i\alpha}^{(0)}=\delta_{i,\alpha}$. Alternatively, we could have used random starting values as long as the vectors are normalized. Another possibility is to give states below the Fermi level a larger weight.

 \item The Hartree-Fock matrix simplifies then to (assuming that the coefficients $C_{i\alpha} $  are real)
\end{itemize}

\noindent
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j = 1}^N\sum_{\gamma\delta} C_{j\gamma}^{(0)}C_{j\delta}^{(0)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock algorithm}

% --- begin paragraph admon ---
\paragraph{}
Solving the Hartree-Fock eigenvalue problem yields then new eigenvectors $C_{i\alpha}^{(1)}$ and eigenvalues
$\epsilon_i^{HF(1)}$. 
\begin{itemize}
 \item With the new eigenvalues we can set up a new Hartree-Fock potential 
\end{itemize}

\noindent
\[
\sum_{j = 1}^N\sum_{\gamma\delta} C_{j\gamma}^{(1)}C_{j\delta}^{(1)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The diagonalization with the new Hartree-Fock potential yields new eigenvectors and eigenvalues.
This process is continued till for example
\[
\frac{\sum_{p} |\epsilon_i^{(n)}-\epsilon_i^{(n-1)}|}{m} \le \lambda,  
\]
where $\lambda$ is a user prefixed quantity ($\lambda \sim 10^{-8}$ or smaller) and $p$ runs over all calculated single-particle
energies and $m$ is the number of single-particle states.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
We can rewrite the ground state energy by adding and subtracting $\hat{u}^{HF}(x_i)$ 
\[
  E_0^{HF} =\langle \Phi_0 | \hat{H} | \Phi_0\rangle = 
\sum_{i\le F}^N \langle i | \hat{h}_0 +\hat{u}^{HF}| j\rangle+ \frac{1}{2}\sum_{i\le F}^N\sum_{j \le F}^N\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^N \langle i |\hat{u}^{HF}| i\rangle,
\]
which results in
\[
  E_0^{HF}
  = \sum_{i\le F}^N \varepsilon_i^{HF} + \frac{1}{2}\sum_{i\le F}^N\sum_{j \le F}^N\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^N \langle i |\hat{u}^{HF}| i\rangle.
\]
Our single-particle states $ijk\dots$ are now single-particle states obtained from the solution of the Hartree-Fock equations.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
Using our definition of the Hartree-Fock single-particle energies we obtain then the following expression for the total ground-state energy
\[
  E_0^{HF}
  = \sum_{i\le F}^N \varepsilon_i - \frac{1}{2}\sum_{i\le F}^N\sum_{j \le F}^N\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right].
\]
This form will be used in our discussion of Koopman's theorem.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{Atomic physics case.}
We have 
\[
  E[\Phi^{\mathrm{HF}}(N)] 
  = \sum_{i=1}^H \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
where $\Phi^{\mathrm{HF}}(N)$ is the new Slater determinant defined by the new basis of Eq.~(\ref{eq:newbasis})
for $N$ electrons (same $Z$).  If we assume that the single-particle wave functions in the new basis do not change 
when we remove one electron or add one electron, we can then define the corresponding energy for the $N-1$ systems as 
\[
  E[\Phi^{\mathrm{HF}}(N-1)] 
  = \sum_{i=1; i\ne k}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1;i,j\ne k}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
where we have removed a single-particle state $k\le F$, that is a state below the Fermi level.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
Calculating the difference 
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{i=1;i\ne k}^N\langle ik|\hat{v}|ik\rangle_{AS}  \frac{1}{2}\sum_{j=1;j\ne k}^N\langle kj|\hat{v}|kj\rangle_{AS},
\]
we obtain
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{j=1}^N\langle kj|\hat{v}|kj\rangle_{AS}
\]
which is just our definition of the Hartree-Fock single-particle energy
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \epsilon_k^{\mathrm{HF}} 
\]
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
Similarly, we can now compute the difference (we label the single-particle states above the Fermi level as $abcd > F$)
\[
  E[\Phi^{\mathrm{HF}}(N+1)]-   E[\Phi^{\mathrm{HF}}(N)]= \epsilon_a^{\mathrm{HF}}. 
\]
These two equations can thus be used to the electron affinity or ionization energies, respectively. 
Koopman's theorem states that for example the ionization energy of a closed-shell system is given by the energy of the highest occupied single-particle state.  If we assume that changing the number of electrons from $N$ to $N+1$ does not change the Hartree-Fock single-particle energies and eigenfunctions, then Koopman's theorem simply states that the ionization energy of an atom is given by the single-particle energy of the last bound state. In a similar way, we can also define the electron affinities.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
As an example, consider a simple model for atomic sodium, Na. Neutral sodium has eleven electrons, 
with the weakest bound one being confined the $3s$ single-particle quantum numbers. The energy needed to remove an electron from neutral sodium is rather small, 5.1391 eV, a feature which pertains to all alkali metals.
Having performed a  Hartree-Fock calculation for neutral sodium would then allows us to compute the
ionization energy by using the single-particle energy for the $3s$ states, namely $\epsilon_{3s}^{\mathrm{HF}}$. 

From these considerations, we see that Hartree-Fock theory allows us to make a connection between experimental 
observables (here ionization and affinity energies) and the underlying interactions between particles.  
In this sense, we are now linking the dynamics and structure of a many-body system with the laws of motion which govern the system. Our approach is a reductionistic one, meaning that we want to understand the laws of motion 
in terms of the particles or degrees of freedom which we believe are the fundamental ones. Our Slater determinant, being constructed as the product of various single-particle functions, follows this philosophy.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations, Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
With similar arguments as in atomic physics, we can now use Hartree-Fock theory to make a link
between nuclear forces and separation energies. Changing to nuclear system, we define
\[
  E[\Phi^{\mathrm{HF}}(A)] 
  = \sum_{i=1}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
where $\Phi^{\mathrm{HF}}(A)$ is the new Slater determinant defined by the new basis of Eq.~(\ref{eq:newbasis})
for $A$ nucleons, where $A=N+Z$, with $N$ now being the number of neutrons and $Z$ th enumber of protons.  If we assume again that the single-particle wave functions in the new basis do not change from a nucleus with $A$ nucleons to a nucleus with $A-1$  nucleons, we can then define the corresponding energy for the $A-1$ systems as 
\[
  E[\Phi^{\mathrm{HF}}(A-1)] 
  = \sum_{i=1; i\ne k}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1;i,j\ne k}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
where we have removed a single-particle state $k\le F$, that is a state below the Fermi level.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
Calculating the difference 
\[
  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{i=1;i\ne k}^N\langle ik|\hat{v}|ik\rangle_{AS}  \frac{1}{2}\sum_{j=1;j\ne k}^N\langle kj|\hat{v}|kj\rangle_{AS},
\]
which becomes 
\[
  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{j=1}^N\langle kj|\hat{v}|kj\rangle_{AS}
\]
which is just our definition of the Hartree-Fock single-particle energy
\[
  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \epsilon_k^{\mathrm{HF}} 
\]
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
Similarly, we can now compute the difference (recall that the single-particle states $abcd > F$)
\[
  E[\Phi^{\mathrm{HF}}(A+1)]-   E[\Phi^{\mathrm{HF}}(A)]= \epsilon_a^{\mathrm{HF}}. 
\]
If we then recall that the binding energy differences 
\[
BE(A)-BE(A-1) \hspace{0.5cm} \mathrm{and} \hspace{0.5cm} BE(A+1)-BE(A), 
\]
define the separation energies, we see that the Hartree-Fock single-particle energies can be used to
define separation energies. We have thus our first link between nuclear forces (included in the potential energy term) and an observable quantity defined by differences in binding energies.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
We have thus the following interpretations (if the single-particle field do not change)
\[
BE(A)-BE(A-1)\approx  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \epsilon_k^{\mathrm{HF}}, 
\]
and
\[
BE(A+1)-BE(A)\approx  E[\Phi^{\mathrm{HF}}(A+1)]-   E[\Phi^{\mathrm{HF}}(A)] =  \epsilon_a^{\mathrm{HF}}. 
\]
If  we use ${}^{16}\mbox{O}$ as our closed-shell nucleus, we could then interpret the separation energy
\[
BE(^{16}\mathrm{O})-BE(^{15}\mathrm{O})\approx \epsilon_{0p^{\nu}_{1/2}}^{\mathrm{HF}}, 
\]
and
\[
BE(^{16}\mathrm{O})-BE(^{15}\mathrm{N})\approx \epsilon_{0p^{\pi}_{1/2}}^{\mathrm{HF}}.
\]
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
Similalry, we could interpret
\[
BE(^{17}\mathrm{O})-BE(^{16}\mathrm{O})\approx \epsilon_{0d^{\nu}_{5/2}}^{\mathrm{HF}}, 
\]
and 
\[
BE(^{17}\mathrm{F})-BE(^{16}\mathrm{O})\approx\epsilon_{0d^{\pi}_{5/2}}^{\mathrm{HF}}.
\]
We can continue like this for all $A\pm 1$ nuclei where $A$ is a good closed-shell (or subshell closure)
nucleus. Examples are ${}^{22}\mbox{O}$, ${}^{24}\mbox{O}$, ${}^{40}\mbox{Ca}$, ${}^{48}\mbox{Ca}$, ${}^{52}\mbox{Ca}$, ${}^{54}\mbox{Ca}$, ${}^{56}\mbox{Ni}$, 
${}^{68}\mbox{Ni}$, ${}^{78}\mbox{Ni}$, ${}^{90}\mbox{Zr}$, ${}^{88}\mbox{Sr}$, ${}^{100}\mbox{Sn}$, ${}^{132}\mbox{Sn}$ and ${}^{208}\mbox{Pb}$, to mention some possile cases.
% --- end paragraph admon ---



% !split
\subsection{Analysis of Hartree-Fock equations and Koopman's theorem}

% --- begin paragraph admon ---
\paragraph{}
We can thus make our first interpretation of the separation energies in terms of the simplest
possible many-body theory. 
If we also recall that the so-called energy gap for neutrons (or protons) is defined as
\[
\Delta S_n= 2BE(N,Z)-BE(N-1,Z)-BE(N+1,Z),
\]
for neutrons and the corresponding gap for protons
\[
\Delta S_p= 2BE(N,Z)-BE(N,Z-1)-BE(N,Z+1),
\]
we can define the neutron and proton energy gaps for ${}^{16}\mbox{O}$ as
\[
\Delta S_{\nu}=\epsilon_{0d^{\nu}_{5/2}}^{\mathrm{HF}}-\epsilon_{0p^{\nu}_{1/2}}^{\mathrm{HF}}, 
\]
and 
\[
\Delta S_{\pi}=\epsilon_{0d^{\pi}_{5/2}}^{\mathrm{HF}}-\epsilon_{0p^{\pi}_{1/2}}^{\mathrm{HF}}. 
\]
% --- end paragraph admon ---





% !split
\subsection{Basic definitions and motivation}

% --- begin paragraph admon ---
\paragraph{}

Our final aim is to develop a Hartree-Fock code which can be used to study properties of
both atoms and molecules.

For a molecular system, the eigenfunctions of the Hartree-Fock equations are called
\emph{molecular orbitals} (MOs). It is important to distinguish these
from the perhaps more familiar \emph{atomic orbitals}, where we can think of (as we have done till now)
that the electrons occupy some well-defined hydrogen-like states.

An example like the $H_2$-molecule may suffice.
In the ground state the electrons are not occupying the 1$s$-orbitals of atomic Hydrogen. The
molecular system is entirely different from the atomic one, with an entirely different Hamiltonian,
and the eigenstates of the Hartree-Fock equations will therefore also be different.
% --- end paragraph admon ---







% !split
\subsection{Basic definitions and motivation}

% --- begin paragraph admon ---
\paragraph{}

In order to solve the Hartree-Fock equations, we need to expand the molecular orbitals in a known
set of basis functions
\begin{equation}
 \phi_k(\vec r) = \sum_{\mu=1}^M\chi_{\mu k}(\vec r).
\end{equation}
The question we then need to answer is how to choose basis functions $\chi_{\mu k}$? The answer to this
is primarily dictated by the following three criteria:

\begin{itemize}
  \item The functions should make physically sense, i.e., they should have a large probability where   the electrons are likely to be and small elsewhere.

  \item It should be possible to integrate the functions efficiently.

  \item The solution of the Hartree-Fock equations should converge towards the Hartree-Fock limit        as the number of basis functions increases.
\end{itemize}

\noindent
The first point suggests that we choose atomic orbitals as basis functions,  which is often
referred to as ``linear combination of atomic orbitals'' (LCAO). In the project we will use the various atomic nuclei as mass centers which the electrons orbit around. However, this is not strictly required since the
atomic orbitals are merely being used as basis functions, and they are not to be thought of
as orbitals occupied by electrons.
% --- end paragraph admon ---



% !split
\subsection{Basic definitions, Slater orbitals}

% --- begin paragraph admon ---
\paragraph{}

A much set of state functions are the so-called 
Slater type orbitals (STO), defined as
\begin{equation}
 \chi^{STO}(r,\theta,\phi,n,l,m) = \frac{(2a)^{n+1/2}}{[(2n)!]^{1/2}}r^{n-1}\exp(-a r) Y^m_l(\theta,\phi),
\end{equation}
where $n$ is the principal quantum number, $l$ and $m$ are the orbital momentum quantum numbers,
$Y^m_l(\theta,\phi)$ are the spherical harmonics familiar from the solution of the Schr\"odinger
equation for the Hydrogen atom, and $a$ is an exponent which determines the radial decay of the
function. The main attractive features of the STOs are that they have the correct exponential decay with
increasing $r$ and that the orbital components are hydrogenic. 
Furthermore, they can be used to represent in a better way weakly bound states or even resonances. The hydrogen-like state functions 
represent only bound states.
STOs are mainly 
used in atomic Hartree-Fock calculations. When doing molecular calculations, however, they have the
disadvantage that the two-particle integrals $\langle\mu\sigma\vert g\vert\nu\lambda\rangle$ need to compute 
an anti-symmetrized matrix interaction element have no known closed form expression. This is because integrals of products
of exponentials centered on different nuclei are difficult to handle. They can of course be calculated
numerically, but for large molecules this is very time consuming.
% --- end paragraph admon ---



% !split
\subsection{Basic definitions}

% --- begin paragraph admon ---
\paragraph{}

A clever trick which makes multiple center integrals easier to handle is to replace the exponential
term $\exp(-a r)$ with $\exp(-a r^2)$, that is, to functions proportional with Gaussians. This simplifies 
considerably the integrals to evaluate since the product of two Gaussians centered on nuclei with positions
$\vec A$ and $\vec B$ is equal to \emph{one} Gaussian centered on some point $\vec P$ on
the line between them:
\begin{equation}
\label{eq:gaussian_product}
 \exp(-a|\vec r - \vec A|^2)\cdot \exp(-b|\vec r - \vec B|^2) = K_{AB}\,\exp(-p|\vec r - \vec P|^2),
\end{equation}
where

\begin{align}
 K_{AB} & =  \exp\Big(-\frac{ab}{a + b}|\vec A - \vec B|^2\Big), \\
 \vec P & =  \frac{a \vec A + b \vec B}{a + b}, \\
 p & =  a + b.
\end{align}
This is the so-called \emph{Gaussian product theorem}.
% --- end paragraph admon ---



% !split
\subsection{Basic definitions}

% --- begin paragraph admon ---
\paragraph{}

The general functional form of a normalised Gaussian type orbital 
centered at $\vec A$ is given by

\begin{equation}
 G_{ijk}(a, \vec r_A) = \Big(\frac{2a}{\pi}\Big)^{3/4}\Big[\frac{(8a)^{i+j+k}\,i!\,j!\,k!}{(2i)!\,(2j)!\,(2k)!}\Big]x_A^i\,y_A^j\,z_A^k\,\exp(-a r_A^2),
\end{equation}
where $\vec r_A = \vec r - \vec A$ and the integers $i$, $j$, $k$ determine the orbital momentum quantum number $l=i+j+k$.
% --- end paragraph admon ---



% !split
\subsection{Disadvantages}

% --- begin paragraph admon ---
\paragraph{}

The greatest drawback with GTOs is that they do not have the proper exponential radial decay. This can be fixed by forming linear combinations of GTOs
to resemble the STOs
\begin{equation}
 \chi^{CGTO}(\vec r_A,i,j,k) = \sum_{p=1}^L d_p G_{ijk}(a_p, \vec r_A).
\end{equation}
These are called STO-LG basis functions, where L refers to the number of Gaussians used in the linear combination.
The individual Gaussians are called \emph{primitive} basis functions and the linear combinations are called \emph{contracted} basis functions, hence the label
CGTO (Contracted Gaussian Type Orbital). These are the functions we will employ in this project.

A very common choice for the STO-LG basis sets is $L=3$. 
It is important to note that the parameters $(a_p,d_p)$ are static and that the linear combination of Gaussians constitute \emph{one single}
basis function. With the wording ``basis function'', we  will refer to a contracted basis function.
% --- end paragraph admon ---



% !split
\subsection{Basic definitions}

% --- begin paragraph admon ---
\paragraph{}

The STO-LG basis sets belong to the family of \emph{minimal basis sets}.
It means that there is one and only one basis function per atomic orbital.
The STO-LG basis sets for the Hydrogen and Helium atoms, for example, contain only one basis
function for the 1$s$ atomic orbital. This basis function is, as explained above, composed of
a linear combination of L primitives. For the atoms Lithium through Neon the STO-LG basis
sets contain 5 basis functions; one for each of the atomic orbitals
$1s$, $2s$, $2p_x$, $2p_y$ and $2p_z$.



\begin{quote}
\begin{tabular}{cccc}
\hline
\multicolumn{1}{c}{ $p$ } & \multicolumn{1}{c}{ 1 } & \multicolumn{1}{c}{ 2 } & \multicolumn{1}{c}{ 3 } \\
\hline
$d_p$ & 0.1543 & 0.5353 & 0.4446 \\
$a_p$ & 3.4252 & 0.6239 & 0.1688 \\
\hline
\end{tabular}
\end{quote}

\noindent
% --- end paragraph admon ---



% !split
\subsection{Cartesian Gaussians and how to compute integrals}

% --- begin paragraph admon ---
\paragraph{}

Using GTOs as basis functions improves the speed of the integrations which must be done when setting up 
for example the Fock matrix.
The Cartesian Gaussian functions centered at $\vec A$ are given by

\begin{equation}
 G_{ijk}(a, \vec r_A) = x^i_A\,y^j_A\,z^k_A\,\exp(-a r^2_A),
\end{equation}
where $\vec r_A = \vec r - \vec A$. These will be our so-called primitive basis functions (see also the flow chart of Hartree-Fock code). 
They factorize in the Cartesian components

\begin{equation}
 G_{ijk}(a, \vec r_A) = G_i(a, x_A)\,G_j(a, y_A)\,G_k(a, z_A),
\end{equation}
where

\begin{equation}
 G_i(a, x_A) = x^i_A\,\exp(-a x^2_A),
\end{equation}
and the other factors are defined similarly. Each of the components obey the simple recurrence relation

\begin{equation}
 x_A\,G_i = G_{i+1}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

We introduce  shorthand notation

\begin{align}
  G_a(\vec r) & = G_{ikm}(a, \vec r_A), \\
  G_b(\vec r) & = G_{jln}(b, \vec r_B),
\end{align}
and define the overlap distribution  as

\begin{equation}
 \Omega_{ab}(\vec r) = G_a(\vec r)\,G_b(\vec r).
\end{equation}
Using the Gaussian product theorem (\ref{eq:gaussian_product}) this can be written as

\begin{equation}
 \Omega_{ab}(\vec r) = K_{AB}\,x^i_A\,x^j_B\,y^k_A\,y^l_B\,z^m_A\,z^n_B\,\exp(-p\,r^2_P),
\end{equation}
where

\begin{equation}
 \begin{split}
  K_{AB}  = & \exp\Big(-\frac{ab}{a + b}R^2_{AB}\Big) \\
  \vec R_{AB} = &  \vec A - \vec B \\
  p = & a + b\\
  \vec r_P = & \vec r - \vec P \\
  \vec P = & \frac{a\vec A + b\vec B}{a + b}.
 \end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

Because the Gaussians $G_a$ and $G_b$ factorize in their Cartesian components, such a factorization applies to the overlap distribution
as well, namely

\begin{equation}
 \Omega_{ab}(\vec r) = \Omega_{ij}(x)\,\Omega_{kl}(y)\,\Omega_{mn}(z),
\end{equation}
where

\begin{equation}
 \Omega_{ij} = K^x_{AB}\,x^i_A\,x^j_B\,\exp(-px^2_P)
\end{equation}
and

\begin{equation}
\begin{split}
 K^x_{AB} = & \exp\Big(-\frac{ab}{a + b}X^2_{AB}\Big) \\
   X_{AB} = & A_x - B_x.
\end{split}
\end{equation}
The distributions $\Omega_{kl}(y)$ and $\Omega_{mn}(z)$ are defined similarly.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

A very useful representation of the Cartesian GTOs is given by the so-called Hermite Gaussians. These functions simplify 
the integrations significantly. The Hermite Gaussians centered at $\vec P$ are defined by

\begin{equation}
 \Lambda_{tuv}(p, \vec r_p) = \Big(\frac{\partial}{\partial P_x}\Big)^t \Big(\frac{\partial}{\partial P_y}\Big)^u \Big(\frac{\partial}{\partial P_z}\Big)^v \exp(-p\, r^2_P),
\end{equation}
where $\vec r_p = \vec r - \vec P$. They factorize as (like the cartesian GTOs also do)

\begin{equation}
 \Lambda_{tuv}(p, \vec r_P) = \Lambda_t(p,x_P)\,\Lambda_u(p,y_P)\,\Lambda_v(p,z_P),
\end{equation}
where

\begin{equation}
\label{eq:HermiteGaussian_x}
 \Lambda_t(p,x_P) = \Big(\frac{\partial}{\partial P_x}\Big)^t \exp(-p\,x^2_P),
\end{equation}
and the other factors are defined similarly.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

However, their recurrence relation is quite different from that of the Cartesian Gaussians:

\begin{equation}
\begin{split}
 \Lambda_{t+1}(p,x_P) & = \Big(\frac{\partial}{\partial P_x}\Big)^t \frac{\partial}{\partial P_x}\exp(-px^2_P) \\
                      & = \Big(\frac{\partial}{\partial P_x}\Big)^t 2px_P \exp(-px^2_P)  \\
                      & = 2p[-t\Big(\frac{\partial}{\partial P_x}\Big)^{t-1} + x_P \Big(\frac{\partial}{\partial P_x}\Big)^t] \exp(-px^2_P) \\
                      & = 2p[-t\Lambda_{t-1} + x_P \Lambda_t],
\end{split}
\end{equation}
where we have used that

\begin{equation}
\label{eq:derivation_rule}
 \Big(\frac{\partial}{\partial x}\Big)^t x f(x) = t\Big(\frac{\partial}{\partial x}\Big)^{t-1}f(x) + x\Big(\frac{\partial}{\partial x}\Big)^t f(x).
\end{equation}
The recurrence relation reads

\begin{equation}
\label{eq:hermite_gaussian_recurrence}
 x_P \Lambda_t = \frac{1}{2p}\Lambda_{t+1} + t\Lambda_{t-1}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

Our first goal is to compute the overlap integral

\begin{equation}
S_{ab}  = \langle G_a|G_b\rangle = \int d\vec r \,\Omega_{ab}(\vec r)
\end{equation}
between two Gaussians centered at the points $\vec A$ and $\vec B$.
Since the overlap distribution $\Omega_{ab}$ factorizes in the Cartesian components, the integrals over $x$, $y$ and $z$ can be calculated independently of each other

\begin{equation}
\begin{split}
 S_{ab} = & \langle G_i|G_j\rangle \langle G_k|G_l\rangle \langle G_m|G_n\rangle \\
        = & S_{ij}\,S_{kl}\,S_{mn}.
\end{split}
\end{equation}
The $x$ component of the overlap integral, for example, is given by

\begin{equation}
\label{eq:intG_ij}
\begin{split}
 S_{ij} = & \int dx \,\Omega_{ij}(x) \\
        = & K_{AB}^x\int dx \,x_A^ix_B^j\exp(-px_P^2),
\end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

In equation (\ref{eq:intG_ij}) the two-center GTOs have been reduced to a one-center Gaussian.
However, the integral is still not straightforward to calculate because of the powers $x_A^i$ and $x_B^j$. A smart way to deal with this is to express the Cartesian Gaussian
in terms of the Hermite Gaussians. Note that (\ref{eq:HermiteGaussian_x}) is a polynomial of order $t$ in $x$ multiplied by the exponential function. In equation (\ref{eq:intG_ij}) the polynomial
is of order $i+j$. This means that we can express the overlap distribution $\Omega_{ij}(x)$ in equation (\ref{eq:intG_ij}) in terms of the Hermite Gaussians in (\ref{eq:HermiteGaussian_x}) in the following way:
\begin{equation}
\label{eq:LinCombOfHermGauss}
 \Omega_{ij}(x) = \sum_{t=0}^{i+j} E^{ij}_t \Lambda_t(p, x_P),
\end{equation}
where $E^{ij}_t$ are constants.
Note that the sum is over $t$ only. The indices $i$ and $j$ are static and are determined from the powers of $x$ in $G_i$ and $G_j$.
We use them as labels on the coefficients $E^{ij}_t$ because different sets of indices will lead to different sets of coefficients.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

To get the overlap integral in the $x$-direction we integrate (\ref{eq:LinCombOfHermGauss}) over $\mathbb{R}$, which now turns out to be extremely easy;
the only term that survives the integration is the term for $t=0$:

\begin{align}
 \int dx\,\Lambda_t(p,x_P) & =  \int dx\,\Big(\frac{\partial}{\partial P_x}\Big)^t\exp(-p\,x^2_P), \\
                           & =  \Big(\frac{\partial}{\partial P_x}\Big)^t \int dx\,\exp(-p\,x^2_P), \\
                           & =  \sqrt{\frac{\pi}{p}}\,\delta_{t0}.
\end{align}
We have used Leibniz' rule, which says that the differentiation of an integrand with respect to a variable which is not an integration variable can
be moved outside the integral. Thus the integral in (\ref{eq:intG_ij}) is simply

\begin{equation}
 S_{ij} = E^{ij}_0\,\sqrt{\frac{\pi}{p}}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

The same procedure can be used for the integrals with respect to $y$ and $z$, which means that the total overlap integral is

\begin{equation}
 S_{ab} = E^{ij}_0\,E^{kl}_0\,E^{mn}_0\,\Big(\frac{\pi}{p}\Big)^{3/2}.
\end{equation}
We need thereafter to determine the coefficients $E^{ij}_t$. When $i=j=0$ in equation (\ref{eq:LinCombOfHermGauss})
we have

\begin{equation}
 E^{0,0}_0 = K_{AB}^x.
\end{equation}
The other coefficients are found via the following recurrence relations

\begin{equation}
\label{eq:E_recurrence}
\begin{split}
 E^{i+1,j}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PA}E^{ij}_t + (t+1)E^{ij}_{t+1} \\
 E^{i,j+1}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PB}E^{ij}_t + (t+1)E^{ij}_{t+1}.
\end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations}

% --- begin paragraph admon ---
\paragraph{}

Analogous expressions hold for the coefficients $E^{kl}_u$ and $E^{mn}_v$. The first equation in (\ref{eq:E_recurrence}) 
can be derived by comparing two equivalent ways of expanding the product $G_{i+1}G_j$
in Hermite Gaussians. The first way is

\begin{equation}
 G_{i+1}\,G_j= \sum_{t=0}^{i+j+1}E^{i+1,j}_t \Lambda_t,
\end{equation}
and the second way is

\begin{equation}
\label{eq:derivation_E_coeffs}
\begin{split}
 G_{i+1}\,G_j & = x_A G_i\,G_j \\
              & = [(x - P_x) + (P_x - A_x)]\sum_{t=0}^{i+j} E^{ij}_t \Lambda_t\\
              & = \sum_{t=0}^{i+j}[x_P + X_{PA}] E^{ij}_t \Lambda_t \\
              & = \sum_{t=0}^{i+j}[\frac{1}{2p}\Lambda_{t+1} + t\Lambda_{t-1} + X_{PA}\Lambda_t]E^{ij}_t \\
              & = \sum_{t=0}^{i+j}[\frac{1}{2p}E^{ij}_{t-1} + X_{PA}E^{ij}_t + (t+1)E^{ij}_{t+1}] \Lambda_t,
\end{split}
\end{equation}
where we have used the recurrence relation (\ref{eq:hermite_gaussian_recurrence}) on the fourth line and changed the 
summation indices on the fifth line.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, kinetic energy}

% --- begin paragraph admon ---
\paragraph{}

Note that the change in summation indices in equation (\ref{eq:derivation_E_coeffs}) implies that we must define

\begin{equation}
 E^{ij}_t = 0, \qquad \text{if }t<0\text{ or }t > i + j.
\end{equation}

Next we turn to the evaluation of the kinetic integral:

\begin{equation}
\begin{split}
T_{ab} & = -\frac{1}{2}\langle G_a\vert\nabla^2\vert G_b\rangle \\
       & = -\frac{1}{2}\langle G_{ikm}(a, \vec r_A)\vert\nabla^2\vert G_{jln}(b, \vec r_B)\rangle \\
       & = -\frac{1}{2}(T_{ij}\,S_{kl}\,S_{mn} + S_{ij}\,T_{kl}\,S_{mn} + S_{ij}\,S_{kl}\,T_{mn}),
\end{split}
\end{equation}
where

\begin{equation}
 T_{ij} = \int dx \,G_i(a,x_A)\frac{\partial^2}{\partial x^2}G_j(b,x_B),
\end{equation}
and the other factors are defined in the same way. Performing the differentiation yields

\begin{equation}
 T_{ij} = 4b^2\,S_{i,j+2} - 2b(2j + 1)S_{i,j} + j(j-1)S_{i,j-2}.
\end{equation}
Thus we see that the kinetic integrals are calculated easily as products of the overlap integrals.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, one-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

We now turn to the Coulomb integral due to the interaction between the electrons and the atomic nuclei

\begin{equation}
 V_{ab} = \langle G_a\vert\frac{1}{r_C}\vert G_b\rangle,
\end{equation}
where $r_C = |\vec r - \vec C|$. As before, the overlap distribution is expanded in terms of  Hermite Gaussians

\begin{equation}
\begin{split}
 V_{ab} & = \int d\vec r \,\frac{\Omega_{ab}(\vec r)}{r_C} \\
        & = \sum_{tuv}E^{ij}_t E^{kl}_u E^{mn}_v\int d\vec r \, \frac{\Lambda_{tuv}(p,\vec r_P)}{r_C} \\
        & = \sum_{tuv}E^{ab}_{tuv}\int d\vec r \, \frac{\Lambda_{tuv}(p,\vec r_P)}{r_C}. \\
\end{split}
\end{equation}
Here we have used the shorthand notation

\begin{equation}
 E^{ab}_{tuv} = E^{ij}_t E^{kl}_u E^{mn}_v.
\end{equation}
In this integral other terms besides $\Lambda_{000}$ will survive due to the factor $1/r_C$. Let us nonetheless start by evaluating this term

\begin{equation}
 V_p = \int d\vec r \, \frac{\Lambda_{000}(p,\vec r_P)}{r_C} = \int d\vec r\, \frac{\exp(-p\,r_P^2)}{r_C}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, one-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

We will show that this three-dimensional integral can actually be converted to a one-dimensional one. The trick is to observe that the factor $1/r_C$ can be replaced by the integral

\begin{equation}
 \frac{1}{r_C} = \frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty dt\,\exp(-r^2_C\,t^2).
\end{equation}
Inserting this into $V_p$ and using the Gaussian product theorem gives

\begin{align}
 V_p & =  \int \exp(-p\,r_P^2)\Big(\frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty\exp(-r^2_C\,t^2)\,dt\Big)\,d\vec r \\
     & =  \frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty\int\exp\Big(-\frac{pt^2}{p + t^2}R^2_{PC}\Big)\,\exp[-(p + t^2)r^2_S] d\vec r\, dt,
\end{align}
where $\vec R_{PC} = \vec P - \vec C$ and $\vec r_S = \vec r - \vec S$ for some point $\vec S$. Doing the integral over the spatial coordinates reveals that the specific value of $\vec S$ is not relevant

\begin{align}
 V_p & =  \frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty\exp\Big(-\frac{pt^2}{p + t^2}R^2_{PC}\Big)\Big(\frac{\pi}{p + t^2}\Big)^{3/2}\,dt \\
     & =  2\pi\int_0^\infty\exp\Big(-\frac{pt^2}{p + t^2}R^2_{PC}\Big)\frac{dt}{(p + t^2)^{3/2}}.
\end{align}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, one-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

Next we change integration variable from $t$ to $u$ by defining

\begin{equation}
 u^2 = \frac{t^2}{p + t^2}.
\end{equation}
This will change the range of integration from $[0,\infty\rangle$ to $[0,1]$. This is beneficial because the final integral at which we arrive will be calculated numerically.
The change of variables leads to

\begin{align}
\label{eq:V_p}
 V_p & = \frac{2\pi}{p}\int_0^1\exp(-p\,R^2_{PC}\,u^2)\,du \\
     & = \frac{2\pi}{p}F_0(p\,R^2_{PC}),
\end{align}
where $F_0(x)$ is a special instance of the Boys function $F_n(x)$ which is defined as

\begin{equation}
 F_n(x) = \int_0^1\exp(-xt^2)\,t^{2n}\,dt.
\end{equation}
We will discuss the Boys functions below
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, one-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

We have now a  simplified way of calculating the integral of $\Lambda_{000}/r_C$. However, we need to integrate $\Lambda_{tuv}/r_C$ for general values of $t$, $u$ and $v$.
These integrals are actually not that hard to do once the Boys function is calculated:

\begin{align}
 V_{ab} & = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv}\int d\vec r \, \frac{\Lambda_{tuv}(p,\vec r_p)}{r_C} \\
        & = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv} \frac{\partial^{t+u+v} F_0(p R^2_{PC})}{\partial P_x^t \partial P_y^u \partial P_z^v} \\
        & = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv} R_{tuv}(p,\vec R_{PC}), \label{eq:V_ab}
\end{align}
where we have defined

\begin{equation}
 R_{tuv}(p,\vec R_{PC}) = \frac{\partial^{t+u+v} F_0(p R^2_{PC})}{\partial P_x^t \partial P_y^u \partial P_z^v}.
\end{equation}
% --- end paragraph admon ---




% !split
\subsection{Integral evaluations, one-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

We need to calculate derivatives of the function $F_0$. Note first that

\begin{equation}
 \frac{d}{dx}F_n(x) = -F_{n+1}(x).
\end{equation}
This means that it is possible to derive analytical expressions for the Coulomb term $V_{ab}$. However, in practice they are calculated recursively in a manner similar to the way we calculate
the coefficients $E^{ij}_t$. Before presenting the recursion relations, we introduce the so-called auxiliary Hermite integrals

\begin{equation}
 R^n_{tuv}(p,\vec R_{PC}) = (-2p)^n\,\frac{\partial^{t+u+v} F_n(p R^2_{PC})}{\partial P_x^t \partial P_y^u \partial P_z^v}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, one-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

By starting with the source terms $R^n_{000}(p,\vec R_{PC}) = (-2p)^n\,F_n(p R^2_{PC})$ we can reach the targets $R^0_{tuv}(p,\vec R_{PC}) = R_{tuv}(p,\vec R_{PC})$ through the following
recurrence relations

\begin{equation}
\label{eq:R_recurrence}
 \begin{split}
  R^n_{t+1,u,v} & = tR^{n+1}_{t-1,u,v} + X_{PC} R^{n+1}_{tuv} \\
  R^n_{t,u+1,v} & = uR^{n+1}_{t,u-1,v} + Y_{PC} R^{n+1}_{tuv} \\
  R^n_{t,u,v+1} & = vR^{n+1}_{t,u,v-1} + Z_{PC} R^{n+1}_{tuv}.
 \end{split}
\end{equation}
The first of these are derived as follows

\begin{align}
 R^{n}_{t+1,u,v} & = (-2p)^n\frac{\partial^{t+u+v}}{\partial P_x^t \partial P_y^u \partial P_z^v} [2pX_{PC}F'_n(pR_{PC}^2)] \\
                 & = (-2p)^{n+1}\frac{\partial^{t+u+v}}{\partial P_x^t\partial P_y^u \partial P_z^v}\Big[X_{PC}F_{n+1}(pR_{PC}^2)\Big] \\
                 & = (-2p)^{n+1}\frac{\partial^{u+v}}{\partial P_y^u \partial P_z^v}\Big[t\frac{\partial^{t-1}}{\partial P_x^{t-1}} + X_{PC}\frac{\partial^t}{\partial P_x^t}\Big]F_{n+1}(pR_{PC}^2) \\
                 & = tR^{n+1}_{t-1,u,v} + X_{PC}R^{n+1}_{tuv},
\end{align}
where we have used equation (\ref{eq:derivation_rule}) and the fact that $F'_n(x) = -F_{n+1}(x)$.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, two-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

Finally we show how to calculate the Coulomb integral due to the interaction between the electrons. It is given by

\begin{equation}
\begin{split}
  g_{acbd} & = \langle G_a G_c\vert \frac{1}{r_{12}}\vert G_b G_d\rangle \\
           & = \int\int \frac{\Omega_{ab}(\vec r_1)\Omega_{cd}(\vec r_2)}{r_{12}} d\vec r_1 d\vec r_2 \\
           & = \sum_{tuv}\sum_{\tau\nu\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}\int\int\frac{\Lambda_{tuv}(p,\vec r_{1P})\Lambda_{\tau\nu\phi}(q,\vec r_{2Q})}{r_{12}}d \vec r_1 d\vec r_2 \\
           & = \sum_{tuv}\sum_{\tau\nu\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}\frac{\partial^{t+u+v}}{\partial P_x^t \partial P_y^u \partial P_z^v}
                \frac{\partial^{\tau+\nu+\phi}}{\partial Q_x^\tau \partial Q_y^\nu \partial Q_z^\phi} \\
           &    \hspace{30mm} \int\int\frac{\exp(-pr^2_{1P})\exp(-qr^2_{2Q})}{r_{12}}d \vec r_1 d\vec r_2,
\end{split}
\end{equation}
where, similar to $p$ and $\vec r_{1P}$, we have defined

\begin{equation}
 \begin{split}
    q = & c + d\\
  \vec r_{2Q} = & \vec r_2 - \vec Q \\
  \vec Q = & \frac{c\,\vec C + d\,\vec D}{c + d}.
 \end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, two-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

Thus we need to evaluate the integral

\begin{equation}
 V_{pq} = \int\int\frac{\exp(-pr^2_{1P})\exp(-qr^2_{2Q})}{r_{12}}d \vec r_1 d\vec r_2.
\end{equation}
By first integrating over $\vec r_1$ and using equation (\ref{eq:V_p}) this can be written as

\begin{equation}
 V_{pq} = \int\Big(\frac{2\pi}{p}\int_0^1\exp(-p\,r^2_{2P}\,u^2)\,du\Big)\exp(-qr^2_{2Q}) d \vec r_2.
\end{equation}
Next we change the order of integration and use the Gaussian product theorem to get

\begin{equation}
\begin{split}
 V_{pq} & = \frac{2\pi}{p}\int_0^1\int\exp(-\frac{pqu^2}{pu^2+q}R^2_{PQ})\exp[-(pu^2+q)r_{2S}^2] d\vec r_2 du \\
        & = \frac{2\pi}{p}\int_0^1\exp(-\frac{pqu^2}{pu^2+q}R^2_{PQ})\Big(\frac{\pi}{pu^2+q}\Big)^{3/2} du.
\end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, two-body Coulomb interaction}

% --- begin paragraph admon ---
\paragraph{}

Again, the value of $\vec S$ in $\vec r_{2S} = \vec r_2 - \vec S$ is not relevant. If we now make the change of variables

\begin{equation}
 \frac{v^2}{p+q} = \frac{u^2}{pu^2+q},
\end{equation}
we get the result

\begin{equation}
 V_{pq} = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big).
\end{equation}
From this we get the final answer

\begin{equation}
\begin{split}
 g_{acbd} & = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\sum_{tuv}\sum_{\tau\nu\phi}(-1)^{\tau+\nu+\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi} \\
          & \hspace{40mm} \frac{\partial^{t+u+v+\tau+\nu+\phi}}{\partial P_x^{t+\tau} \partial P_y^{u+\nu} \partial P_z^{v+\phi}}F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big) \\
          & = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\sum_{tuv}\sum_{\tau\nu\phi}(-1)^{\tau+\nu+\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}R_{t+\tau,u+\nu,v+\phi}(\alpha,\vec R_{PQ}),
\end{split}
\end{equation}
where $\alpha = pq/(p+q)$. The term $(-)^{\tau+\nu+\phi}$ arises due to the fact that

\begin{equation}
\frac{\partial}{\partial Q_x} F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big) = - \frac{\partial}{\partial P_x} F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big).
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, two-body Coulomb interaction and Boys function}

% --- begin paragraph admon ---
\paragraph{}

Calculating the Coulomb integrals boils down to evaluating the Boys function

\begin{equation}
 F_n(x) = \int_0^1\exp(-xt^2)\,t^{2n}\,dt.
\end{equation}
Doing this by standard numerical procedures is computationally
expensive and should therefore be avoided. Here we describe a possible way to calculate the Boys function efficiently.

First note that if $x$ is very large, the function value will hardly be affected by changing the upper limit of the integral from $1$ to $\infty$. Doing this is useful
since the integral can be calculated exactly. Thus, we have the following approximation for the Boys function for large $x$:

\begin{equation}
 F_n(x) \approx \frac{(2n-1)!!}{2^{n+1}}\sqrt{\frac{\pi}{x^{2n+1}}}. \hspace{15mm} (x\hspace{2mm}\mathrm{large})
\end{equation}
For small values of $x$ there seems to be no escape from numerical calculation. However, instead of doing the integral real time, it can be tabulated for regular values of $x$.
For values between the tabulated ones, the function can be calculated by a Taylor expansion centered at the nearest tabulated point $x_t$:

\begin{equation}
 F_n(x_t+\Delta x) = \sum_{k=0}^\infty\frac{F_{n+k}(x_t) (-\Delta x)^k}{k!}. \hspace{15mm} (x\hspace{2mm}\mathrm{small})
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, two-body Coulomb interaction and Boys function}

% --- begin paragraph admon ---
\paragraph{}

The computational cost can be reduced even further by calculating the Boys function according to the description above only for the highest values of $n$ needed; for lower values of $n$ the function
can be found via the recursion relation

\begin{equation}
 F_n(x) = \frac{2xF_{n+1}(x)+e^{-x}}{2n+1},
\end{equation}
which can be shown by integrating the function by parts.
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, summarizing}

% --- begin paragraph admon ---
\paragraph{}

The Gaussian functions are given by

\begin{equation}
 \begin{split}
  G_a(\vec r) & = G_{ikm}(a, \vec r_A) = x^i_A\,y^j_A\,z^k_A\exp(-a r^2_A), \\
  G_b(\vec r) & = G_{jln}(b, \vec r_B) = x^i_B\,y^j_B\,z^k_B\exp(-b r^2_B),
 \end{split}
\end{equation}
where $\vec r_A = \vec r - \vec A$ and $\vec r_B = \vec r - \vec B$. We further define

\begin{equation}
\begin{split}
  p & = a + b, \\
 \vec P & = \frac{a\vec A + b\vec B}{a + b}.
\end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, summarizing}

% --- begin paragraph admon ---
\paragraph{}

The overlap integral

\begin{equation}
 S_{ab} = \langle G_a|G_b\rangle
\end{equation}
is calculated as

\begin{equation}
 S_{ab} = E^{ij}_0\,E^{kl}_0\,E^{mn}_0\,\Big(\frac{\pi}{p}\Big)^{3/2},
\end{equation}
where

\begin{equation}
 E^{i=0,j=0}_0 = \exp(-\frac{ab}{a+b}X_{AB}^2),
\end{equation}
and the desired coefficients are found via

\begin{equation}
\begin{split}
 E^{i+1,j}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PA}E^{ij}_t + (t+1)E^{ij}_{t+1}, \\
 E^{i,j+1}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PB}E^{ij}_t + (t+1)E^{ij}_{t+1}.
\end{split}
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, summarizing}

% --- begin paragraph admon ---
\paragraph{}

The kinetic integral is calculated as

\begin{equation}
 T_{ab} = -\frac{1}{2}(T_{ij}\,S_{kl}\,S_{mn} + S_{ij}\,T_{kl}\,S_{mn} + S_{ij}\,S_{kl}\,T_{mn}),
\end{equation}
where

\begin{equation}
 T_{ij} = 4b^2\,S_{i,j+2} - 2b(2j + 1)S_{i,j} + j(j-1)S_{i,j-2}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Integral evaluations, summarizing}

% --- begin paragraph admon ---
\paragraph{}

The Coulomb integral

\begin{equation}
 V_{ab} = \langle G_a\vert\frac{1}{r_C}\vert G_b\rangle
\end{equation}
is calculated as
\begin{equation}
 V_{ab} = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv} R_{tuv}(p,\vec R_{PC}),
\end{equation}
where

\begin{equation}
 E^{ab}_{tuv} = E^{ij}_t\,E^{kl}_u\,E^{mn}_v,
\end{equation}
and $R_{tuv}(p,\vec R_{PC})$ is found by first calculating the source term

\begin{equation}
 R^n_{000}(p,\vec R_{PC}) = (-2p)^n\,F_n(p R^2_{PC})
\end{equation}
and then iterating towards the target $R^0_{tuv}(p,\vec R_{PC}) = R_{tuv}(p,\vec R_{PC})$ via the recurrence relations

\begin{equation}
 \begin{split}
  R^n_{t+1,u,v} & = tR^{n+1}_{t-1,u,v} + X_{PC} R^{n+1}_{tuv}, \\
  R^n_{t,u+1,v} & = uR^{n+1}_{t,u-1,v} + Y_{PC} R^{n+1}_{tuv}, \\
  R^n_{t,u,v+1} & = vR^{n+1}_{t,u,v11} + Z_{PC} R^{n+1}_{tuv}.
 \end{split}
\end{equation}
% --- end paragraph admon ---


% !split
\subsection{Integral evaluations, summarizing}

% --- begin paragraph admon ---
\paragraph{}

The Coulomb integral

\begin{equation}
 g_{acbd} = \langle G_a G_c\vert \frac{1}{r_{12}}\vert G_b G_d\rangle
\end{equation}
is calculated as
\begin{equation}
 g_{acbd} = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\sum_{tuv}\sum_{\tau\nu\phi}(-1)^{\tau+\nu+\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}R_{t+\tau,u+\nu,v+\phi}(\alpha,\vec R_{PQ}),
\end{equation}
where

\begin{equation}
  \alpha = \frac{pq}{p + q}.
\end{equation}
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

Till now we have mainly dealt with the Hartree-Fock equations using anti-symmetrized matrix elements. Since the Hamiltonian does not 
contain operators acting on the spin states, it is common to write out the spin-degrees of freedom in an explicit way.

We wrote the Hartree-Fock equations as

\begin{equation*}
  \hat{h}^{HF}(x_i) \psi_{p}(x_i) = \epsilon_{p}\psi_{p}(x_i),
\end{equation*}
with

\begin{equation*}
  \hat{h}^{HF}(x_i)= \hat{h}_0(x_i) + \sum_{j=1}^NV_{j}^{d}(x_i) -
  \sum_{j=1}^NV_{j}^{ex}(x_i),
\end{equation*}
and where $\hat{h}_0(i)$ is the one-body part.
In this equations we include both spin and spatial degrees of freedom.

The direct part is defined as

\begin{equation*}
  V_{p}^{d}(x_i) = \int \psi_{p}^*(x_j)\psi_{p}(x_j)\hat{v}(r_{ij}) dx_j
\end{equation*}
while the exchange operator (or Fock operator) is

\begin{equation*}
  V_{p}^{ex}(x_i) \psi_{q}(x_i) 
  = \left(\int \psi_{p}^*(x_j) 
  \hat{v}(r_{ij})\psi_{q}(x_j)
  dx_j\right)\psi_{p}(x_i).
\end{equation*}
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}
If now deal explicitely with the spin degrees of freedom, we can write the single-particle state
\[
\psi_{p}(x_i) = \phi_{p}(\mathbf{r}_i)\xi_{\sigma_i},
\]
where $\xi_{\sigma_i}$ is a standard Pauli spinor. Since we have only two possible spin values, the direct terms reduces then to
(recall that we have defined $\int dx_j = \sum_{\sigma_j} \int d \mathbf{r}_j$)
\[
  V_{p}^{d}(\mathbf{r}_i)\phi_{q}(\mathbf{r}_i) = 2\int \phi_{p}^*(\mathbf{r}_j)\phi_{p}(\mathbf{r}_i)\hat{v}(r_{ij}) d\mathbf{r}_j\phi_{q}(\mathbf{r}_i)
\]
while the exchange operator (or Fock operator) is
\[
  V_{p}^{ex}(\mathbf{r}_i) \phi_{q}(\mathbf{r}_i) = \left(\int \phi_{p}^*(\mathbf{r}_j) 
  \hat{v}(r_{ij})\phi_{q}(\mathbf{r}_j)
  d\mathbf{r}_j\right)\phi_{p}\mathbf{r}_i).
\]
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

In our Hartree-Fock calculation we expand the single-particle functions in terms of known basis functions (hydrogen-like one, STOs, GTOs etc), namely

\begin{equation*}
\phi_{p}(\mathbf{r}_i) = \sum_{k=1}^{d}C_{pk}\chi_k(\mathbf{r}_i),
\end{equation*}
$d$ is the number of basis functions $\chi_k(\mathbf{r}_i)$. The Hartree-Fock equations become then

\begin{equation*}
\hat{h}^{HF}\hat{C}_p=\epsilon^{HF}\hat{S}\hat{C}_p,
\end{equation*}
where $\hat{S}$ is the overlap matrix needed in case the basis functions $\chi_k(\mathbf{r}_i)$ are not normalized (typically, GTOs are not). 
Our Hartree-Fock Hamiltonian leads then to matrix elements (in a bra-ket notation)

\[
\langle p | \hat{h}^{HF} | q \rangle = \langle p|\hat{h}_0|q\rangle +\sum_{k\le F}\sum_{rs}C_{kr}^*C_{ks}\left(2\langle pr | \hat{v}|qs\rangle-\langle pr | \hat{v}|sq\rangle\right),
\]
with

\[
\langle p|\hat{h}_0|q\rangle = \int \chi_{p}^*(\mathbf{r}_j)\left(-\frac{1}{2}\nabla^2-\frac{Z}{\mathbf{r}_j}  \right)\chi_{q}(\mathbf{r}_j)
  d\mathbf{r}_j.
\]
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

The other integrals are

\begin{equation*}
\langle pr | \hat{v}|qs\rangle = \int\int \chi_{p}^*(\mathbf{r}_i)\chi_{q}^*(\mathbf{r}_j)\hat{v}(r_{ij})\chi_{r}(\mathbf{r}_i)\chi_{s}(\mathbf{r}_j)
  d\mathbf{r}_id\mathbf{r}_j.
\end{equation*}
If we then introduce the density matrix defined as

\begin{equation*}
D_{pq}=\sum_{k\le F}C_{kp}C_{kq}^*,
\end{equation*}
we can rewrite the Hartree-Fock matrix elements as

\begin{equation*}
\langle p | \hat{h}^{HF} | q \rangle = \langle p|\hat{h}_0|q\rangle +\sum_{rs}D_{rs}\left(2\langle pr | \hat{v}|qs\rangle-\langle pr | \hat{v}|sq\rangle\right),
\end{equation*}
meaning that the only quantity we need to calculate at every
interation is the density matrix, which is evaluated using the eigenvector 
obtained from the diagonalization of the Hartree-Fock matrix.
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

From an algorithmic point of view, we see now that we need, with our GTO basis, to evaluate 

\begin{itemize}
  \item The overlap matrix $\hat{S}$.

  \item The kinetic energy and one-body interaction matrix elements $\langle p|hat{h}_0|q\rangle $ and finally the

  \item two-body interaction matrix elements $\langle pr | \hat{v}|qs\rangle$.
\end{itemize}

\noindent
All these elements can be computed once and for all and stored in
memory. The overlap matrix $S$ and the one-body matrix elements
$\langle p|\hat{h}_0|q\rangle $ can be stored as simple
one-dimensional arrays, or alternatively as matrices of small
dimensions.  The time-consuming part in the Hartree-Fock calculations
involves the calculation of the two-body matrix. Furthermore, the
storage of these matrix elements plays also an important role, in
particular we wish to access the table of matrix elements as fast as
possible.
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

In a brute force algorithm for storing the matrix elements, if we have $d$ basis functions, we end up with the need of storing 
$d^4$ matrix elements. We can reduce this considerably by the following considerations.
In the calculation of the two-body matrix elements $\langle pr | \hat{v}|qs\rangle$ we have the following symmetries

\begin{itemize}
  \item Invariance under permutations, that is  
\end{itemize}

\noindent
\begin{equation*} \langle pr | \hat{v}|qs\rangle = \langle rp | \hat{v}|sq\rangle.
\end{equation*}
\begin{itemize}
  \item The functions entering the evaluation of the integrals are all real, meaning that if we interchange $p\leftrightarrow q$ or  $r\leftrightarrow s$, we end up with the same matrix element.
\end{itemize}

\noindent
This reduces by a factor of eight the total number of matrix elements to be stored.
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

Furthermore, in setting up a table for the two-body matrix elements we can convert the need of using four indices $pqrs$ of 
$\langle pr | \hat{v}|qs\rangle$, which in a brute forces way could be coded as a four-dimensional array, to 
a two-dimensional array $V_{lm}$, where $l$ and $m$ stand for all possible two-body configurations $pq$.

Each number $l$ and $m$ in $V_{lm}$  should then point to a set of single-particle  states $(p,q)$ and $(r,s)$.  

In our case, since we have 
symmetries which allow us to set $p\le q$, we have, with $d$ single particle states a total of $d(d+1)/2$ two-body configurations.
How do we store such a matrix? The simplest thing to do is to convert it into a one-dimensional array. How do we achieve that?
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

We now have a matrix $V$ of dimension $n\times n$ and we want to store the elements $V_{lm}$ as a one-dimensional array $A$ using
$0 \le l \le m \le n-1$. For

\begin{itemize}
  \item $l=0$ we have $n$ elements

  \item $l=1$ we have $n-1$ elements

  \item $\dots$

  \item $l=\nu$ we have $n-\nu$ elements

  \item $\dots$

  \item $l=n-1$ we have $1$ element,
\end{itemize}

\noindent
and the total number is

\begin{equation*}
\sum_{\nu =0}^{n-1}\left(n-\nu\right)=\frac{n(n+1)}{2}.
\end{equation*}
% --- end paragraph admon ---



% !split
\subsection{Hartree-Fock equations with spin degrees of freedom}

% --- begin paragraph admon ---
\paragraph{}

To find the number ($\mathrm{number}(l,m)$) in a one-dimensional array $A$ which corresponds to a matrix element $V_{lm}$, we note that

\begin{equation*}
\mathrm{number}(l,m)=\sum_{\nu =0}^{l-1}\left(n-\nu\right)+m-l=\frac{l(2n-l-1)}{2}+m.
\end{equation*}
The first matrix element $V(0,0)$ is obviously given by the element $A(0)$. 

We have thus reduced a four dimensional array to a one-dimensional array, where the given pairs $(p,q)$ and $(r,s)$ point to the matrix indices $l$
and $m$, respectively. The latter are used to find the explicit number $\mathrm{number}(l,m)$ which points to the desired matrix element stored 
in a one-dimensional array.
% --- end paragraph admon ---



% !split
\subsection{Exercises: Derivation of Hartree-Fock equations}

% --- begin paragraph admon ---
\paragraph{Exercise 1.}
Consider a Slater determinant built up of single-particle orbitals $\psi_{\lambda}$, 
with $\lambda = 1,2,\dots,N$.

The unitary transformation
\[
\psi_a  = \sum_{\lambda} C_{a\lambda}\phi_{\lambda},
\]
brings us into the new basis.  
The new basis has quantum numbers $a=1,2,\dots,N$.
Show that the new basis is orthonormal.
Show that the new Slater determinant constructed from the new single-particle wave functions can be
written as the determinant based on the previous basis and the determinant of the matrix $C$.
Show that the old and the new Slater determinants are equal up to a complex constant with absolute value unity.
(Hint, $C$ is a unitary matrix).
% --- end paragraph admon ---



% !split
\subsection{Exercises: Derivation of Hartree-Fock equations}

% --- begin paragraph admon ---
\paragraph{Exercise 2.}
Consider the  Slater  determinant
\[
\Phi_{0}=\frac{1}{\sqrt{n!}}\sum_{p}(-)^{p}P
\prod_{i=1}^{n}\psi_{\alpha_{i}}(x_{i}).
\]
A small variation in this function is given by
\[
\delta\Phi_{0}=\frac{1}{\sqrt{n!}}\sum_{p}(-)^{p}P
\psi_{\alpha_{1}}(x_{1})\psi_{\alpha_{2}}(x_{2})\dots
\psi_{\alpha_{i-1}}(x_{i-1})(\delta\psi_{\alpha_{i}}(x_{i}))
\psi_{\alpha_{i+1}}(x_{i+1})\dots\psi_{\alpha_{n}}(x_{n}).
\]
Show that
\[
\langle \delta\Phi_{0}|\sum_{i=1}^{n}\left\{t(x_{i})+u(x_{i})
\right\}+\frac{1}{2}
\sum_{i\neq j=1}^{n}v(x_{i},x_{j})|\Phi_{0}\rangle=\sum_{i=1}^{n}\langle \delta\psi_{\alpha_{i}}|\hat{t}+\hat{u}
|\phi_{\alpha_{i}}\rangle
+\sum_{i\neq j=1}^{n}\left\{\langle\delta\psi_{\alpha_{i}}
\psi_{\alpha_{j}}|\hat{v}|\psi_{\alpha_{i}}\psi_{\alpha_{j}}\rangle-
\langle\delta\psi_{\alpha_{i}}\psi_{\alpha_{j}}|\hat{v}
|\psi_{\alpha_{j}}\psi_{\alpha_{i}}\rangle\right\}
\]
% --- end paragraph admon ---




% ------------------- end of main content ---------------


\printindex

\end{document}

