TITLE: Hartree-Fock methods
AUTHOR:   Morten Hjorth-Jensen, National Superconducting Cyclotron Laboratory and Department of Physics and Astronomy, Michigan State University, East Lansing, MI 48824, USA & Department of Physics, University of Oslo, Oslo, Norway 
DATE: Spring 2015

!split
===== Why Hartree-Fock? Derivation of Hartree-Fock equations in coordinate space =====
!bblock
Hartree-Fock (HF) theory is an algorithm for finding an approximative expression for the ground state of a given Hamiltonian. The basic ingredients are
 *  Define a single-particle basis $\{\psi_{\alpha}\}$ so that
!bt
\[ 
\hat{h}^{\mathrm{HF}}\psi_{\alpha} = \varepsilon_{\alpha}\psi_{\alpha}
\]
!et
with the Hartree-Fock Hamiltonian defined as
!bt
\[
\hat{h}^{\mathrm{HF}}=\hat{t}+\hat{u}_{\mathrm{ext}}+\hat{u}^{\mathrm{HF}}
\]
!et
 *  The term  $\hat{u}^{\mathrm{HF}}$ is a single-particle potential to be determined by the HF algorithm.
 *  The HF algorithm means to choose $\hat{u}^{\mathrm{HF}}$ in order to have 
!bt
\[ \langle \hat{H} \rangle = E^{\mathrm{HF}}= \langle \Phi_0 | \hat{H}|\Phi_0 \rangle
\]
!et
that is to find a local minimum with a Slater determinant $\Phi_0$ being the ansatz for the ground state. 
 *  The variational principle ensures that $E^{\mathrm{HF}} \ge E_0$, with $E_0$ the exact ground state energy.
!eblock


!split
===== Why Hartree-Fock? Derivation of Hartree-Fock equations in coordinate space =====
!bblock
We will show that the Hartree-Fock Hamiltonian $\hat{h}^{\mathrm{HF}}$ equals our definition of the operator $\hat{f}$ discussed in connection with the new definition of the normal-ordered Hamiltonian (see later lectures), that is we have, for a specific matrix element
!bt
\[
\langle p |\hat{h}^{\mathrm{HF}}| q \rangle =\langle p |\hat{f}| q \rangle=\langle p|\hat{t}+\hat{u}_{\mathrm{ext}}|q \rangle +\sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS},
\]
!et
meaning that
!bt
\[
\langle p|\hat{u}^{\mathrm{HF}}|q\rangle = \sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS}.
\]
!et
The so-called Hartree-Fock potential $\hat{u}^{\mathrm{HF}}$ brings an explicit medium dependence due to the summation over all single-particle states below the Fermi level $F$. It brings also in an explicit dependence on the two-body interaction (in nuclear physics we can also have complicated three- or higher-body forces). The two-body interaction, with its contribution from the other bystanding fermions, creates an effective mean field in which a given fermion moves, in addition to the external potential $\hat{u}_{\mathrm{ext}}$ which confines the motion of the fermion. For systems like nuclei, there is no external confining potential. Nuclei are examples of self-bound systems, where the binding arises due to the intrinsic nature of the strong force. For nuclear systems thus, there would be no external one-body potential in the Hartree-Fock Hamiltonian. 
!eblock

!split
===== Variational Calculus and Lagrangian Multipliers  =====
!bblock 
The calculus of variations involves 
problems where the quantity to be minimized or maximized is an integral. 

In the general case we have an integral of the type
!bt
\[ 
E[\Phi]= \int_a^b f(\Phi(x),\frac{\partial \Phi}{\partial x},x)dx,
\]
!et
where $E$ is the quantity which is sought minimized or maximized.
The problem is that although $f$ is a function of the variables $\Phi$, $\partial \Phi/\partial x$ and $x$, the exact dependence of
$\Phi$ on $x$ is not known.  This means again that even though the integral has fixed limits $a$ and $b$, the path of integration is
not known. In our case the unknown quantities are the single-particle wave functions and we wish to choose an integration path which makes
the functional $E[\Phi]$ stationary. This means that we want to find minima, or maxima or saddle points. In physics we search normally for minima.
Our task is therefore to find the minimum of $E[\Phi]$ so that its variation $\delta E$ is zero  subject to specific
constraints. In our case the constraints appear as the integral which expresses the orthogonality of the  single-particle wave functions.
The constraints can be treated via the technique of Lagrangian multipliers
!eblock


!split
===== Variational Calculus and Lagrangian Multipliers  =====
!bblock 
Let us specialize to the expectation value of the energy for one particle in three-dimensions.
This expectation value reads
!bt
\[
  E=\int dxdydz \psi^*(x,y,z) \hat{H} \psi(x,y,z),
\]
!et
with the constraint
!bt
\[
 \int dxdydz \psi^*(x,y,z) \psi(x,y,z)=1,
\]
!et
and a Hamiltonian
!bt
\[
\hat{H}=-\frac{1}{2}\nabla^2+V(x,y,z).
\]
!et
We will, for the sake of notational convenience,  skip the variables $x,y,z$ below, and write for example $V(x,y,z)=V$.
!eblock

!split
===== Variational Calculus and Lagrangian Multipliers  =====
!bblock 
The integral involving the kinetic energy can be written as, with the function $\psi$ vanishing
strongly for large values of $x,y,z$ (given here by the limits $a$ and $b$), 
!bt
 \[
  \int_a^b dxdydz \psi^* \left(-\frac{1}{2}\nabla^2\right) \psi dxdydz = \psi^*\nabla\psi|_a^b+\int_a^b dxdydz\frac{1}{2}\nabla\psi^*\nabla\psi.
\]
!et
We will drop the limits $a$ and $b$ in the remaining discussion. 
Inserting this expression into the expectation value for the energy and taking the variational minimum  we obtain
!bt
\[
\delta E = \delta \left\{\int dxdydz\left( \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi\right)\right\} = 0.
\]
!et
!eblock

!split
===== Variational Calculus and Lagrangian Multipliers  =====
!bblock 
The constraint appears in integral form as 
!bt
\[
 \int dxdydz \psi^* \psi=\mathrm{constant},
\]
!et
and multiplying with a Lagrangian multiplier $\lambda$ and taking the variational minimum we obtain the final variational equation
!bt
\[
\delta \left\{\int dxdydz\left( \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi-\lambda\psi^*\psi\right)\right\} = 0.
\]
!et
We introduce the function  $f$
!bt
\[
  f =  \frac{1}{2}\nabla\psi^*\nabla\psi+V\psi^*\psi-\lambda\psi^*\psi=
\frac{1}{2}(\psi^*_x\psi_x+\psi^*_y\psi_y+\psi^*_z\psi_z)+V\psi^*\psi-\lambda\psi^*\psi,
\]
!et
where we have skipped the dependence on $x,y,z$ and introduced the shorthand $\psi_x$, $\psi_y$ and $\psi_z$  for the various derivatives.
!eblock

!split
===== Variational Calculus and Lagrangian Multipliers  =====
!bblock 
For $\psi^*$ the Euler-Lagrange  equations yield
!bt
\[
\frac{\partial f}{\partial \psi^*}- \frac{\partial }{\partial x}\frac{\partial f}{\partial \psi^*_x}-\frac{\partial }{\partial y}\frac{\partial f}{\partial \psi^*_y}-\frac{\partial }{\partial z}\frac{\partial f}{\partial \psi^*_z}=0,
\] 
!et
which results in 
!bt
\[
    -\frac{1}{2}(\psi_{xx}+\psi_{yy}+\psi_{zz})+V\psi=\lambda \psi.
\]
!et
We can then identify the  Lagrangian multiplier as the energy of the system. The last equation is 
nothing but the standard 
Schroedinger equation and the variational  approach discussed here provides 
a powerful method for obtaining approximate solutions of the wave function.
!eblock




!split
===== Definitions and notations =====
!bblock
Before we proceed we need some definitions.
We will assume that the interacting part of the Hamiltonian
can be approximated by a two-body interaction.
This means that our Hamiltonian is written as the sum of some onebody part and a twobody part
!bt
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^N \hat{h}_0(x_i) + \sum_{i < j}^N \hat{v}(r_{ij}),
label{Hnuclei}
\end{equation}
!et
with 
!bt
\begin{equation}
  H_0=\sum_{i=1}^N \hat{h}_0(x_i).
label{hinuclei}
\end{equation}
!et
The onebody part $u_{\mathrm{ext}}(x_i)$ is normally approximated by a harmonic oscillator potential or the Coulomb interaction an electron feels from the nucleus. However, other potentials are fully possible, such as 
one derived from the self-consistent solution of the Hartree-Fock equations to be discussed here.
!eblock


!split
===== Definitions and notations =====
!bblock
Our Hamiltonian is invariant under the permutation (interchange) of two particles.
Since we deal with fermions however, the total wave function is antisymmetric.
Let $\hat{P}$ be an operator which interchanges two particles.
Due to the symmetries we have ascribed to our Hamiltonian, this operator commutes with the total Hamiltonian,
!bt 
\[
[\hat{H},\hat{P}] = 0,
 \]
!et
meaning that $\Psi_{\lambda}(x_1, x_2, \dots , x_A)$ is an eigenfunction of 
$\hat{P}$ as well, that is
!bt 
\[
\hat{P}_{ij}\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A)=
\beta\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A),
\]
!et
where $\beta$ is the eigenvalue of $\hat{P}$. We have introduced the suffix $ij$ in order to indicate that we permute particles $i$ and $j$.
The Pauli principle tells us that the total wave function for a system of fermions
has to be antisymmetric, resulting in the eigenvalue $\beta = -1$.   
!eblock

!split
===== Definitions and notations =====
!bblock
In our case we assume that  we can approximate the exact eigenfunction with a Slater determinant
!bt
\begin{equation}
   \Phi(x_1, x_2,\dots ,x_A,\alpha,\beta,\dots, \sigma)=\frac{1}{\sqrt{N!}}
\left| \begin{array}{ccccc} \psi_{\alpha}(x_1)& \psi_{\alpha}(x_2)& \dots & \dots & \psi_{\alpha}(x_A)\\
                            \psi_{\beta}(x_1)&\psi_{\beta}(x_2)& \dots & \dots & \psi_{\beta}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{\sigma}(x_1)&\psi_{\sigma}(x_2)& \dots & \dots & \psi_{\sigma}(x_A)\end{array} \right|, label{eq:HartreeFockDet}
\end{equation}
!et
where  $x_i$  stand for the coordinates and spin values of a particle $i$ and $\alpha,\beta,\dots, \gamma$ 
are quantum numbers needed to describe remaining quantum numbers.  
!eblock

!split
===== Definitions and notations =====
!bblock
The single-particle function $\psi_{\alpha}(x_i)$  are eigenfunctions of the onebody
Hamiltonian $h_i$, that is
!bt 
\[
\hat{h}_0(x_i)=\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i),
\]
!et
with eigenvalues 
!bt 
\[
\hat{h}_0(x_i) \psi_{\alpha}(x_i)=\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i).
\]
!et
The energies $\varepsilon_{\alpha}$ are the so-called non-interacting single-particle energies, or unperturbed energies. 
The total energy is in this case the sum over all  single-particle energies, if no two-body or more complicated
many-body interactions are present.
!eblock

!split
===== Definitions and notations =====
!bblock
Let us denote the ground state energy by $E_0$. According to the
variational principle we have
!bt
\[
  E_0 \le E[\Phi] = \int \Phi^*\hat{H}\Phi d\mathbf{\tau}
\]
!et
where $\Phi$ is a trial function which we assume to be normalized
!bt
\[
  \int \Phi^*\Phi d\mathbf{\tau} = 1,
\]
!et
where we have used the shorthand $d\mathbf{\tau}=dx_1dr_2\dots dr_A$.
!eblock

!split
===== Definitions and notations =====
!bblock
In the Hartree-Fock method the trial function is the Slater
determinant of Eq.~(ref{eq:HartreeFockDet}) which can be rewritten as 
!bt
\[
  \Phi(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{N!}}\sum_{P} (-)^P\hat{P}\psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A)=\sqrt{N!}\hat{A}\Phi_H,
\]
!et
where we have introduced the antisymmetrization operator $\hat{A}$ defined by the 
summation over all possible permutations of two particles.
!eblock

!split
===== Definitions and notations =====
!bblock
It is defined as
!bt
\begin{equation}
  \hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
label{antiSymmetryOperator}
\end{equation}
!et
with $p$ standing for the number of permutations. We have introduced for later use the so-called
Hartree-function, defined by the simple product of all possible single-particle functions
!bt
\[
  \Phi_H(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) =
  \psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A).
\]
!et
!eblock

!split
===== Definitions and notations =====
!bblock
Both $\hat{H}_0$ and $\hat{H}_I$ are invariant under all possible permutations of any two particles
and hence commute with $\hat{A}$
!bt
\begin{equation}
  [H_0,\hat{A}] = [H_I,\hat{A}] = 0. label{commutionAntiSym}
\end{equation}
!et
Furthermore, $\hat{A}$ satisfies
!bt
\begin{equation}
  \hat{A}^2 = \hat{A},  label{AntiSymSquared}
\end{equation}
!et
since every permutation of the Slater
determinant reproduces it. 
!eblock

!split
===== Definitions and notations =====
!bblock
The expectation value of $\hat{H}_0$ 
!bt
\[
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau}
\]
!et
is readily reduced to
!bt
\[
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau},
\]
!et
where we have used Eqs.~(ref{commutionAntiSym}) and
(ref{AntiSymSquared}). The next step is to replace the antisymmetrization
operator by its definition and to
replace $\hat{H}_0$ with the sum of one-body operators
!bt
\[
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{i=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{h}_0\hat{P}\Phi_H d\mathbf{\tau}.
\]
!et
!eblock

!split
===== Definitions and notations =====
!bblock
The integral vanishes if two or more particles are permuted in only one
of the Hartree-functions $\Phi_H$ because the individual single-particle wave functions are
orthogonal. We obtain then
!bt
\[
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}= \sum_{i=1}^N \int \Phi_H^*\hat{h}_0\Phi_H  d\mathbf{\tau}.
\]
!et
Orthogonality of the single-particle functions allows us to further simplify the integral, and we
arrive at the following expression for the expectation values of the
sum of one-body Hamiltonians 
!bt
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{\mu=1}^N \int \psi_{\mu}^*(x)\hat{h}_0\psi_{\mu}(x)dx
  d\mathbf{r}.
  label{H1Expectation}
\end{equation}
!et
!eblock

!split
===== Definitions and notations =====
!bblock
We introduce the following shorthand for the above integral
!bt
\[
\langle \mu | \hat{h}_0 | \mu \rangle = \int \psi_{\mu}^*(x)\hat{h}_0\psi_{\mu}(x)dx,
\]
!et
and rewrite Eq.~(ref{H1Expectation}) as
!bt
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\tau
  = \sum_{\mu=1}^N \langle \mu | \hat{h}_0 | \mu \rangle.
  label{H1Expectation1}
\end{equation}
!et
!eblock

!split
===== Definitions and notations =====
!bblock
The expectation value of the two-body part of the Hamiltonian is obtained in a
similar manner. We have
!bt
\[
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_I\hat{A}\Phi_H d\mathbf{\tau},
\]
!et
which reduces to
!bt
\[
 \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i\le j=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{v}(r_{ij})\hat{P}\Phi_H d\mathbf{\tau},
\]
!et
by following the same arguments as for the one-body
Hamiltonian. 
!eblock

!split
===== Definitions and notations =====
!bblock
Because of the dependence on the inter-particle distance $r_{ij}$,  permutations of
any two particles no longer vanish, and we get
!bt
\[
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i < j=1}^N \int  
  \Phi_H^*\hat{v}(r_{ij})(1-P_{ij})\Phi_H d\mathbf{\tau}.
\]
!et
where $P_{ij}$ is the permutation operator that interchanges
particle $i$ and particle $j$. Again we use the assumption that the single-particle wave functions
are orthogonal. 
!eblock


!split
===== Definitions and notations =====
!bblock
We obtain
!bt
\begin{equation}
\begin{split}
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N
    &\left[ \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j \right.\\
  &\left.
  - \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j
  \right]. label{H2Expectation}
\end{split}
\end{equation}
!et
The first term is the so-called direct term. It is frequently also called the  Hartree term, 
while the second is due to the Pauli principle and is called
the exchange term or just the Fock term.
The factor  $1/2$ is introduced because we now run over
all pairs twice. 
!eblock

!split
===== Definitions and notations =====
!bblock
The last equation allows us to  introduce some further definitions.  
The single-particle wave functions $\psi_{\mu}(x)$, defined by the quantum numbers $\mu$ and $x$
are defined as the overlap 
!bt
\[
   \psi_{\alpha}(x)  = \langle x | \alpha \rangle .
\]
!et
!eblock

!split
===== Definitions and notations =====
!bblock
We introduce the following shorthands for the above two integrals
!bt
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle =  \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j,
\]
!et
and
!bt 
\[
\langle \mu\nu|\hat{v}|\nu\mu\rangle = \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j.  
\]
!et
!eblock










!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
Let us denote the ground state energy by $E_0$. According to the
variational principle we have
!bt
\[
  E_0 \le E[\Phi] = \int \Phi^*\hat{H}\Phi d\mathbf{\tau}
\]
!et
where $\Phi$ is a trial function which we assume to be normalized
!bt
\[
  \int \Phi^*\Phi d\mathbf{\tau} = 1,
\]
!et
where we have used the shorthand $d\mathbf{\tau}=dx_1dx_2\dots dx_A$.
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
In the Hartree-Fock method the trial function is a Slater
determinant which can be rewritten as 
!bt
\[
  \Psi(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{N!}}\sum_{P} (-)^PP\psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A)=\sqrt{N!}\hat{A}\Phi_H,
\]
!et
where we have introduced the anti-symmetrization operator $\hat{A}$ defined by the 
summation over all possible permutations *p* of two fermions.
It is defined as
!bt
\[
  \hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
\]
!et
with the the Hartree-function given by the simple product of all possible single-particle function
!bt
\[
  \Phi_H(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) =
  \psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A).
\]
!et
!eblock




!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
Our functional is written as
!bt
\[
  E[\Phi] = \sum_{\mu=1}^N \int \psi_{\mu}^*(x_i)\hat{h}_0(x_i)\psi_{\mu}(x_i) dx_i 
  + \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N
   \left[ \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)dx_idx_j- \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
 \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)dx_idx_j\right]
\]
!et
The more compact version reads
!bt
\[
  E[\Phi] 
  = \sum_{\mu}^N \langle \mu | \hat{h}_0 | \mu\rangle+ \frac{1}{2}\sum_{\mu\nu}^N\left[\langle \mu\nu |\hat{v}|\mu\nu\rangle-\langle \nu\mu |\hat{v}|\mu\nu\rangle\right].
\]
!et
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
Since the interaction is invariant under the interchange of two particles it means for example that we have
!bt
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle =  \langle \nu\mu|\hat{v}|\nu\mu\rangle,  
\]
!et
or in the more general case
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle =  \langle \nu\mu|\hat{v}|\tau\sigma\rangle.  
\]
!et
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
The direct and exchange matrix elements can be  brought together if we define the antisymmetrized matrix element
!bt
\[
\langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS}= \langle \mu\nu|\hat{v}|\mu\nu\rangle-\langle \mu\nu|\hat{v}|\nu\mu\rangle,
\]
!et
or for a general matrix element  
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{AS}= \langle \mu\nu|\hat{v}|\sigma\tau\rangle-\langle \mu\nu|\hat{v}|\tau\sigma\rangle.
\]
!et
It has the symmetry property
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{AS}= -\langle \mu\nu|\hat{v}|\tau\sigma\rangle_{AS}=-\langle \nu\mu|\hat{v}|\sigma\tau\rangle_{AS}.
\]
!et
The antisymmetric matrix element is also hermitian, implying 
!bt
\[
\langle \mu\nu|\hat{v}|\sigma\tau\rangle_{AS}= \langle \sigma\tau|\hat{v}|\mu\nu\rangle_{AS}.
\]
!et
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
With these notations we rewrite the Hartree-Fock functional as
!bt
\begin{equation}
  \int \Phi^*\hat{H_I}\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS}. label{H2Expectation2}
\end{equation}
!et

Adding the contribution from the one-body operator $\hat{H}_0$ to
(ref{H2Expectation2}) we obtain the energy functional 
!bt
\begin{equation}
  E[\Phi] 
  = \sum_{\mu=1}^N \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS}. label{FunctionalEPhi}
\end{equation}
!et 
In our coordinate space derivations below we will spell out the Hartree-Fock equations in terms of their integrals.
!eblock


!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
If we generalize the Euler-Lagrange equations to more variables 
and introduce $N^2$ Lagrange multipliers which we denote by 
$\epsilon_{\mu\nu}$, we can write the variational equation for the functional of $E$
!bt
\[
  \delta E - \sum_{\mu\nu}^N \epsilon_{\mu\nu} \delta
  \int \psi_{\mu}^* \psi_{\nu} = 0.
\]
!et
For the orthogonal wave functions $\psi_{i}$ this reduces to
!bt
\[
  \delta E - \sum_{\mu=1}^N \epsilon_{\mu} \delta
  \int \psi_{\mu}^* \psi_{\mu} = 0.
\]
!et
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
Variation with respect to the single-particle wave functions $\psi_{\mu}$ yields then
!bt
\[
  \sum_{\mu=1}^N \int \delta\psi_{\mu}^*\hat{h_0}(x_i)\psi_{\mu}
  dx_i  
  + \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \left[ \int
  \delta\psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\psi_{\mu}\psi_{\nu} dx_idx_j- \int
  \delta\psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\psi_{\nu}\psi_{\mu}
  dx_idx_j \right]+ 
\]
!et
!bt
\[
\sum_{\mu=1}^N \int \psi_{\mu}^*\hat{h_0}(x_i)\delta\psi_{\mu}
  dx_i 
  + \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \left[ \int
  \psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\delta\psi_{\mu}\psi_{\nu} dx_idx_j- \int
  \psi_{\mu}^*\psi_{\nu}^*\hat{v}(r_{ij})\psi_{\nu}\delta\psi_{\mu}
  dx_idx_j \right]-  \sum_{{\mu}=1}^N E_{\mu} \int \delta\psi_{\mu}^*
  \psi_{\mu}dx_i
  -  \sum_{{\mu}=1}^N E_{\mu} \int \psi_{\mu}^*
  \delta\psi_{\mu}dx_i = 0.
\]
!et
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
Although the variations $\delta\psi$ and $\delta\psi^*$ are not
independent, they may in fact be treated as such, so that the 
terms dependent on either $\delta\psi$ and $\delta\psi^*$ individually 
may be set equal to zero. To see this, simply 
replace the arbitrary variation $\delta\psi$ by $i\delta\psi$, so that
$\delta\psi^*$ is replaced by $-i\delta\psi^*$, and combine the two
equations. We thus arrive at the Hartree-Fock equations
!bt
\begin{equation}
\left[ -\frac{1}{2}\nabla_i^2+ \sum_{\nu=1}^N\int \psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\nu}(x_j)dx_j \right]\psi_{\mu}(x_i) - \left[ \sum_{{\nu}=1}^N \int\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_j) dx_j\right] \psi_{\nu}(x_i) = \epsilon_{\mu} \psi_{\mu}(x_i).  label{eq:hartreefockcoordinatespace}
\end{equation}
!et
Notice that the integration $\int dx_j$ implies an
integration over the spatial coordinates $\mathbf{r_j}$ and a summation
over the spin-coordinate of fermion $j$. We note that the factor of $1/2$ in front of the sum involving the two-body interaction, has been removed. This is due to the fact that we need to vary both $\delta\psi_{\mu}^*$ and
$\delta\psi_{\nu}^*$. Using the symmetry properties of the two-body interaction and interchanging $\mu$ and $\nu$
as summation indices, we obtain two identical terms. 
!eblock

!split
===== Derivation of Hartree-Fock equations in coordinate space =====
!bblock
The two first terms in the last equation are the one-body kinetic energy and the
electron-nucleus potential. The third or *direct* term is the averaged electronic repulsion of the other
electrons. As written, the
term includes the *self-interaction* of 
electrons when $\mu=\nu$. The self-interaction is cancelled in the fourth
term, or the *exchange* term. The exchange term results from our
inclusion of the Pauli principle and the assumed determinantal form of
the wave-function. Equation (ref{eq:hartreefockcoordinatespace}), in addition to the kinetic energy and the attraction from the atomic nucleus that confines the motion of a single electron,   represents now the motion of a single-particle modified by the two-body interaction. The additional contribution to the Schroedinger equation due to the two-body interaction, represents a mean field set up by all the other bystanding electrons, the latter given by the sum over all single-particle states occupied by $N$ electrons. 

The Hartree-Fock equation is an example of an integro-differential equation. These equations involve repeated calculations of integrals, in addition to the solution of a set of coupled differential equations. 
The Hartree-Fock equations can also be rewritten in terms of an eigenvalue problem. The solution of an eigenvalue problem represents often a more practical algorithm and the  solution of  coupled  integro-differential equations.
This alternative derivation of the Hartree-Fock equations is given below.
!eblock


!split
===== Analysis of Hartree-Fock equations in coordinate space =====
!bblock
  A theoretically convenient form of the
Hartree-Fock equation is to regard the direct and exchange operator
defined through 
!bt
\begin{equation*}
  V_{\mu}^{d}(x_i) = \int \psi_{\mu}^*(x_j) 
 \hat{v}(r_{ij})\psi_{\mu}(x_j) dx_j
\end{equation*}
!et
and
!bt
\begin{equation*}
  V_{\mu}^{ex}(x_i) g(x_i) 
  = \left(\int \psi_{\mu}^*(x_j) 
 \hat{v}(r_{ij})g(x_j) dx_j
  \right)\psi_{\mu}(x_i),
\end{equation*}
!et
respectively. 
!eblock

!split
===== Analysis of Hartree-Fock equations in coordinate space =====
!bblock
The function $g(x_i)$ is an arbitrary function,
and by the substitution $g(x_i) = \psi_{\nu}(x_i)$
we get
!bt
\begin{equation*}
  V_{\mu}^{ex}(x_i) \psi_{\nu}(x_i) 
  = \left(\int \psi_{\mu}^*(x_j) 
 \hat{v}(r_{ij})\psi_{\nu}(x_j)
  dx_j\right)\psi_{\mu}(x_i).
\end{equation*}
!et
We may then rewrite the Hartree-Fock equations as
!bt
\[
  \hat{h}^{HF}(x_i) \psi_{\nu}(x_i) = \epsilon_{\nu}\psi_{\nu}(x_i),
\]
!et
with
!bt
\[
  \hat{h}^{HF}(x_i)= \hat{h}_0(x_i) + \sum_{\mu=1}^NV_{\mu}^{d}(x_i) -
  \sum_{\mu=1}^NV_{\mu}^{ex}(x_i),
\]
!et
and where $\hat{h}_0(i)$ is the one-body part. The latter is normally chosen as a part which yields solutions in closed form. The harmonic oscilltor is a classical problem thereof.
We normally rewrite the last equation as
!bt
\[
  \hat{h}^{HF}(x_i)= \hat{h}_0(x_i) + \hat{u}^{HF}(x_i). 
\]
!et
!eblock


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
Another possibility is to expand the single-particle functions in a known basis  and vary the coefficients, 
that is, the new single-particle wave function is written as a linear expansion
in terms of a fixed chosen orthogonal basis (for example the well-known harmonic oscillator functions or the hydrogen-like functions etc).
We define our new Hartree-Fock single-particle basis by performing a unitary transformation 
on our previous basis (labelled with greek indices) as
!bt
\begin{equation}
\psi_p^{HF}  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. label{eq:newbasis}
\end{equation}
!et
In this case we vary the coefficients $C_{p\lambda}$. If the basis has infinitely many solutions, we need
to truncate the above sum.  We assume that the basis $\phi_{\lambda}$ is orthogonal. A unitary transformation keeps the orthogonality, as discussed in exercise 1 below.  
!eblock

!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
It is normal to choose a single-particle basis defined as the eigenfunctions
of parts of the full Hamiltonian. The typical situation consists of the solutions of the one-body part of the Hamiltonian, that is we have
!bt
\[
\hat{h}_0\phi_{\lambda}=\epsilon_{\lambda}\phi_{\lambda}.
\]
!et 
The single-particle wave functions $\phi_{\lambda}({\bf r})$, defined by the quantum numbers $\lambda$ and ${\bf r}$
are defined as the overlap 
!bt
\[
   \phi_{\lambda}({\bf r})  = \langle {\bf r} | \lambda \rangle .
\]
!et
!eblock

!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
In our discussions hereafter we will use our definitions of single-particle states above and below the Fermi ($F$) level given by the labels
$ijkl\dots \le F$ for so-called single-hole states and $abcd\dots > F$ for so-called particle states.
For general single-particle states we employ the labels $pqrs\dots$. 
!eblock


!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
In Eq.~(ref{FunctionalEPhi}), restated here
!bt
\[
  E[\Phi] 
  = \sum_{\mu=1}^N \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS},
\]
!et 
we found the expression for the energy functional in terms of the basis function $\phi_{\lambda}({\bf r})$. We then  varied the above energy functional with respect to the basis functions $|\mu \rangle$. 
Now we are interested in defining a new basis defined in terms of
a chosen basis as defined in Eq.~(ref{eq:newbasis}). We can then rewrite the energy functional as
!bt
\begin{equation}
  E[\Phi^{HF}] 
  = \sum_{i=1}^N \langle i | h | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS}, label{FunctionalEPhi2}
\end{equation}
!et
where $\Phi^{HF}$ is the new Slater determinant defined by the new basis of Eq.~(ref{eq:newbasis}). 
!eblock

!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
Using Eq.~(ref{eq:newbasis}) we can rewrite Eq.~(ref{FunctionalEPhi2}) as 
!bt
\begin{equation}
  E[\Psi] 
  = \sum_{i=1}^N \sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
  \frac{1}{2}\sum_{ij=1}^N\sum_{{\alpha\beta\gamma\delta}} C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. label{FunctionalEPhi3}
\end{equation}
!et
!eblock

!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
We wish now to minimize the above functional. We introduce again a set of Lagrange multipliers, noting that
since $\langle i | j \rangle = \delta_{i,j}$ and $\langle \alpha | \beta \rangle = \delta_{\alpha,\beta}$, 
the coefficients $C_{i\gamma}$ obey the relation
!bt
\[
 \langle i | j \rangle=\delta_{i,j}=\sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | \beta \rangle=
\sum_{\alpha} C^*_{i\alpha}C_{i\alpha},
\]
!et
which allows us to define a functional to be minimized that reads
!bt
\begin{equation}
  F[\Phi^{HF}]=E[\Phi^{HF}] - \sum_{i=1}^N\epsilon_i\sum_{\alpha} C^*_{i\alpha}C_{i\alpha}.
\end{equation}
!et
!eblock



!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
Minimizing with respect to $C^*_{i\alpha}$, remembering that the equations for $C^*_{i\alpha}$ and $C_{i\alpha}$
can be written as two  independent equations, we obtain
!bt
\[
\frac{d}{dC^*_{i\alpha}}\left[  E[\Phi^{HF}] - \sum_{j}\epsilon_j\sum_{\alpha} C^*_{j\alpha}C_{j\alpha}\right]=0,
\]
!et
which yields for every single-particle state $i$ and index $\alpha$ (recalling that the coefficients $C_{i\alpha}$ are matrix elements of a unitary (or orthogonal for a real symmetric matrix) matrix)
the following Hartree-Fock equations
!bt
\[
\sum_{\beta} C_{i\beta}\langle \alpha | h | \beta \rangle+
\sum_{j=1}^N\sum_{\beta\gamma\delta} C^*_{j\beta}C_{j\delta}C_{i\gamma}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}=\epsilon_i^{HF}C_{i\alpha}.
\]
!et
!eblock

!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
We can rewrite this equation as (changing dummy variables)
!bt
\[
\sum_{\beta} \left\{\langle \alpha | h | \beta \rangle+
\sum_{j}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}\right\}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}.
\]
!et
Note that the sums over greek indices run over the number of basis set functions (in principle an infinite number).
!eblock

!split
===== Hartree-Fock by varying the coefficients of a wave function expansion =====
!bblock
Defining 
!bt
\[
h_{\alpha\beta}^{HF}=\langle \alpha | h | \beta \rangle+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS},
\]
!et
we can rewrite the new equations as 
!bt
\begin{equation}
\sum_{\gamma}h_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}. label{eq:newhf}
\end{equation}
!et
The latter is nothing but a standard eigenvalue problem. Compared with Eq.~(ref{eq:hartreefockcoordinatespace}),
we see that we do not need to compute any integrals in an iterative procedure for solving the equations.
It suffices to tabulate the matrix elements $\langle \alpha | h | \beta \rangle$ and $\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}$ once and for all. Successive iterations require thus only a look-up in tables over one-body and two-body matrix elements. These details will be discussed below when we solve the Hartree-Fock equations numerical. 
!eblock

!split
===== Hartree-Fock algorithm =====
!bblock
Our Hartree-Fock matrix  is thus
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\langle \alpha | \hat{h}_0 | \beta \rangle+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
The Hartree-Fock equations are solved in an iterative waym starting with a guess for the coefficients $C_{j\gamma}=\delta_{j,\gamma}$ and solving the equations by diagonalization till the new single-particle energies
$\epsilon_i^{\mathrm{HF}}$ do not change anymore by a prefixed quantity. 
!eblock

!split
===== Hartree-Fock algorithm =====
!bblock
Normally we assume that the single-particle basis $|\beta\rangle$ forms an eigenbasis for the operator
$\hat{h}_0$, meaning that the Hartree-Fock matrix becomes  
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
The Hartree-Fock eigenvalue problem
!bt
\[
\sum_{\beta}\hat{h}_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{\mathrm{HF}}C_{i\alpha},
\]
!et
can be written out in a more compact form as
!bt
\[
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}. 
\]
!et
!eblock

!split
===== Hartree-Fock algorithm =====
!bblock
The Hartree-Fock equations are, in their simplest form, solved in an iterative way, starting with a guess for the
coefficients $C_{i\alpha}$. We label the coefficients as $C_{i\alpha}^{(n)}$, where the subscript $n$ stands for iteration $n$.
To set up the algorithm we can proceed as follows:

 * We start with a guess $C_{i\alpha}^{(0)}=\delta_{i,\alpha}$. Alternatively, we could have used random starting values as long as the vectors are normalized. Another possibility is to give states below the Fermi level a larger weight.
 * The Hartree-Fock matrix simplifies then to (assuming that the coefficients $C_{i\alpha} $  are real)
!bt
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j = 1}^N\sum_{\gamma\delta} C_{j\gamma}^{(0)}C_{j\delta}^{(0)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
!eblock

!split
===== Hartree-Fock algorithm =====
!bblock
Solving the Hartree-Fock eigenvalue problem yields then new eigenvectors $C_{i\alpha}^{(1)}$ and eigenvalues
$\epsilon_i^{HF(1)}$. 
 * With the new eigenvalues we can set up a new Hartree-Fock potential 
!bt
\[
\sum_{j = 1}^N\sum_{\gamma\delta} C_{j\gamma}^{(1)}C_{j\delta}^{(1)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
!et
The diagonalization with the new Hartree-Fock potential yields new eigenvectors and eigenvalues.
This process is continued till for example
!bt
\[
\frac{\sum_{p} |\epsilon_i^{(n)}-\epsilon_i^{(n-1)}|}{m} \le \lambda,  
\]
!et
where $\lambda$ is a user prefixed quantity ($\lambda \sim 10^{-8}$ or smaller) and $p$ runs over all calculated single-particle
energies and $m$ is the number of single-particle states.
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
We can rewrite the ground state energy by adding and subtracting $\hat{u}^{HF}(x_i)$ 
!bt
\[
  E_0^{HF} =\langle \Phi_0 | \hat{H} | \Phi_0\rangle = 
\sum_{i\le F}^N \langle i | \hat{h}_0 +\hat{u}^{HF}| j\rangle+ \frac{1}{2}\sum_{i\le F}^N\sum_{j \le F}^N\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^N \langle i |\hat{u}^{HF}| i\rangle,
\]
!et
which results in
!bt
\[
  E_0^{HF}
  = \sum_{i\le F}^N \varepsilon_i^{HF} + \frac{1}{2}\sum_{i\le F}^N\sum_{j \le F}^N\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^N \langle i |\hat{u}^{HF}| i\rangle.
\]
!et
Our single-particle states $ijk\dots$ are now single-particle states obtained from the solution of the Hartree-Fock equations.
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
Using our definition of the Hartree-Fock single-particle energies we obtain then the following expression for the total ground-state energy
!bt
\[
  E_0^{HF}
  = \sum_{i\le F}^N \varepsilon_i - \frac{1}{2}\sum_{i\le F}^N\sum_{j \le F}^N\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right].
\]
!et
This form will be used in our discussion of Koopman's theorem.
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock  Atomic physics case
We have 
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)] 
  = \sum_{i=1}^H \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
!et
where $\Phi^{\mathrm{HF}}(N)$ is the new Slater determinant defined by the new basis of Eq.~(ref{eq:newbasis})
for $N$ electrons (same $Z$).  If we assume that the single-particle wave functions in the new basis do not change 
when we remove one electron or add one electron, we can then define the corresponding energy for the $N-1$ systems as 
!bt
\[
  E[\Phi^{\mathrm{HF}}(N-1)] 
  = \sum_{i=1; i\ne k}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1;i,j\ne k}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
!et
where we have removed a single-particle state $k\le F$, that is a state below the Fermi level.  
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
Calculating the difference 
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{i=1;i\ne k}^N\langle ik|\hat{v}|ik\rangle_{AS}  \frac{1}{2}\sum_{j=1;j\ne k}^N\langle kj|\hat{v}|kj\rangle_{AS},
\]
!et
we obtain
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{j=1}^N\langle kj|\hat{v}|kj\rangle_{AS}
\]
!et
which is just our definition of the Hartree-Fock single-particle energy
!bt
\[
  E[\Phi^{\mathrm{HF}}(N)]-   E[\Phi^{\mathrm{HF}}(N-1)] = \epsilon_k^{\mathrm{HF}} 
\]
!et
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
Similarly, we can now compute the difference (we label the single-particle states above the Fermi level as $abcd > F$)
!bt
\[
  E[\Phi^{\mathrm{HF}}(N+1)]-   E[\Phi^{\mathrm{HF}}(N)]= \epsilon_a^{\mathrm{HF}}. 
\]
!et
These two equations can thus be used to the electron affinity or ionization energies, respectively. 
Koopman's theorem states that for example the ionization energy of a closed-shell system is given by the energy of the highest occupied single-particle state.  If we assume that changing the number of electrons from $N$ to $N+1$ does not change the Hartree-Fock single-particle energies and eigenfunctions, then Koopman's theorem simply states that the ionization energy of an atom is given by the single-particle energy of the last bound state. In a similar way, we can also define the electron affinities. 
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
As an example, consider a simple model for atomic sodium, Na. Neutral sodium has eleven electrons, 
with the weakest bound one being confined the $3s$ single-particle quantum numbers. The energy needed to remove an electron from neutral sodium is rather small, 5.1391 eV, a feature which pertains to all alkali metals.
Having performed a  Hartree-Fock calculation for neutral sodium would then allows us to compute the
ionization energy by using the single-particle energy for the $3s$ states, namely $\epsilon_{3s}^{\mathrm{HF}}$. 

From these considerations, we see that Hartree-Fock theory allows us to make a connection between experimental 
observables (here ionization and affinity energies) and the underlying interactions between particles.  
In this sense, we are now linking the dynamics and structure of a many-body system with the laws of motion which govern the system. Our approach is a reductionistic one, meaning that we want to understand the laws of motion 
in terms of the particles or degrees of freedom which we believe are the fundamental ones. Our Slater determinant, being constructed as the product of various single-particle functions, follows this philosophy.
!eblock

!split
===== Analysis of Hartree-Fock equations, Koopman's theorem =====
!bblock  
With similar arguments as in atomic physics, we can now use Hartree-Fock theory to make a link
between nuclear forces and separation energies. Changing to nuclear system, we define
!bt
\[
  E[\Phi^{\mathrm{HF}}(A)] 
  = \sum_{i=1}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
!et
where $\Phi^{\mathrm{HF}}(A)$ is the new Slater determinant defined by the new basis of Eq.~(ref{eq:newbasis})
for $A$ nucleons, where $A=N+Z$, with $N$ now being the number of neutrons and $Z$ th enumber of protons.  If we assume again that the single-particle wave functions in the new basis do not change from a nucleus with $A$ nucleons to a nucleus with $A-1$  nucleons, we can then define the corresponding energy for the $A-1$ systems as 
!bt
\[
  E[\Phi^{\mathrm{HF}}(A-1)] 
  = \sum_{i=1; i\ne k}^N \langle i | \hat{h}_0 | i \rangle +
  \frac{1}{2}\sum_{ij=1;i,j\ne k}^N\langle ij|\hat{v}|ij\rangle_{AS},
\]
!et
where we have removed a single-particle state $k\le F$, that is a state below the Fermi level.  
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
Calculating the difference 
!bt
\[
  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{i=1;i\ne k}^N\langle ik|\hat{v}|ik\rangle_{AS}  \frac{1}{2}\sum_{j=1;j\ne k}^N\langle kj|\hat{v}|kj\rangle_{AS},
\]
!et
which becomes 
!bt
\[
  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \langle k | \hat{h}_0 | k \rangle +
  \frac{1}{2}\sum_{j=1}^N\langle kj|\hat{v}|kj\rangle_{AS}
\]
!et
which is just our definition of the Hartree-Fock single-particle energy
!bt
\[
  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \epsilon_k^{\mathrm{HF}} 
\]
!et
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
Similarly, we can now compute the difference (recall that the single-particle states $abcd > F$)
!bt
\[
  E[\Phi^{\mathrm{HF}}(A+1)]-   E[\Phi^{\mathrm{HF}}(A)]= \epsilon_a^{\mathrm{HF}}. 
\]
!et
If we then recall that the binding energy differences 
!bt
\[
BE(A)-BE(A-1) \hspace{0.5cm} \mathrm{and} \hspace{0.5cm} BE(A+1)-BE(A), 
\]
!et
define the separation energies, we see that the Hartree-Fock single-particle energies can be used to
define separation energies. We have thus our first link between nuclear forces (included in the potential energy term) and an observable quantity defined by differences in binding energies. 
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
We have thus the following interpretations (if the single-particle field do not change)
!bt
\[
BE(A)-BE(A-1)\approx  E[\Phi^{\mathrm{HF}}(A)]-   E[\Phi^{\mathrm{HF}}(A-1)] 
  = \epsilon_k^{\mathrm{HF}}, 
\]
!et
and
!bt 
\[
BE(A+1)-BE(A)\approx  E[\Phi^{\mathrm{HF}}(A+1)]-   E[\Phi^{\mathrm{HF}}(A)] =  \epsilon_a^{\mathrm{HF}}. 
\]
!et
If  we use ${}^{16}\mbox{O}$ as our closed-shell nucleus, we could then interpret the separation energy
!bt
\[
BE(^{16}\mathrm{O})-BE(^{15}\mathrm{O})\approx \epsilon_{0p^{\nu}_{1/2}}^{\mathrm{HF}}, 
\]
!et
and
!bt 
\[
BE(^{16}\mathrm{O})-BE(^{15}\mathrm{N})\approx \epsilon_{0p^{\pi}_{1/2}}^{\mathrm{HF}}.
\]
!et
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
Similalry, we could interpret
!bt
\[
BE(^{17}\mathrm{O})-BE(^{16}\mathrm{O})\approx \epsilon_{0d^{\nu}_{5/2}}^{\mathrm{HF}}, 
\]
!et
and 
!bt
\[
BE(^{17}\mathrm{F})-BE(^{16}\mathrm{O})\approx\epsilon_{0d^{\pi}_{5/2}}^{\mathrm{HF}}.
\]
!et
We can continue like this for all $A\pm 1$ nuclei where $A$ is a good closed-shell (or subshell closure)
nucleus. Examples are ${}^{22}\mbox{O}$, ${}^{24}\mbox{O}$, ${}^{40}\mbox{Ca}$, ${}^{48}\mbox{Ca}$, ${}^{52}\mbox{Ca}$, ${}^{54}\mbox{Ca}$, ${}^{56}\mbox{Ni}$, 
${}^{68}\mbox{Ni}$, ${}^{78}\mbox{Ni}$, ${}^{90}\mbox{Zr}$, ${}^{88}\mbox{Sr}$, ${}^{100}\mbox{Sn}$, ${}^{132}\mbox{Sn}$ and ${}^{208}\mbox{Pb}$, to mention some possile cases.
!eblock

!split
===== Analysis of Hartree-Fock equations and Koopman's theorem =====
!bblock
We can thus make our first interpretation of the separation energies in terms of the simplest
possible many-body theory. 
If we also recall that the so-called energy gap for neutrons (or protons) is defined as
!bt
\[
\Delta S_n= 2BE(N,Z)-BE(N-1,Z)-BE(N+1,Z),
\]
!et
for neutrons and the corresponding gap for protons
!bt
\[
\Delta S_p= 2BE(N,Z)-BE(N,Z-1)-BE(N,Z+1),
\]
!et
we can define the neutron and proton energy gaps for ${}^{16}\mbox{O}$ as
!bt
\[
\Delta S_{\nu}=\epsilon_{0d^{\nu}_{5/2}}^{\mathrm{HF}}-\epsilon_{0p^{\nu}_{1/2}}^{\mathrm{HF}}, 
\]
!et
and 
!bt
\[
\Delta S_{\pi}=\epsilon_{0d^{\pi}_{5/2}}^{\mathrm{HF}}-\epsilon_{0p^{\pi}_{1/2}}^{\mathrm{HF}}. 
\]
!et
!eblock


!split
===== Exercises: Derivation of Hartree-Fock equations  =====
!bblock  Exercise 1
Consider a Slater determinant built up of single-particle orbitals $\psi_{\lambda}$, 
with $\lambda = 1,2,\dots,N$.

The unitary transformation
!bt
\[
\psi_a  = \sum_{\lambda} C_{a\lambda}\phi_{\lambda},
\]
!et
brings us into the new basis.  
The new basis has quantum numbers $a=1,2,\dots,N$.
Show that the new basis is orthonormal.
Show that the new Slater determinant constructed from the new single-particle wave functions can be
written as the determinant based on the previous basis and the determinant of the matrix $C$.
Show that the old and the new Slater determinants are equal up to a complex constant with absolute value unity.
(Hint, $C$ is a unitary matrix). 

!eblock

!split
===== Exercises: Derivation of Hartree-Fock equations  =====
!bblock  Exercise 2 
Consider the  Slater  determinant
!bt
\[
\Phi_{0}=\frac{1}{\sqrt{n!}}\sum_{p}(-)^{p}P
\prod_{i=1}^{n}\psi_{\alpha_{i}}(x_{i}).
\]
!et
A small variation in this function is given by
!bt
\[
\delta\Phi_{0}=\frac{1}{\sqrt{n!}}\sum_{p}(-)^{p}P
\psi_{\alpha_{1}}(x_{1})\psi_{\alpha_{2}}(x_{2})\dots
\psi_{\alpha_{i-1}}(x_{i-1})(\delta\psi_{\alpha_{i}}(x_{i}))
\psi_{\alpha_{i+1}}(x_{i+1})\dots\psi_{\alpha_{n}}(x_{n}).
\]
!et
Show that
!bt
\[
\langle \delta\Phi_{0}|\sum_{i=1}^{n}\left\{t(x_{i})+u(x_{i})
\right\}+\frac{1}{2}
\sum_{i\neq j=1}^{n}v(x_{i},x_{j})|\Phi_{0}\rangle=\sum_{i=1}^{n}\langle \delta\psi_{\alpha_{i}}|\hat{t}+\hat{u}
|\phi_{\alpha_{i}}\rangle
+\sum_{i\neq j=1}^{n}\left\{\langle\delta\psi_{\alpha_{i}}
\psi_{\alpha_{j}}|\hat{v}|\psi_{\alpha_{i}}\psi_{\alpha_{j}}\rangle-
\langle\delta\psi_{\alpha_{i}}\psi_{\alpha_{j}}|\hat{v}
|\psi_{\alpha_{j}}\psi_{\alpha_{i}}\rangle\right\}
\]
!et
!eblock



===== Basic definitions and motivation =====
!bblock

In this course the final aim is to develop a Hartree-Fock code which can be used to study properties of
both atoms and molecules.

For a molecular system, the eigenfunctions of the Hartree-Fock equations are called
*molecular orbitals* (MOs). It is important to distinguish these
from the perhaps more familiar *atomic orbitals*, where we can think of (as we have done till now)
that the electrons occupy some well-defined hydrogen-like states.

An example like the $H_2$-molecule may suffice.
In the ground state the electrons are not occupying the 1$s$-orbitals of atomic Hydrogen. The
molecular system is entirely different from the atomic one, with an entirely different Hamiltonian,
and the eigenstates of the Hartree-Fock equations will therefore also be different.
!eblock






===== Basic definitions and motivation =====
!bblock

In order to solve the Hartree-Fock equations, we need to expand the molecular orbitals in a known
set of basis functions
!bt
\begin{equation}
 \phi_k(\vec r) = \sum_{\mu=1}^M\chi_{\mu k}(\vec r).
\end{equation}
!et
The question we then need to answer is how to choose basis functions $\chi_{\mu k}$? The answer to this
is primarily dictated by the following three criteria:

  * The functions should make physically sense, i.e., they should have a large probability where   the electrons are likely to be and small elsewhere.

  * It should be possible to integrate the functions efficiently.

  * The solution of the Hartree-Fock equations should converge towards the Hartree-Fock limit        as the number of basis functions increases.


The first point suggests that we choose atomic orbitals as basis functions,  which is often
referred to as ``linear combination of atomic orbitals'' (LCAO). In the project we will use the various atomic nuclei as mass centers which the electrons orbit around. However, this is not strictly required since the
atomic orbitals are merely being used as basis functions, and they are not to be thought of
as orbitals occupied by electrons. 
!eblock


===== Basic definitions, Slater orbitals =====
!bblock

A much set of state functions are the so-called 
Slater type orbitals (STO), defined as

!bt
\begin{equation}
 \chi^{STO}(r,\theta,\phi,n,l,m) = \frac{(2a)^{n+1/2}}{[(2n)!]^{1/2}}r^{n-1}\exp(-a r) Y^m_l(\theta,\phi),
\end{equation}
!et
where $n$ is the principal quantum number, $l$ and $m$ are the orbital momentum quantum numbers,
$Y^m_l(\theta,\phi)$ are the spherical harmonics familiar from the solution of the Schr\"odinger
equation for the Hydrogen atom, and $a$ is an exponent which determines the radial decay of the
function. The main attractive features of the STOs are that they have the correct exponential decay with
increasing $r$ and that the orbital components are hydrogenic. 
Furthermore, they can be used to represent in a better way weakly bound states or even resonances. The hydrogen-like state functions 
represent only bound states.
STOs are mainly 
used in atomic Hartree-Fock calculations. When doing molecular calculations, however, they have the
disadvantage that the two-particle integrals $\bra{\mu\sigma}g\ket{\nu\lambda}$ need to compute 
an anti-symmetrized matrix interaction element have no known closed form expression. This is because integrals of products
of exponentials centered on different nuclei are difficult to handle. They can of course be calculated
numerically, but for large molecules this is very time consuming.
!eblock

===== Basic definitions =====
!bblock

A clever trick which makes multiple center integrals easier to handle is to replace the exponential
term $\exp(-a r)$ with $\exp(-a r^2)$, that is, to functions proportional with Gaussians. This simplifies 
considerably the integrals to evaluate since the product of two Gaussians centered on nuclei with positions
$\vec A$ and $\vec B$ is equal to *one* Gaussian centered on some point $\vec P$ on
the line between them:

!bt
\begin{equation}
label{eq:gaussian_product}
 \exp(-a|\vec r - \vec A|^2)\cdot \exp(-b|\vec r - \vec B|^2) = K_{AB}\,\exp(-p|\vec r - \vec P|^2),
\end{equation}
!et
where

!bt
\begin{align}
 K_{AB} & =  \exp\Big(-\frac{ab}{a + b}|\vec A - \vec B|^2\Big), \\
 \vec P & =  \frac{a \vec A + b \vec B}{a + b}, \\
 p & =  a + b.
\end{align}
!et
This is the so-called *Gaussian product theorem*.
!eblock

===== Basic definitions =====
!bblock

The general functional form of a normalised Gaussian type orbital 
centered at $\vec A$ is given by

!bt
\begin{equation}
 G_{ijk}(a, \vec r_A) = \Big(\frac{2a}{\pi}\Big)^{3/4}\Big[\frac{(8a)^{i+j+k}\,i!\,j!\,k!}{(2i)!\,(2j)!\,(2k)!}\Big]x_A^i\,y_A^j\,z_A^k\,\exp(-a r_A^2),
\end{equation}
!et
where $\vec r_A = \vec r - \vec A$ and the integers $i$, $j$, $k$ determine the orbital momentum quantum number $l=i+j+k$. 
!eblock

===== Disadvantages =====
!bblock

The greatest drawback with GTOs is that they do not have the proper exponential radial decay. This can be fixed by forming linear combinations of GTOs
to resemble the STOs
!bt
\begin{equation}
 \chi^{CGTO}(\vec r_A,i,j,k) = \sum_{p=1}^L d_p G_{ijk}(a_p, \vec r_A).
\end{equation}
!et
These are called STO-LG basis functions, where L refers to the number of Gaussians used in the linear combination.
The individual Gaussians are called *primitive* basis functions and the linear combinations are called *contracted* basis functions, hence the label
CGTO (Contracted Gaussian Type Orbital). These are the functions we will employ in this project.

A very common choice for the STO-LG basis sets is $L=3$. 
It is important to note that the parameters $(a_p,d_p)$ are static and that the linear combination of Gaussians constitute *one single*
basis function. With the wording ``basis function'', we  will refer to a contracted basis function.
!eblock

===== Basic definitions =====
!bblock

The STO-LG basis sets belong to the family of *minimal basis sets*.
It means that there is one and only one basis function per atomic orbital.
The STO-LG basis sets for the Hydrogen and Helium atoms, for example, contain only one basis
function for the 1$s$ atomic orbital. This basis function is, as explained above, composed of
a linear combination of L primitives. For the atoms Lithium through Neon the STO-LG basis
sets contain 5 basis functions; one for each of the atomic orbitals
$1s$, $2s$, $2p_x$, $2p_y$ and $2p_z$.


|-----------------------------------|
| $p$    | 1      | 2      | 3      |
|---c-------c-------c-------c-------|
| $d_p$  | 0.1543 | 0.5353 | 0.4446 |
| $a_p$  | 3.4252 | 0.6239 | 0.1688 |
|-----------------------------------|

!eblock

===== Cartesian Gaussians and how to compute integrals =====
!bblock

Using GTOs as basis functions improves the speed of the integrations which must be done when setting up 
for example the Fock matrix.
The Cartesian Gaussian functions centered at $\vec A$ are given by

!bt
\begin{equation}
 G_{ijk}(a, \vec r_A) = x^i_A\,y^j_A\,z^k_A\,\exp(-a r^2_A),
\end{equation}
!et
where $\vec r_A = \vec r - \vec A$. These will be our so-called primitive basis functions (see also the flow chart of Hartree-Fock code). 
They factorize in the Cartesian components

!bt
\begin{equation}
 G_{ijk}(a, \vec r_A) = G_i(a, x_A)\,G_j(a, y_A)\,G_k(a, z_A),
\end{equation}
!et
where

!bt
\begin{equation}
 G_i(a, x_A) = x^i_A\,\exp(-a x^2_A),
\end{equation}
!et
and the other factors are defined similarly. Each of the components obey the simple recurrence relation

!bt
\begin{equation}
 x_A\,G_i = G_{i+1}.
\end{equation}
!et
!eblock

===== Integral evaluations =====
!bblock

We introduce  shorthand notation

!bt
\begin{align}
  G_a(\vec r) & = G_{ikm}(a, \vec r_A), \\
  G_b(\vec r) & = G_{jln}(b, \vec r_B),
\end{align}
!et
and define the overlap distribution  as

!bt
\begin{equation}
 \Omega_{ab}(\vec r) = G_a(\vec r)\,G_b(\vec r).
\end{equation}
!et
Using the Gaussian product theorem (ref{eq:gaussian_product}) this can be written as

!bt
\begin{equation}
 \Omega_{ab}(\vec r) = K_{AB}\,x^i_A\,x^j_B\,y^k_A\,y^l_B\,z^m_A\,z^n_B\,\exp(-p\,r^2_P),
\end{equation}
!et
where

!bt
\begin{equation}
 \begin{split}
  K_{AB}  = & \exp\Big(-\frac{ab}{a + b}R^2_{AB}\Big) \\
  \vec R_{AB} = &  \vec A - \vec B \\
  p = & a + b\\
  \vec r_P = & \vec r - \vec P \\
  \vec P = & \frac{a\vec A + b\vec B}{a + b}.
 \end{split}
\end{equation}
!et
!eblock

===== Integral evaluations =====
!bblock

Because the Gaussians $G_a$ and $G_b$ factorize in their Cartesian components, such a factorization applies to the overlap distribution
as well, namely

!bt
\begin{equation}
 \Omega_{ab}(\vec r) = \Omega_{ij}(x)\,\Omega_{kl}(y)\,\Omega_{mn}(z),
\end{equation}
!et
where

!bt
\begin{equation}
 \Omega_{ij} = K^x_{AB}\,x^i_A\,x^j_B\,\exp(-px^2_P)
\end{equation}
!et
and

!bt
\begin{equation}
\begin{split}
 K^x_{AB} = & \exp\Big(-\frac{ab}{a + b}X^2_{AB}\Big) \\
   X_{AB} = & A_x - B_x.
\end{split}
\end{equation}
!et
The distributions $\Omega_{kl}(y)$ and $\Omega_{mn}(z)$ are defined similarly.
!eblock

===== Integral evaluations =====
!bblock

A very useful representation of the Cartesian GTOs is given by the so-called Hermite Gaussians. These functions simplify 
the integrations significantly. The Hermite Gaussians centered at $\vec P$ are defined by

!bt
\begin{equation}
 \Lambda_{tuv}(p, \vec r_p) = \Big(\frac{\partial}{\partial P_x}\Big)^t \Big(\frac{\partial}{\partial P_y}\Big)^u \Big(\frac{\partial}{\partial P_z}\Big)^v \exp(-p\, r^2_P),
\end{equation}
!et
where $\vec r_p = \vec r - \vec P$. They factorize as (like the cartesian GTOs also do)

!bt
\begin{equation}
 \Lambda_{tuv}(p, \vec r_P) = \Lambda_t(p,x_P)\,\Lambda_u(p,y_P)\,\Lambda_v(p,z_P),
\end{equation}
!et
where

!bt
\begin{equation}
label{eq:HermiteGaussian_x}
 \Lambda_t(p,x_P) = \Big(\frac{\partial}{\partial P_x}\Big)^t \exp(-p\,x^2_P),
\end{equation}
!et
and the other factors are defined similarly. 
!eblock

===== Integral evaluations =====
!bblock

However, their recurrence relation is quite different from that of the Cartesian Gaussians:

!bt
\begin{equation}
\begin{split}
 \Lambda_{t+1}(p,x_P) & = \Big(\frac{\partial}{\partial P_x}\Big)^t \frac{\partial}{\partial P_x}\exp(-px^2_P) \\
                      & = \Big(\frac{\partial}{\partial P_x}\Big)^t 2px_P \exp(-px^2_P)  \\
                      & = 2p[-t\Big(\frac{\partial}{\partial P_x}\Big)^{t-1} + x_P \Big(\frac{\partial}{\partial P_x}\Big)^t] \exp(-px^2_P) \\
                      & = 2p[-t\Lambda_{t-1} + x_P \Lambda_t],
\end{split}
\end{equation}
!et
where we have used that

!bt
\begin{equation}
label{eq:derivation_rule}
 \Big(\frac{\partial}{\partial x}\Big)^t x f(x) = t\Big(\frac{\partial}{\partial x}\Big)^{t-1}f(x) + x\Big(\frac{\partial}{\partial x}\Big)^t f(x).
\end{equation}
!et
The recurrence relation reads

!bt
\begin{equation}
label{eq:hermite_gaussian_recurrence}
 x_P \Lambda_t = \frac{1}{2p}\Lambda_{t+1} + t\Lambda_{t-1}.
\end{equation}
!et
!eblock

===== Integral evaluations =====
!bblock

Our first goal is to compute the overlap integral

!bt
\begin{equation}
S_{ab}  = \langle G_a|G_b\rangle = \int d\vec r \,\Omega_{ab}(\vec r)
\end{equation}
!et
between two Gaussians centered at the points $\vec A$ and $\vec B$.
Since the overlap distribution $\Omega_{ab}$ factorizes in the Cartesian components, the integrals over $x$, $y$ and $z$ can be calculated independently of each other

!bt
\begin{equation}
\begin{split}
 S_{ab} = & \langle G_i|G_j\rangle \langle G_k|G_l\rangle \langle G_m|G_n\rangle \\
        = & S_{ij}\,S_{kl}\,S_{mn}.
\end{split}
\end{equation}
!et
The $x$ component of the overlap integral, for example, is given by

!bt
\begin{equation}
label{eq:intG_ij}
\begin{split}
 S_{ij} = & \int dx \,\Omega_{ij}(x) \\
        = & K_{AB}^x\int dx \,x_A^ix_B^j\exp(-px_P^2),
\end{split}
\end{equation}
!et
!eblock

===== Integral evaluations =====
!bblock

In equation (ref{eq:intG_ij}) the two-center GTOs have been reduced to a one-center Gaussian.
However, the integral is still not straightforward to calculate because of the powers $x_A^i$ and $x_B^j$. A smart way to deal with this is to express the Cartesian Gaussian
in terms of the Hermite Gaussians. Note that (ref{eq:HermiteGaussian_x}) is a polynomial of order $t$ in $x$ multiplied by the exponential function. In equation (ref{eq:intG_ij}) the polynomial
is of order $i+j$. This means that we can express the overlap distribution $\Omega_{ij}(x)$ in equation (ref{eq:intG_ij}) in terms of the Hermite Gaussians in (ref{eq:HermiteGaussian_x}) in the following way:

!bt
\begin{equation}
label{eq:LinCombOfHermGauss}
 \Omega_{ij}(x) = \sum_{t=0}^{i+j} E^{ij}_t \Lambda_t(p, x_P),
\end{equation}
!et
where $E^{ij}_t$ are constants.
Note that the sum is over $t$ only. The indices $i$ and $j$ are static and are determined from the powers of $x$ in $G_i$ and $G_j$.
We use them as labels on the coefficients $E^{ij}_t$ because different sets of indices will lead to different sets of coefficients.
!eblock

===== Integral evaluations =====
!bblock

To get the overlap integral in the $x$-direction we integrate (ref{eq:LinCombOfHermGauss}) over $\mathbb{R}$, which now turns out to be extremely easy;
the only term that survives the integration is the term for $t=0$:

!bt
\begin{align}
 \int dx\,\Lambda_t(p,x_P) & =  \int dx\,\Big(\frac{\partial}{\partial P_x}\Big)^t\exp(-p\,x^2_P), \\
                           & =  \Big(\frac{\partial}{\partial P_x}\Big)^t \int dx\,\exp(-p\,x^2_P), \\
                           & =  \sqrt{\frac{\pi}{p}}\,\delta_{t0}.
\end{align}
!et
We have used Leibniz' rule, which says that the differentiation of an integrand with respect to a variable which is not an integration variable can
be moved outside the integral. Thus the integral in (ref{eq:intG_ij}) is simply

!bt
\begin{equation}
 S_{ij} = E^{ij}_0\,\sqrt{\frac{\pi}{p}}.
\end{equation}
!et
!eblock

===== Integral evaluations =====
!bblock

The same procedure can be used for the integrals with respect to $y$ and $z$, which means that the total overlap integral is

!bt
\begin{equation}
 S_{ab} = E^{ij}_0\,E^{kl}_0\,E^{mn}_0\,\Big(\frac{\pi}{p}\Big)^{3/2}.
\end{equation}
!et
We need thereafter to determine the coefficients $E^{ij}_t$. When $i=j=0$ in equation (ref{eq:LinCombOfHermGauss})
we have

!bt
\begin{equation}
 E^{0,0}_0 = K_{AB}^x.
\end{equation}
!et
The other coefficients are found via the following recurrence relations

!bt
\begin{equation}
label{eq:E_recurrence}
\begin{split}
 E^{i+1,j}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PA}E^{ij}_t + (t+1)E^{ij}_{t+1} \\
 E^{i,j+1}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PB}E^{ij}_t + (t+1)E^{ij}_{t+1}.
\end{split}
\end{equation}
!et
!eblock

===== Integral evaluations =====
!bblock

Analogous expressions hold for the coefficients $E^{kl}_u$ and $E^{mn}_v$. The first equation in (ref{eq:E_recurrence}) 
can be derived by comparing two equivalent ways of expanding the product $G_{i+1}G_j$
in Hermite Gaussians. The first way is

!bt
\begin{equation}
 G_{i+1}\,G_j= \sum_{t=0}^{i+j+1}E^{i+1,j}_t \Lambda_t,
\end{equation}
!et
and the second way is

!bt
\begin{equation}
label{eq:derivation_E_coeffs}
\begin{split}
 G_{i+1}\,G_j & = x_A G_i\,G_j \\
              & = [(x - P_x) + (P_x - A_x)]\sum_{t=0}^{i+j} E^{ij}_t \Lambda_t\\
              & = \sum_{t=0}^{i+j}[x_P + X_{PA}] E^{ij}_t \Lambda_t \\
              & = \sum_{t=0}^{i+j}[\frac{1}{2p}\Lambda_{t+1} + t\Lambda_{t-1} + X_{PA}\Lambda_t]E^{ij}_t \\
              & = \sum_{t=0}^{i+j}[\frac{1}{2p}E^{ij}_{t-1} + X_{PA}E^{ij}_t + (t+1)E^{ij}_{t+1}] \Lambda_t,
\end{split}
\end{equation}
!et
where we have used the recurrence relation (ref{eq:hermite_gaussian_recurrence}) on the fourth line and changed the 
summation indices on the fifth line. 
!eblock

===== Integral evaluations, kinetic energy =====
!bblock

Note that the change in summation indices in equation (ref{eq:derivation_E_coeffs}) implies that we must define

!bt
\begin{equation}
 E^{ij}_t = 0, \qquad \text{if }t<0\text{ or }t > i + j.
\end{equation}
!et

Next we turn to the evaluation of the kinetic integral:

!bt
\begin{equation}
\begin{split}
T_{ab} & = -\frac{1}{2}\bra{G_a}\nabla^2\ket{G_b} \\
       & = -\frac{1}{2}\bra{G_{ikm}(a, \vec r_A)}\nabla^2\ket{G_{jln}(b, \vec r_B)} \\
       & = -\frac{1}{2}(T_{ij}\,S_{kl}\,S_{mn} + S_{ij}\,T_{kl}\,S_{mn} + S_{ij}\,S_{kl}\,T_{mn}),
\end{split}
\end{equation}
!et
where

!bt
\begin{equation}
 T_{ij} = \int dx \,G_i(a,x_A)\frac{\partial^2}{\partial x^2}G_j(b,x_B),
\end{equation}
!et
and the other factors are defined in the same way. Performing the differentiation yields

!bt
\begin{equation}
 T_{ij} = 4b^2\,S_{i,j+2} - 2b(2j + 1)S_{i,j} + j(j-1)S_{i,j-2}.
\end{equation}
!et
Thus we see that the kinetic integrals are calculated easily as products of the overlap integrals.
!eblock

===== Integral evaluations, one-body Coulomb interaction =====
!bblock

We now turn to the Coulomb integral due to the interaction between the electrons and the atomic nuclei

!bt
\begin{equation}
 V_{ab} = \bra{G_a}\frac{1}{r_C}\ket{G_b},
\end{equation}
!et
where $r_C = |\vec r - \vec C|$. As before, the overlap distribution is expanded in terms of  Hermite Gaussians

!bt
\begin{equation}
\begin{split}
 V_{ab} & = \int d\vec r \,\frac{\Omega_{ab}(\vec r)}{r_C} \\
        & = \sum_{tuv}E^{ij}_t E^{kl}_u E^{mn}_v\int d\vec r \, \frac{\Lambda_{tuv}(p,\vec r_P)}{r_C} \\
        & = \sum_{tuv}E^{ab}_{tuv}\int d\vec r \, \frac{\Lambda_{tuv}(p,\vec r_P)}{r_C}. \\
\end{split}
\end{equation}
!et
Here we have used the shorthand notation

!bt
\begin{equation}
 E^{ab}_{tuv} = E^{ij}_t E^{kl}_u E^{mn}_v.
\end{equation}
!et
In this integral other terms besides $\Lambda_{000}$ will survive due to the factor $1/r_C$. Let us nonetheless start by evaluating this term

!bt
\begin{equation}
 V_p = \int d\vec r \, \frac{\Lambda_{000}(p,\vec r_P)}{r_C} = \int d\vec r\, \frac{\exp(-p\,r_P^2)}{r_C}.
\end{equation}
!et
!eblock

===== Integral evaluations, one-body Coulomb interaction =====
!bblock

We will show that this three-dimensional integral can actually be converted to a one-dimensional one. The trick is to observe that the factor $1/r_C$ can be replaced by the integral

!bt
\begin{equation}
 \frac{1}{r_C} = \frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty dt\,\exp(-r^2_C\,t^2).
\end{equation}
!et
Inserting this into $V_p$ and using the Gaussian product theorem gives

!bt
\begin{align}
 V_p & =  \int \exp(-p\,r_P^2)\Big(\frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty\exp(-r^2_C\,t^2)\,dt\Big)\,d\vec r \\
     & =  \frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty\int\exp\Big(-\frac{pt^2}{p + t^2}R^2_{PC}\Big)\,\exp[-(p + t^2)r^2_S] d\vec r\, dt,
\end{align}
!et
where $\vec R_{PC} = \vec P - \vec C$ and $\vec r_S = \vec r - \vec S$ for some point $\vec S$. Doing the integral over the spatial coordinates reveals that the specific value of $\vec S$ is not relevant

!bt
\begin{align}
 V_p & =  \frac{1}{\sqrt{\pi}}\int_{-\infty}^\infty\exp\Big(-\frac{pt^2}{p + t^2}R^2_{PC}\Big)\Big(\frac{\pi}{p + t^2}\Big)^{3/2}\,dt \\
     & =  2\pi\int_0^\infty\exp\Big(-\frac{pt^2}{p + t^2}R^2_{PC}\Big)\frac{dt}{(p + t^2)^{3/2}}.
\end{align}
!et
!eblock

===== Integral evaluations, one-body Coulomb interaction =====
!bblock

Next we change integration variable from $t$ to $u$ by defining

!bt
\begin{equation}
 u^2 = \frac{t^2}{p + t^2}.
\end{equation}
!et
This will change the range of integration from $[0,\infty\rangle$ to $[0,1]$. This is beneficial because the final integral at which we arrive will be calculated numerically.
The change of variables leads to

!bt
\begin{align}
label{eq:V_p}
 V_p & = \frac{2\pi}{p}\int_0^1\exp(-p\,R^2_{PC}\,u^2)\,du \\
     & = \frac{2\pi}{p}F_0(p\,R^2_{PC}),
\end{align}
!et
where $F_0(x)$ is a special instance of the Boys function $F_n(x)$ which is defined as

!bt
\begin{equation}
 F_n(x) = \int_0^1\exp(-xt^2)\,t^{2n}\,dt.
\end{equation}
!et
We will discuss the Boys functions below
!eblock

===== Integral evaluations, one-body Coulomb interaction =====
!bblock

We have now a  simplified way of calculating the integral of $\Lambda_{000}/r_C$. However, we need to integrate $\Lambda_{tuv}/r_C$ for general values of $t$, $u$ and $v$.
These integrals are actually not that hard to do once the Boys function is calculated:

!bt
\begin{align}
 V_{ab} & = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv}\int d\vec r \, \frac{\Lambda_{tuv}(p,\vec r_p)}{r_C} \\
        & = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv} \frac{\partial^{t+u+v} F_0(p R^2_{PC})}{\partial P_x^t \partial P_y^u \partial P_z^v} \\
        & = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv} R_{tuv}(p,\vec R_{PC}), label{eq:V_ab}
\end{align}
!et
where we have defined

!bt
\begin{equation}
 R_{tuv}(p,\vec R_{PC}) = \frac{\partial^{t+u+v} F_0(p R^2_{PC})}{\partial P_x^t \partial P_y^u \partial P_z^v}.
\end{equation}
!et
!eblock



===== Integral evaluations, one-body Coulomb interaction =====
!bblock

We need to calculate derivatives of the function $F_0$. Note first that

!bt
\begin{equation}
 \frac{d}{dx}F_n(x) = -F_{n+1}(x).
\end{equation}
!et
This means that it is possible to derive analytical expressions for the Coulomb term $V_{ab}$. However, in practice they are calculated recursively in a manner similar to the way we calculate
the coefficients $E^{ij}_t$. Before presenting the recursion relations, we introduce the so-called auxiliary Hermite integrals

!bt
\begin{equation}
 R^n_{tuv}(p,\vec R_{PC}) = (-2p)^n\,\frac{\partial^{t+u+v} F_n(p R^2_{PC})}{\partial P_x^t \partial P_y^u \partial P_z^v}.
\end{equation}
!et
!eblock

===== Integral evaluations, one-body Coulomb interaction =====
!bblock

By starting with the source terms $R^n_{000}(p,\vec R_{PC}) = (-2p)^n\,F_n(p R^2_{PC})$ we can reach the targets $R^0_{tuv}(p,\vec R_{PC}) = R_{tuv}(p,\vec R_{PC})$ through the following
recurrence relations

!bt
\begin{equation}
label{eq:R_recurrence}
 \begin{split}
  R^n_{t+1,u,v} & = tR^{n+1}_{t-1,u,v} + X_{PC} R^{n+1}_{tuv} \\
  R^n_{t,u+1,v} & = uR^{n+1}_{t,u-1,v} + Y_{PC} R^{n+1}_{tuv} \\
  R^n_{t,u,v+1} & = vR^{n+1}_{t,u,v-1} + Z_{PC} R^{n+1}_{tuv}.
 \end{split}
\end{equation}
!et
The first of these are derived as follows

!bt
\begin{align}
 R^{n}_{t+1,u,v} & = (-2p)^n\frac{\partial^{t+u+v}}{\partial P_x^t \partial P_y^u \partial P_z^v} [2pX_{PC}F'_n(pR_{PC}^2)] \\
                 & = (-2p)^{n+1}\frac{\partial^{t+u+v}}{\partial P_x^t\partial P_y^u \partial P_z^v}\Big[X_{PC}F_{n+1}(pR_{PC}^2)\Big] \\
                 & = (-2p)^{n+1}\frac{\partial^{u+v}}{\partial P_y^u \partial P_z^v}\Big[t\frac{\partial^{t-1}}{\partial P_x^{t-1}} + X_{PC}\frac{\partial^t}{\partial P_x^t}\Big]F_{n+1}(pR_{PC}^2) \\
                 & = tR^{n+1}_{t-1,u,v} + X_{PC}R^{n+1}_{tuv},
\end{align}
!et
where we have used equation (ref{eq:derivation_rule}) and the fact that $F'_n(x) = -F_{n+1}(x)$.
!eblock

===== Integral evaluations, two-body Coulomb interaction =====
!bblock

Finally we show how to calculate the Coulomb integral due to the interaction between the electrons. It is given by

!bt
\begin{equation}
\begin{split}
  g_{acbd} & = \bra{G_a G_c}\frac{1}{r_{12}}\ket{G_b G_d} \\
           & = \int\int \frac{\Omega_{ab}(\vec r_1)\Omega_{cd}(\vec r_2)}{r_{12}} d\vec r_1 d\vec r_2 \\
           & = \sum_{tuv}\sum_{\tau\nu\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}\int\int\frac{\Lambda_{tuv}(p,\vec r_{1P})\Lambda_{\tau\nu\phi}(q,\vec r_{2Q})}{r_{12}}d \vec r_1 d\vec r_2 \\
           & = \sum_{tuv}\sum_{\tau\nu\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}\frac{\partial^{t+u+v}}{\partial P_x^t \partial P_y^u \partial P_z^v}
                \frac{\partial^{\tau+\nu+\phi}}{\partial Q_x^\tau \partial Q_y^\nu \partial Q_z^\phi} \\
           &    \hspace{30mm} \int\int\frac{\exp(-pr^2_{1P})\exp(-qr^2_{2Q})}{r_{12}}d \vec r_1 d\vec r_2,
\end{split}
\end{equation}
!et
where, similar to $p$ and $\vec r_{1P}$, we have defined

!bt
\begin{equation}
 \begin{split}
    q = & c + d\\
  \vec r_{2Q} = & \vec r_2 - \vec Q \\
  \vec Q = & \frac{c\,\vec C + d\,\vec D}{c + d}.
 \end{split}
\end{equation}
!et
!eblock

===== Integral evaluations, two-body Coulomb interaction =====
!bblock

Thus we need to evaluate the integral

!bt
\begin{equation}
 V_{pq} = \int\int\frac{\exp(-pr^2_{1P})\exp(-qr^2_{2Q})}{r_{12}}d \vec r_1 d\vec r_2.
\end{equation}
!et
By first integrating over $\vec r_1$ and using equation (ref{eq:V_p}) this can be written as

!bt
\begin{equation}
 V_{pq} = \int\Big(\frac{2\pi}{p}\int_0^1\exp(-p\,r^2_{2P}\,u^2)\,du\Big)\exp(-qr^2_{2Q}) d \vec r_2.
\end{equation}
!et
Next we change the order of integration and use the Gaussian product theorem to get

!bt
\begin{equation}
\begin{split}
 V_{pq} & = \frac{2\pi}{p}\int_0^1\int\exp(-\frac{pqu^2}{pu^2+q}R^2_{PQ})\exp[-(pu^2+q)r_{2S}^2] d\vec r_2 du \\
        & = \frac{2\pi}{p}\int_0^1\exp(-\frac{pqu^2}{pu^2+q}R^2_{PQ})\Big(\frac{\pi}{pu^2+q}\Big)^{3/2} du.
\end{split}
\end{equation}
!et
!eblock

===== Integral evaluations, two-body Coulomb interaction =====
!bblock

Again, the value of $\vec S$ in $\vec r_{2S} = \vec r_2 - \vec S$ is not relevant. If we now make the change of variables

!bt
\begin{equation}
 \frac{v^2}{p+q} = \frac{u^2}{pu^2+q},
\end{equation}
!et
we get the result

!bt
\begin{equation}
 V_{pq} = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big).
\end{equation}
!et
From this we get the final answer

!bt
\begin{equation}
\begin{split}
 g_{acbd} & = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\sum_{tuv}\sum_{\tau\nu\phi}(-1)^{\tau+\nu+\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi} \\
          & \hspace{40mm} \frac{\partial^{t+u+v+\tau+\nu+\phi}}{\partial P_x^{t+\tau} \partial P_y^{u+\nu} \partial P_z^{v+\phi}}F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big) \\
          & = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\sum_{tuv}\sum_{\tau\nu\phi}(-1)^{\tau+\nu+\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}R_{t+\tau,u+\nu,v+\phi}(\alpha,\vec R_{PQ}),
\end{split}
\end{equation}
!et
where $\alpha = pq/(p+q)$. The term $(-)^{\tau+\nu+\phi}$ arises due to the fact that

!bt
\begin{equation}
\frac{\partial}{\partial Q_x} F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big) = - \frac{\partial}{\partial P_x} F_0\Big(\frac{pq}{p+q}R^2_{PQ}\Big).
\end{equation}
!et
!eblock

===== Integral evaluations, two-body Coulomb interaction and Boys function =====
!bblock

Calculating the Coulomb integrals boils down to evaluating the Boys function

!bt
\begin{equation}
 F_n(x) = \int_0^1\exp(-xt^2)\,t^{2n}\,dt.
\end{equation}
!et
Doing this by standard numerical procedures is computationally
expensive and should therefore be avoided. Here we describe a possible way to calculate the Boys function efficiently.

First note that if $x$ is very large, the function value will hardly be affected by changing the upper limit of the integral from $1$ to $\infty$. Doing this is useful
since the integral can be calculated exactly. Thus, we have the following approximation for the Boys function for large $x$:

!bt
\begin{equation}
 F_n(x) \approx \frac{(2n-1)!!}{2^{n+1}}\sqrt{\frac{\pi}{x^{2n+1}}}. \hspace{15mm} (x\hspace{2mm}\mathrm{large})
\end{equation}
!et
For small values of $x$ there seems to be no escape from numerical calculation. However, instead of doing the integral real time, it can be tabulated for regular values of $x$.
For values between the tabulated ones, the function can be calculated by a Taylor expansion centered at the nearest tabulated point $x_t$:

!bt
\begin{equation}
 F_n(x_t+\Delta x) = \sum_{k=0}^\infty\frac{F_{n+k}(x_t) (-\Delta x)^k}{k!}. \hspace{15mm} (x\hspace{2mm}\mathrm{small})
\end{equation}
!et
!eblock

===== Integral evaluations, two-body Coulomb interaction and Boys function =====
!bblock

The computational cost can be reduced even further by calculating the Boys function according to the description above only for the highest values of $n$ needed; for lower values of $n$ the function
can be found via the recursion relation

!bt
\begin{equation}
 F_n(x) = \frac{2xF_{n+1}(x)+e^{-x}}{2n+1},
\end{equation}
!et
which can be shown by integrating the function by parts.
!eblock

===== Integral evaluations, summarizing =====
!bblock

The Gaussian functions are given by

!bt
\begin{equation}
 \begin{split}
  G_a(\vec r) & = G_{ikm}(a, \vec r_A) = x^i_A\,y^j_A\,z^k_A\exp(-a r^2_A), \\
  G_b(\vec r) & = G_{jln}(b, \vec r_B) = x^i_B\,y^j_B\,z^k_B\exp(-b r^2_B),
 \end{split}
\end{equation}
!et
where $\vec r_A = \vec r - \vec A$ and $\vec r_B = \vec r - \vec B$. We further define

!bt
\begin{equation}
\begin{split}
  p & = a + b, \\
 \vec P & = \frac{a\vec A + b\vec B}{a + b}.
\end{split}
\end{equation}
!et
!eblock

===== Integral evaluations, summarizing =====
!bblock

The overlap integral

!bt
\begin{equation}
 S_{ab} = \langle G_a|G_b\rangle
\end{equation}
!et
is calculated as

!bt
\begin{equation}
 S_{ab} = E^{ij}_0\,E^{kl}_0\,E^{mn}_0\,\Big(\frac{\pi}{p}\Big)^{3/2},
\end{equation}
!et
where

!bt
\begin{equation}
 E^{i=0,j=0}_0 = \exp(-\frac{ab}{a+b}X_{AB}^2),
\end{equation}
!et
and the desired coefficients are found via

!bt
\begin{equation}
\begin{split}
 E^{i+1,j}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PA}E^{ij}_t + (t+1)E^{ij}_{t+1}, \\
 E^{i,j+1}_t & = \frac{1}{2p}E^{ij}_{t-1} + X_{PB}E^{ij}_t + (t+1)E^{ij}_{t+1}.
\end{split}
\end{equation}
!et
!eblock

===== Integral evaluations, summarizing =====
!bblock

The kinetic integral is calculated as

!bt
\begin{equation}
 T_{ab} = -\frac{1}{2}(T_{ij}\,S_{kl}\,S_{mn} + S_{ij}\,T_{kl}\,S_{mn} + S_{ij}\,S_{kl}\,T_{mn}),
\end{equation}
!et
where

!bt
\begin{equation}
 T_{ij} = 4b^2\,S_{i,j+2} - 2b(2j + 1)S_{i,j} + j(j-1)S_{i,j-2}.
\end{equation}
!et
!eblock

===== Integral evaluations, summarizing =====
!bblock

The Coulomb integral

!bt
\begin{equation}
 V_{ab} = \bra{G_a}\frac{1}{r_C}\ket{G_b}
\end{equation}
!et
is calculated as

!bt
\begin{equation}
 V_{ab} = \frac{2\pi}{p}\sum_{tuv}E^{ab}_{tuv} R_{tuv}(p,\vec R_{PC}),
\end{equation}
!et
where

!bt
\begin{equation}
 E^{ab}_{tuv} = E^{ij}_t\,E^{kl}_u\,E^{mn}_v,
\end{equation}
!et
and $R_{tuv}(p,\vec R_{PC})$ is found by first calculating the source term

!bt
\begin{equation}
 R^n_{000}(p,\vec R_{PC}) = (-2p)^n\,F_n(p R^2_{PC})
\end{equation}
!et
and then iterating towards the target $R^0_{tuv}(p,\vec R_{PC}) = R_{tuv}(p,\vec R_{PC})$ via the recurrence relations

!bt
\begin{equation}
 \begin{split}
  R^n_{t+1,u,v} & = tR^{n+1}_{t-1,u,v} + X_{PC} R^{n+1}_{tuv}, \\
  R^n_{t,u+1,v} & = uR^{n+1}_{t,u-1,v} + Y_{PC} R^{n+1}_{tuv}, \\
  R^n_{t,u,v+1} & = vR^{n+1}_{t,u,v11} + Z_{PC} R^{n+1}_{tuv}.
 \end{split}
\end{equation}
!et
!eblock

===== Integral evaluations, summarizing =====
!bblock

The Coulomb integral

!bt
\begin{equation}
 g_{acbd} = \bra{G_a G_c}\frac{1}{r_{12}}\ket{G_b G_d}
\end{equation}
!et
is calculated as

!bt
\begin{equation}
 g_{acbd} = \frac{2\pi^{5/2}}{pq\sqrt{p+q}}\sum_{tuv}\sum_{\tau\nu\phi}(-1)^{\tau+\nu+\phi}E^{ab}_{tuv}E^{cd}_{\tau\nu\phi}R_{t+\tau,u+\nu,v+\phi}(\alpha,\vec R_{PQ}),
\end{equation}
!et
where

!bt
\begin{equation}
  \alpha = \frac{pq}{p + q}.
\end{equation}
!et
!eblock


===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

Till now we have mainly dealt with the Hartree-Fock equations using anti-symmetrized matrix elements. Since the Hamiltonian does not 
contain operators acting on the spin states, it is common to write out the spin-degrees of freedom in an explicit way.

We wrote the Hartree-Fock equations as

!bt
\begin{equation*}
  \hat{h}^{HF}(x_i) \psi_{p}(x_i) = \epsilon_{p}\psi_{p}(x_i),
\end{equation*}
!et
with

!bt
\begin{equation*}
  \hat{h}^{HF}(x_i)= \hat{h}_0(x_i) + \sum_{j=1}^NV_{j}^{d}(x_i) -
  \sum_{j=1}^NV_{j}^{ex}(x_i),
\end{equation*}
!et
and where $\hat{h}_0(i)$ is the one-body part.
In this equations we include both spin and spatial degrees of freedom.

The direct part is defined as

!bt
\begin{equation*}
  V_{p}^{d}(x_i) = \int \psi_{p}^*(x_j)\psi_{p}(x_j)\hat{v}(r_{ij}) dx_j
\end{equation*}
!et
while the exchange operator (or Fock operator) is

!bt
\begin{equation*}
  V_{p}^{ex}(x_i) \psi_{q}(x_i) 
  = \left(\int \psi_{p}^*(x_j) 
  \hat{v}(r_{ij})\psi_{q}(x_j)
  dx_j\right)\psi_{p}(x_i).
\end{equation*}
!et
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

If now deal explicitely with the spin degrees of freedom, we can write the single-particle state

!bt
\begin{equation*}
\psi_{p}(x_i) = \phi_{p}(_r__i)\xi_{\sigma_i},
\end{equation*}
!et
where $\xi_{\sigma_i}$ is a standard Pauli spinor. Since we have only two possible spin values, the direct terms reduces then to
(recall that we have defined $\int dx_j = \sum_{\sigma_j} \int d_r__j$)

!bt
\begin{equation*}
  V_{p}^{d}(_r__i)\phi_{q}(_r__i) = 2\int \phi_{p}^*(_r__j)\phi_{p}(_r__i)\hat{v}(r_{ij}) d_r__j\phi_{q}(_r__i)
\end{equation*}
!et
while the exchange operator (or Fock operator) is

!bt
\begin{equation*}
  V_{p}^{ex}(_r__i) \phi_{q}(_r__i) 
  = \left(\int \phi_{p}^*(_r__j) 
  \hat{v}(r_{ij})\phi_{q}(_r__j)
  d_r__j\right)\phi_{p}(_r__i).
\end{equation*}
!et
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

In our Hartree-Fock calculation we expand the single-particle functions in terms of known basis functions (hydrogen-like one, STOs, GTOs etc), namely

!bt
\begin{equation*}
\phi_{p}(_r__i) = \sum_{k=1}^{d}C_{pk}\chi_k(_r__i),
\end{equation*}
!et
$d$ is the number of basis functions $\chi_k(_r__i)$. The Hartree-Fock equations become then

!bt
\begin{equation*}
\hat{h}^{HF}\hat{C}_p=\epsilon^{HF}\hat{S}\hat{C}_p,
\end{equation*}
!et
where $\hat{S}$ is the overlap matrix needed in case the basis functions $\chi_k(_r__i)$ are not normalized (typically, GTOs are not). 
Our Hartree-Fock Hamiltonian leads then to matrix elements (in a bra-ket notation)

!bt
\begin{equation*}
\langle p | \hat{h}^{HF} | q \rangle = \langle p|\hat{h}_0|q\rangle +\sum_{k\le F}\sum_{rs}C_{kr}^*C_{ks}\left(2\langle pr | \hat{v}|qs\rangle-\langle pr | \hat{v}|sq\rangle\right),
\end{equation*}
!et
with

!bt
\begin{equation*}
\langle p|\hat{h}_0|q\rangle = \int \chi_{p}^*(_r__j)\left(-\frac{1}{2}\nabla^2-\frac{Z}{_r__j}  \right)\chi_{q}(_r__j)
  d_r__j.
\end{equation*}
!et
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

The other integrals are

!bt
\begin{equation*}
\langle pr | \hat{v}|qs\rangle = \int\int \chi_{p}^*(_r__i)\chi_{q}^*(_r__j)\hat{v}(r_{ij})\chi_{r}(_r__i)\chi_{s}(_r__j)
  d_r__id_r__j.
\end{equation*}
!et
If we then introduce the density matrix defined as

!bt
\begin{equation*}
D_{pq}=\sum_{k\le F}C_{kp}C_{kq}^*,
\end{equation*}
!et
we can rewrite the Hartree-Fock matrix elements as

!bt
\begin{equation*}
\langle p | \hat{h}^{HF} | q \rangle = \langle p|\hat{h}_0|q\rangle +\sum_{rs}D_{rs}\left(2\langle pr | \hat{v}|qs\rangle-\langle pr | \hat{v}|sq\rangle\right),
\end{equation*}
!et
meaning that the only quantity we need to calculate at every
interation is the density matrix, which is evaluated using the eigenvector 
obtained from the diagonalization of the Hartree-Fock matrix.
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

From an algorithmic point of view, we see now that we need, with our GTO basis, to evaluate 

  * The overlap matrix $\hat{S}$.

  * The kinetic energy and one-body interaction matrix elements $\langle p|hat{h}_0|q\rangle $ and finally the

  * two-body interaction matrix elements $\langle pr | \hat{v}|qs\rangle$.


All these elements can be computed once and for all and stored in
memory. The overlap matrix $S$ and the one-body matrix elements
$\langle p|\hat{h}_0|q\rangle $ can be stored as simple
one-dimensional arrays, or alternatively as matrices of small
dimensions.  The time-consuming part in the Hartree-Fock calculations
involves the calculation of the two-body matrix. Furthermore, the
storage of these matrix elements plays also an important role, in
particular we wish to access the table of matrix elements as fast as
possible.  
!eblock


===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

In a brute force algorithm for storing the matrix elements, if we have $d$ basis functions, we end up with the need of storing 
$d^4$ matrix elements. We can reduce this considerably by the following considerations.
In the calculation of the two-body matrix elements $\langle pr | \hat{v}|qs\rangle$ we have the following symmetries

  * Invariance under permutations, that is  
!bt 
\begin{equation*} \langle pr | \hat{v}|qs\rangle = \langle rp | \hat{v}|sq\rangle.
\end{equation*}
!et
  * The functions entering the evaluation of the integrals are all real, meaning that if we interchange $p\leftrightarrow q$ or  $r\leftrightarrow s$, we end up with the same matrix element.


This reduces by a factor of eight the total number of matrix elements to be stored. 
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

Furthermore, in setting up a table for the two-body matrix elements we can convert the need of using four indices $pqrs$ of 
$\langle pr | \hat{v}|qs\rangle$, which in a brute forces way could be coded as a four-dimensional array, to 
a two-dimensional array $V_{lm}$, where $l$ and $m$ stand for all possible two-body configurations $pq$.
 
Each number $l$ and $m$ in $V_{lm}$  should then point to a set of single-particle  states $(p,q)$ and $(r,s)$.  

In our case, since we have 
symmetries which allow us to set $p\le q$, we have, with $d$ single particle states a total of $d(d+1)/2$ two-body configurations.
How do we store such a matrix? The simplest thing to do is to convert it into a one-dimensional array. How do we achieve that? 
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

We now have a matrix $V$ of dimension $n\times n$ and we want to store the elements $V_{lm}$ as a one-dimensional array $A$ using
$0 \le l \le m \le n-1$. For

  * $l=0$ we have $n$ elements

  * $l=1$ we have $n-1$ elements

  * $\dots$


  * $l=\nu$ we have $n-\nu$ elements

  * $\dots$


  * $l=n-1$ we have $1$ element,


and the total number is

!bt
\begin{equation*}
\sum_{\nu =0}^{n-1}\left(n-\nu\right)=\frac{n(n+1)}{2}.
\end{equation*}
!et 
!eblock

===== Hartree-Fock equations with spin degrees of freedom =====
!bblock

To find the number ($\mathrm{number}(l,m)$) in a one-dimensional array $A$ which corresponds to a matrix element $V_{lm}$, we note that

!bt
\begin{equation*}
\mathrm{number}(l,m)=\sum_{\nu =0}^{l-1}\left(n-\nu\right)+m-l=\frac{l(2n-l-1)}{2}+m.
\end{equation*}
!et 
The first matrix element $V(0,0)$ is obviously given by the element $A(0)$. 

We have thus reduced a four dimensional array to a one-dimensional array, where the given pairs $(p,q)$ and $(r,s)$ point to the matrix indices $l$
and $m$, respectively. The latter are used to find the explicit number $\mathrm{number}(l,m)$ which points to the desired matrix element stored 
in a one-dimensional array.
!eblock

===== The hydrogen molecule, our next step =====
!bblock

The 
H$_2$ molecule consists of two protons and two electrons 
with a ground state energy $E=-31.949$ eV or $-1.175$ a.u. and the 
equilibrium distance between the two hydrogen atoms
of $r_0=1.40$ Bohr radii (recall that a Bohr radius is $0.05\times 10^{-9}$m.


We define our systems using the following variables.
You can choose origo is chosen to be halfway between the two protons (this is just one possibility). The distance from 
proton 1 is then defined as 
$-_R_/2$ whereas proton 2 has a distance $_R_/2$.
Calculations are performed for fixed distances $_R_$ between the two protons.
We will need here GTOs with two centers.
!eblock

===== The hydrogen molecule, our next step =====
!bblock

Electron 1 has a distance $r_1$ from the chose origo, while  electron $2$
has a distance $r_2$. 
The kinetic energy operator becomes then

!bt
\begin{equation*}
   -\frac{\nabla_1^2}{2}-\frac{\nabla_2^2}{2}.
\end{equation*}
!et
The distance between the two electrons is
$r_{12}=|_r__1-_r__2|$. 
The repulsion between the two electrons results in a potential energy term given by

!bt
\begin{equation*}
               +\frac{1}{r_{12}}.
\end{equation*}
!et
In a similar way we obtain a repulsive contribution from the interaction between the two 
protons given by

!bt
\begin{equation*}
               +\frac{1}{|_R_|},
\end{equation*}
!et
where $_R_$ is the distance between the two protons.
!eblock

===== The hydrogen molecule, our next step =====
!bblock

To obtain the final potential energy we need to include the attraction the electrons feel from the protons.
To model this, we need to define the distance between the electrons and the two protons.
If we model this along a 
chosen $z$-akse with electron 1 placed at a distance 
$_r__1$ from a chose origo, one proton at $-_R_/2$
and the other at  $_R_/2$, 
the distance from proton 1 to electron 1 becomes

!bt
\begin{equation*}
_r__{1p1}=_r__1+ _R_/2,
\end{equation*}
!et
and

!bt
\begin{equation*}
_r__{1p2}=_r__1- _R_/2,
\end{equation*}
!et
from proton 2.
!eblock

===== The hydrogen molecule, our next step =====
!bblock

Similarly, for electron 2 we obtain

!bt
\begin{equation*}
_r__{2p1}=_r__2+_R_/2,
\end{equation*}
!et
and

!bt
\begin{equation*}
_r__{2p2}=_r__2-_R_/2.
\end{equation*}
!et
These four distances define the attractive contributions to the potential energy

!bt
\begin{equation*}
   -\frac{1}{r_{1p1}}-\frac{1}{r_{1p2}}-\frac{1}{r_{2p1}}-\frac{1}{r_{2p2}}.
\end{equation*}
!et
We can then write the total Hamiltonian as

!bt
\begin{equation*}
   \OP{H}=-\frac{\nabla_1^2}{2}-\frac{\nabla_2^2}{2}
   -\frac{1}{r_{1p1}}-\frac{1}{r_{1p2}}-\frac{1}{r_{2p1}}-\frac{1}{r_{2p2}}
               +\frac{1}{r_{12}}+\frac{1}{|_R_|}.
\end{equation*}
!et
!eblock

===== The hydrogen molecule, our next step =====
!bblock

If we use standard hydrogen-like wave functions, one can make an ansatz for the 
Slater determinant by using the following single-particle states

!bt
\begin{equation*}
   \psi(_r__1,_R_)=\left(\exp{(-\alpha r_{1p1})}
      +\exp{(-\alpha r_{1p2})}\right),
\end{equation*}
!et
for electron 1 and

!bt
\begin{equation*}
   \psi(_r__2,_R_)=\left(\exp{(-\alpha r_{2p1})}
      +\exp{(-\alpha r_{2p2})}\right),
\end{equation*}
!et
for electron 2, with
$\alpha$ being a variational parameter to be optimized. 
We will use GTOs with two centers, corresponding to the atomic nuclei of the hydrogen molecules.
!eblock

===== The Be$_2$ molecule, the next step =====
!bblock

The next step consists in estimating the binding energy of the Be$_2$ molecule.
Useful references are then

  * Moskowitz and Kalos, Int. Journal of Quantum Chemistry _XX_, 1107 (1981). Results for He and H$_2$.

  * Filippi, Singh and Umrigar, J. Chemical Physics _105_, 123 (1996).   Useful results on Be$_2$.

  * J\o rgen H\o gberget, Master of Science thesis University of Oslo, 2013.


With a functioning code for the H$_2$ and Be$_2$ molecules we will next move over to calculations
of closed shell atoms like Ne and Ar and molecules like H$_2$O and SiO$_2$. 
For the latter systems we need also to perform a so-called unrestricted Hartree-Fock calculation.
!eblock

===== Density distribution =====
!bblock

An important quantity which can be related to the charge distribution of electrons,
is the so-called density distribution  (multiplying with the electrical charge gives the charge distribution) defined as

!bt
\begin{equation*}
\rho(_r_)=\rho(_r__1) = \int d_r__2\dots d_r__N \left| \Psi(_r__1,_r__2\dots _r__N)\right|^2, 
\end{equation*}
!et
which in a Hartree-Fock based approach becomes

!bt
\begin{equation*}
\rho(_r_)=\sum_{i=1}^{N}\left| \psi_i(_r_)\right|^2,
\end{equation*}
!et
with $\psi$ the single-particle wave functions (our best basis).  A useful check that the numerics works properly is 
to  integrate the density distributions since it has to give us the total number of electrons in the system, that is

!bt
\begin{equation*}
N=\int d_r_\rho(_r_).
\end{equation*}
!et
This is a useful test of the numerics. 
!eblock





